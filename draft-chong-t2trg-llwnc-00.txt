T2TRG                                                     Chong, Song
Internet-Draft                                                  KAIST
Intended status: Standards Track                      Jang, Hyeonjoon
Expires: December 15, 2021                                      KAIST
                                                         October 2020

                Low End-to-End Latency Content Caching
                      in Wireless Network Clouds
                      draft-chong-t2trg-llwnc-00

Abstract

In this document, we consider the content caching design without 
requiring historical content access information or content popularity
profiles in a hierarchical cellular network architecture.
Our design aims to dynamically select caching locations for
different contents where caching locations can be content servers,
cloud units (CUs), and base stations (BSs). Our design objective
is to support as high content request rates as possible while
maintaining the finite service time.

Status of this Memo

This Internet-Draft is submitted in full conformance with the
provisions of BCP 78 and BCP 79.

Internet-Drafts are working documents of the Internet Engineering
Task Force (IETF).  Note that other groups may also distribute
working documents as Internet-Drafts. The list of current Internet-
Drafts is at http://datatracker.ietf.org/drafts/current/.

Internet-Drafts are draft documents valid for a maximum of six
months and may be updated, replaced, or obsoleted by other
documents at any time.  It is inappropriate to use Internet-Drafts
as reference material or to cite them other than as
"work in progress."

This Internet-Draft will expire on December 15, 2021.


Chong & Jang             Expires  December 15, 2021             [Page 1]

Internet-Draft      Wireless Cloud Content Caching          October 2020

Copyright Notice

Copyright (c) 2020 IETF Trust and the persons identified as the
document authors.  All rights reserved.

 This document is subject to BCP 78 and the IETF Trust's Legal
 Provisions Relating to IETF Documents
 (http://trustee.ietf.org/license-info) in effect on the date of
 publication of this document.  Please review these documents
 carefully, as they describe your rights and restrictions with respect
 to this document.  Code Components extracted from this document must
 include Simplified BSD License text as described in Section 4.e of
 the Trust Legal Provisions and are provided without warranty as
 described in the Simplified BSD License.

Table of Contents

 1.  Introduction . . . . . . . . . . . . . . . . . . . .. . . . . .  2
 2.  Main Idea  . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
 2.1.  System Model . . . . . . . . . . . . . . . . . . . . . . . . . 3
 2.2.  Hybrid Content Caching Design . . . . . . . . . . . .. . . . . 4
 3.  IANA Considerations  . . . . . . .. . . . .  . . . . . . . . . . 5
 4.  Security Considerations  . . . . . . . . . . . .  . . .  . . . . 5
 5.  References . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
 5.1.  Normative References . . . . . . . . . . . . . . . . . . . . . 5
 5.2.  Informative References . . . . . .. . . . .  . . . . . . . . . 5
 Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . 5 
 Authors' Addresses . . . . . . . . . . . . . . . . . . . . . . . . . 6

1.  Introduction

With the rapidly increasing mobile video traffic,
both backhaul and fronthaul networks connecting the internet
with the mobile core and edge networks such as base stations
(BSs) (see Fig. 1) become more and more congested. Since
popular contents are more frequently requested by end users,
we can reduce the end-to-end latency of video content services
and backhaul/fronthaul traffic loads by placing popular
contents at locations closer to the end users. Content
popularity profile, which captures its average access frequency
from end users, can be spatio-temporally varying in wireless
networks due to user mobility or social interaction between
mobile users. Moreover, the massive deployment of small
cells such as femto-cells in the cellular networks increases
the spatial granularity which renders the real-time estimation
of the content popularity in each BS more challenging.
Meanwhile, edge-centric technologies (e.g., edge computing/
caching and distributed Self-Organizing Network (SON))
and cloud-centric technologies (e.g., cloud computing/caching
and Cloud Radio Access Network (C-RAN)) have been devised
to support the latency-critical applications and to address
the huge amount of workloads in the cloud servers, respectively.
Recently, hybrid network architecture and operations
which adaptively exploit the edge-centric and cloud-centric
natures of the wireless network environments, has been proposed.

Chong & Jang             Expires  December 15, 2021             [Page 2]

Internet-Draft      Wireless Cloud Content Caching          October 2020

2.  Main Idea

In this document we consider the caching design in a general wireless 
network architecture where each group of a small number of BSs is 
connected to a cloud unit(CU) where individual BSs and the CU have 
content caching repositories (see Fig. 1). The caching design must 
adaptively determine the content caching locations at BSs and CUs
depending on the network dynamics to support as high average content 
request rates as possible with finite content service time. To address 
this design while not requiring information on historical content access
or content popularity profile, we employ the Lyapunov optimization 
method [a] for which the short-term max-weight problem derived from the
Lyapunov drift must be optimized in the slot-by-slot basis. Because the
max-weight problem is NP-hard and difficult to tackle [b] due to the 
coupling between CU and BS caching decisions, we propose an 
approximation algorithm which achieves the constant approximation ratio
to the optimal weight by exploiting the submodularity of the 
slot-by-slot objective function and the structure of hierarchical
content caching networks.

+------------------+         +-------+        +--+ End-to-End  +------+
| Original Content |---------| Cloud |--------|BS| Path(case1) | End  |
| Servers          | Backhaul|  Unit | Frount +--+ <==========>|      |
+------------------+         +-------+ haul                    | users|
         |  <=================================================>+------+                                    
Backhaul |                   End-to-End Path(case3)
         |
    +-------+ Frouthaul  +--+             +------+
    | Cloud |----------- |BS| ------------| End  |
	|       |            +--+             | users|
    |  Unit |<===========================>+------+ 
	+-------+     End-to-End Path(case2)

     Figure 1: Network Architecture

2.1  System Model

Fig. 1 illustrates the hierarchical network architecture considered in
the dynamic caching design. We consider a video content set where 
the file size of different contents is assumed to be the same and equal
to s (in bits). Each video content file is assumed to be split into 
multiple chunks, and we assume that a file can be recovered at 
the destination even if not all of the chunks for the file are 
successfully delivered [c]. We assume there are E cloud units (CUs) and
N base stations (BSs) in the system. All contents are saved in their 
own original content servers distributed throughout the internet.
We consider a time-slotted system with equal-size time slots of 
duration Δt and the time slots are indexed as t = 0, 1, ...2.
Moreover, caching control decisions are made in the slot-by slot basis.
In each time slot t, the amount of data from content requested by end 
users associated with BSs and CUs is independent and identically
distributed over time slots.

Chong & Jang             Expires  December 15, 2021             [Page 3]

Internet-Draft      Wireless Cloud Content Caching          October 2020

When content f is requested from an end user, the requested content is 
transmitted from its closest caching location among the associated BS, 
CU and original content server which has the corresponding content 
placed by a deployed caching strategy. Hereafter, we call this closest 
network node as a source node of content f. Hence, the end-to-end path 
of content f could vary as the choice of the source node changes.
(Figure 1.)

To capture the dynamics of content requests, services, and the 
corresponding content service time, we introduce virtual queues for 
each BS where the virtual queue backlog for content f, 
i.e., Q_f(t), evolves over time as follows:

           Q_f(t+1) = [Q_f(t) - r_f(t) + A_f(t)]^+ ,

for every CU and associated BS, content(f), where [x]^+ = max(x,0).
In the above, we define A_f(t) and r_f(t) as the amount of data 
from content f requested by end users associated with BSs and the 
amount of served data of content f at BSs, respectively. 
The amount of served data r_f(t) from each virtual queue during time slot
t depends on the caching decision, i.e., to cache content f at CU or BS.
The average virtual queue backlog of content f indirectly captures the
average end-to-end latency of content f.


2.2.  Hybrid Content Caching Design

The hybrid content caching algorithm should (i) achieve low average 
end-to-end latency by stabilizing virtual queues if the content request 
rate vector is within the capacity region and (ii) support as high 
average content request rates as possible. For any content request rate
vector inside the capacity region,all virtual queues must be stable, 
i.e., supremum of the following value

         t-1
   (1/r)* Σ {expectation of sum of Q_f(r) w.r.t every f, BS and CU}
         r=0

should be bounded as t goes to infinity.
To develop such a caching algorithm, we could employ the Lyapunov
optimization method [a]. Toward this end, we define Lyapunov function
and Lyapunov drift function w.r.t. Q_f(t) and derive an upper bound of 
the Lyapunov drift function using the queueing dynamics of the virtual 
queues. Then the content caching algorithm can be developed by 
minimizing the upper bound of the Lyapunov drift function in each time
slot.


Chong & Jang             Expires  December 15, 2021             [Page 4]

Internet-Draft      Wireless Cloud Content Caching          October 2020

3.  IANA Considerations

There are no IANA considerations related to this document.

4.  Security Considerations

There are no security considerations related to this document.

5.  References

5.1.  Normative References


   [a]  M. Neely, “Stochastic network optimization with application to 
        communication and queueing systems,” Synthesis Lectures on 
		Communication Networks, pp. 1–211, 2010.

   [b]  R. Hemmecke, M. Koppe, J. Lee, and R. Weismantel, 50 Years of 
        Integer Programming 1958-2008. Springer, 2009.

   [c]  F. Pantisano, M. Bennis, W. Saad, and M. Debbah, “Match to Cache
        :Joint user association and backhaul allocation in cache-aware 
		small cell networks,” in Proc. of IEEE ICC, London, UK, Jun. 
		2015, pp. 3082–3087.


5.2.  Informative References

Acknowledgements

This work was supported by Institute for Information & communications
Technology Promotion(IITP) grant funded by the Korea government(MSIT)
(No.2015-0-00557, Resilient/Fault-Tolerant Autonomic Networking Based
on Physicality, Relationship and Service Semantic of IoT Devices)


Chong & Jang             Expires  December 15, 2021             [Page 5]

Internet-Draft      Wireless Cloud Content Caching          October 2020

Authors' Addresses

Song Chong
The Graduate School of Artificial Intelligence, 
Korea Advanced Institute of Science and Technology(KAIST)
Daejeon, South Korea
Phone: +82 (0)42 350 3473
Email: songchong@kaist.edu

Hyeonjoon Jang
Electrical Engineering Department, 
Korea Advanced Institute of Science and Technology(KAIST)
Daejeon, South Korea
Phone: +82 (0)42 350 5473
Email: thefelix@kaist.ac.kr

Sewoong Lee
Electrical Engineering Department, 
Korea Advanced Institute of Science and Technology(KAIST)
Daejeon, South Korea
Phone: +82 (0)42 350 5473
Email: dltpdnd21@kaist.ac.kr


Chong & Jang             Expires  December 15, 2021             [Page 6]