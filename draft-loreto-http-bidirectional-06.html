<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en"><head><title>Known Issues and Best Practices for the Use of Long Polling and Streaming in Bidirectional HTTP</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="description" content="Known Issues and Best Practices for the Use of Long Polling and Streaming in Bidirectional HTTP">
<meta name="keywords" content="I-D, Internet-Draft, HTTP, HTTP Streaming, Long Polling">
<meta name="generator" content="xml2rfc v1.35 (http://xml.resource.org/)">
<meta name="viewport" content="width=600;" />
<style type='text/css'><!--
        body {
                font-family: verdana, charcoal, helvetica, arial, sans-serif;
                font-size: 85%;
		max-width: 60em; 
		color: #000; background-color: #FFF;
                margin: 2em;
        }
        h1, h2, h3, h4, h5, h6 {
                font-family: helvetica, monaco, "MS Sans Serif", arial, sans-serif;
                font-weight: bold; font-style: normal;
        }
        h1 { color: #900; background-color: transparent; text-align: right; }
        h3 { color: #333; background-color: transparent; }

        td.RFCbug {
                font-size: x-small; text-decoration: none;
                width: 30px; height: 30px; padding-top: 2px;
                text-align: justify; vertical-align: middle;
                background-color: #000;
        }
        td.RFCbug span.RFC {
                font-family: monaco, charcoal, geneva, "MS Sans Serif", helvetica, verdana, sans-serif;
                font-weight: bold; color: #666;
        }
        td.RFCbug span.hotText {
                font-family: charcoal, monaco, geneva, "MS Sans Serif", helvetica, verdana, sans-serif;
                font-weight: normal; text-align: center; color: #FFF;
        }

        table.TOCbug { width: 30px; height: 15px; }
        td.TOCbug {
                text-align: center; width: 30px; height: 15px;
                color: #FFF; background-color: #900;
        }
        td.TOCbug a {
                font-family: monaco, charcoal, geneva, "MS Sans Serif", helvetica, sans-serif;
                font-weight: bold; font-size: x-small; text-decoration: none;
                color: #FFF; background-color: transparent;
        }

        td.header {
                font-family: arial, helvetica, sans-serif; font-size: x-small;
                vertical-align: top; width: 33%;
                color: #FFF; background-color: #666;
        }
        td.author { font-weight: bold; font-size: x-small; margin-left: 4em; }
        td.author-text { font-size: x-small; }

        /* info code from SantaKlauss at http://www.madaboutstyle.com/tooltip2.html */
        a.info {
                /* This is the key. */
                position: relative;
                z-index: 24;
                text-decoration: none;
        }
        a.info:hover {
                z-index: 25;
                color: #FFF; background-color: #900;
        }
        a.info span { display: none; }
        a.info:hover span.info {
                /* The span will display just on :hover state. */
                display: block;
                position: absolute;
                font-size: smaller;
                top: 2em; left: -5em; width: 15em;
                padding: 2px; border: 1px solid #333;
                color: #900; background-color: #EEE;
                text-align: left;
        }

        a { font-weight: bold; }
        a:link    { color: #900; background-color: transparent; }
        a:visited { color: #633; background-color: transparent; }
        a:active  { color: #633; background-color: transparent; }

        p { margin-left: 2em; margin-right: 2em; }
        p.copyright { font-size: x-small; }
        p.toc { font-size: 85%;
		max-width: 60em; 
		font-weight: bold; margin-left: 3em; }
        table.toc { margin: 0 0 0 3em; padding: 0; border: 0; vertical-align: text-top; }
        td.toc { font-size: 85%;
		max-width: 60em; 
		font-weight: bold; vertical-align: text-top; }

        ol.text { margin-left: 2em; margin-right: 2em; }
        ul.text { margin-left: 2em; margin-right: 2em; }
        li      { margin-left: 3em; }

        /* RFC-2629 <spanx>s and <artwork>s. */
        em     { font-style: italic; }
        strong { font-weight: bold; }
        dfn    { font-weight: bold; font-style: normal; }
        cite   { font-weight: normal; font-style: normal; }
        tt     { color: #036; }
        tt, pre, pre dfn, pre em, pre cite, pre span {
                font-family: "Courier New", Courier, monospace; font-size: small;
        }
        pre {
                text-align: left; padding: 4px;
                color: #000; background-color: #CCC;
        }
        pre dfn  { color: #900; }
        pre em   { color: #66F; background-color: #FFC; font-weight: normal; }
        pre .key { color: #33C; font-weight: bold; }
        pre .id  { color: #900; }
        pre .str { color: #000; background-color: #CFF; }
        pre .val { color: #066; }
        pre .rep { color: #909; }
        pre .oth { color: #000; background-color: #FCF; }
        pre .err { background-color: #FCC; }

        /* RFC-2629 <texttable>s. */
        table.all, table.full, table.headers, table.none {
                font-size: 85%;
		max-width: 60em; 
		text-align: center; border-width: 2px;
                vertical-align: top; border-collapse: collapse;
        }
        table.all, table.full { border-style: solid; border-color: black; }
        table.headers, table.none { border-style: none; }
        th {
                font-weight: bold; border-color: black;
                border-width: 2px 2px 3px 2px;
        }
        table.all th, table.full th { border-style: solid; }
        table.headers th { border-style: none none solid none; }
        table.none th { border-style: none; }
        table.all td {
                border-style: solid; border-color: #333;
                border-width: 1px 2px;
        }
        table.full td, table.headers td, table.none td { border-style: none; }

        hr { height: 1px; }
        hr.insert {
                width: 80%; border-style: none; border-width: 0;
                color: #CCC; background-color: #CCC;
        }
--></style>
</head>
<body>
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<table summary="layout" width="66%" border="0" cellpadding="0" cellspacing="0"><tr><td><table summary="layout" width="100%" border="0" cellpadding="2" cellspacing="1">
<tr><td class="header">Network Working Group</td><td class="header">S. Loreto</td></tr>
<tr><td class="header">Internet-Draft</td><td class="header">Ericsson</td></tr>
<tr><td class="header">Intended status: Informational</td><td class="header">P. Saint-Andre</td></tr>
<tr><td class="header">Expires: July 7, 2011</td><td class="header">Cisco</td></tr>
<tr><td class="header">&nbsp;</td><td class="header">S. Salsano</td></tr>
<tr><td class="header">&nbsp;</td><td class="header">Univ.  of Rome "Tor Vergata"</td></tr>
<tr><td class="header">&nbsp;</td><td class="header">G. Wilkins</td></tr>
<tr><td class="header">&nbsp;</td><td class="header">Webtide</td></tr>
<tr><td class="header">&nbsp;</td><td class="header">January 3, 2011</td></tr>
</table></td></tr></table>
<h1><br />Known Issues and Best Practices for the Use of Long Polling and Streaming in Bidirectional HTTP<br />draft-loreto-http-bidirectional-06</h1>

<h3>Abstract</h3>

<p>On today's Internet, the Hypertext Transfer Protocol (HTTP) is often used (some would say abused) to enable asynchronous, "server-initiated" communication from a server to a client as well as from a client to a server.  This document describes known issues and best practices related to such "bidirectional HTTP" applications, focusing on the two most common mechanisms: "HTTP long polling" and "HTTP streaming".
</p>
<h3>Status of this Memo</h3>
<p>
This Internet-Draft is submitted  in full
conformance with the provisions of BCP&nbsp;78 and BCP&nbsp;79.</p>
<p>
Internet-Drafts are working documents of the Internet Engineering
Task Force (IETF).  Note that other groups may also distribute
working documents as Internet-Drafts.  The list of current
Internet-Drafts is at http://datatracker.ietf.org/drafts/current/.</p>
<p>
Internet-Drafts are draft documents valid for a maximum of six months
and may be updated, replaced, or obsoleted by other documents at any time.
It is inappropriate to use Internet-Drafts as reference material or to cite
them other than as &ldquo;work in progress.&rdquo;</p>
<p>
This Internet-Draft will expire on July 7, 2011.</p>

<h3>Copyright Notice</h3>
<p>
Copyright (c) 2011 IETF Trust and the persons identified as the
document authors.  All rights reserved.</p>
<p>
This document is subject to BCP 78 and the IETF Trust's Legal
Provisions Relating to IETF Documents
(http://trustee.ietf.org/license-info) in effect on the date of
publication of this document.  Please review these documents
carefully, as they describe your rights and restrictions with respect
to this document. Code Components extracted from this document must
include Simplified BSD License text as described in Section 4.e of
the Trust Legal Provisions and are provided without warranty as
described in the Simplified BSD License.</p>
<a name="toc"></a><br /><hr />
<h3>Table of Contents</h3>
<p class="toc">
<a href="#intro">1.</a>&nbsp;
Introduction<br />
<a href="#polling">2.</a>&nbsp;
HTTP Long Polling<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#polling-definition">2.1.</a>&nbsp;
Definition<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#polling-issues">2.2.</a>&nbsp;
HTTP Long Polling Issues<br />
<a href="#streaming">3.</a>&nbsp;
HTTP Streaming<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#streaming-definition">3.1.</a>&nbsp;
Definition<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#streaming-issues">3.2.</a>&nbsp;
HTTP Streaming Issues<br />
<a href="#tech">4.</a>&nbsp;
Overview of Technologies<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#bayeux">4.1.</a>&nbsp;
Bayeux<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#bosh">4.2.</a>&nbsp;
BOSH<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#server-sent-events">4.3.</a>&nbsp;
Server-Sent Events<br />
<a href="#practices">5.</a>&nbsp;
HTTP Best Practices<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#connectionlimit">5.1.</a>&nbsp;
Limits to the Maximum Number of Connections<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#pipelining">5.2.</a>&nbsp;
Pipelined Connections<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#proxies">5.3.</a>&nbsp;
Proxies<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#responses">5.4.</a>&nbsp;
HTTP Responses<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#timeouts">5.5.</a>&nbsp;
Timeouts<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#network">5.6.</a>&nbsp;
Impact on Intermediary Entities<br />
<a href="#anchor1">6.</a>&nbsp;
Acknowledgments<br />
<a href="#iana">7.</a>&nbsp;
IANA Considerations<br />
<a href="#security">8.</a>&nbsp;
Security Considerations<br />
<a href="#rfc.references1">9.</a>&nbsp;
References<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#rfc.references1">9.1.</a>&nbsp;
Normative References<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#rfc.references2">9.2.</a>&nbsp;
Informative References<br />
<a href="#rfc.authors">&#167;</a>&nbsp;
Authors' Addresses<br />
</p>
<br clear="all" />

<a name="intro"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.1"></a><h3>1.&nbsp;
Introduction</h3>

<p>The Hypertext Transfer Protocol <a class='info' href='#RFC2616'>[RFC2616]<span> (</span><span class='info'>Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter, L., Leach, P., and T. Berners-Lee, &ldquo;Hypertext Transfer Protocol -- HTTP/1.1,&rdquo; June&nbsp;1999.</span><span>)</span></a> is a request/response protocol.  HTTP defines the following entities: clients, proxies, and servers.  A client establishes connections to a server for the purpose of sending HTTP requests.  A server accepts connections from clients in order to service HTTP requests by sending back responses.  Proxies are intermediate entities that can be involved in the delivery of requests and responses from the client to the server and vice versa.
</p>
<p>In the standard HTTP model, a server cannot initiate a connection with a client nor send an unrequested HTTP response to the client; thus the server cannot push asynchronous events to clients.  Therefore, in order to receive asynchronous events as soon as possible, the client needs to poll the server periodically for new content.  However, continual polling can consume significant bandwidth by forcing a request/response round trip when no data is available.  It can also be inefficient because it reduces the responsiveness of the application since data is queued until the server receives the next poll request from the client.
</p>
<p>In order to improve this situation, several server push programming mechanisms have been implemented in recent years.  These mechanisms, which are often grouped under the common label "Comet" <a class='info' href='#COMET'>[COMET]<span> (</span><span class='info'>Russell, A., &ldquo;Comet: Low Latency Data for the Browser,&rdquo; March&nbsp;2006.</span><span>)</span></a>, enable a web server to send updates to clients without waiting for a poll request from the client.  Such mechanisms can deliver updates to clients in a more timely manner while avoiding the latency experienced by client applications due to the frequent opening and closing of connections necessary to periodically poll for data.
</p>
<p>The two most common server push mechanisms are "HTTP long polling" and "HTTP streaming":
</p>
<p>
        </p>
<blockquote class="text"><dl>
<dt>HTTP Long Polling:</dt>
<dd> The server attempts to "hold open" (not immediately reply to) each HTTP request, responding only when there are events to deliver.  In this way, there is always a pending request to which the server can reply for the purpose of delivering events as they occur, thereby minimizing the latency in message delivery.
</dd>
<dt>HTTP Streaming:</dt>
<dd> The server keeps a request open indefinitely; that is, it never terminates the request or closes the connection, even after it pushes data to the client.
</dd>
</dl></blockquote><p>
      
</p>
<p>It is possible to define other technologies for bidirectional HTTP, however such technologies typically require changes to HTTP itself (e.g., by defining new HTTP methods).  This document focuses only on bidirectional HTTP technologies that work within the current scope of HTTP as defined in <a class='info' href='#RFC2616'>[RFC2616]<span> (</span><span class='info'>Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter, L., Leach, P., and T. Berners-Lee, &ldquo;Hypertext Transfer Protocol -- HTTP/1.1,&rdquo; June&nbsp;1999.</span><span>)</span></a> (HTTP 1.1) and <a class='info' href='#RFC1945'>[RFC1945]<span> (</span><span class='info'>Berners-Lee, T., Fielding, R., and H. Nielsen, &ldquo;Hypertext Transfer Protocol -- HTTP/1.0,&rdquo; May&nbsp;1996.</span><span>)</span></a> (HTTP 1.0).
</p>
<p>The authors acknowledge that both "HTTP long polling" and "HTTP streaming" stretch the original semantic of HTTP and that the HTTP protocol was not designed for bidirectional communication.  This document does not attempt to obsolete such usages, only to identify issues and recommend best pratices when such usages are deployed.
</p>
<p>The remainder of this document is organized as follows.  <a class='info' href='#polling'>Section&nbsp;2<span> (</span><span class='info'>HTTP Long Polling</span><span>)</span></a> analyzes the "HTTP long polling" technique.  <a class='info' href='#streaming'>Section&nbsp;3<span> (</span><span class='info'>HTTP Streaming</span><span>)</span></a> analyzes the "HTTP streaming" technique.  <a class='info' href='#tech'>Section&nbsp;4<span> (</span><span class='info'>Overview of Technologies</span><span>)</span></a> provides an overview of the specific technologies that use server-push technique.  <a class='info' href='#practices'>Section&nbsp;5<span> (</span><span class='info'>HTTP Best Practices</span><span>)</span></a> lists best practices for bidirectional HTTP using existing technologies.
</p>
<a name="polling"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.2"></a><h3>2.&nbsp;
HTTP Long Polling</h3>

<a name="polling-definition"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.2.1"></a><h3>2.1.&nbsp;
Definition</h3>

<p>With the traditional or "short" polling technique, a client sends regular requests to the server and each request attempts to "pull" any available events or data.  If there are no events or data available, the server returns an empty response and the client waits for some time before sending another poll request.  The polling frequency depends on the latency that the client can tolerate in retrieving updated information from the server.  This mechanism has the drawback that the consumed resources (server processing and network) strongly depend on the acceptable latency in the delivery of updates from server to client.  If the acceptable latency is low (e.g., on the order of seconds) then the polling frequency can cause an unacceptable burden on the server, the network, or both.
</p>
<p>By contrast with such "short polling", "long polling" attempts to minimize both latency in server-client message delivery and the use of processing/network resources.  The server achieves these efficiencies by responding to a request only when a particular event, status, or timeout has occurred.  Once the server sends a long poll response, typically the client immediately sends a new long poll request.  Effectively this means that at any given time the server will be holding open a long poll request, to which it replies when new information is available for the client.  As a result, the server is able to asynchronously "initiate" communication.
</p>
<p>The basic life cycle of an application using "HTTP long polling" is as follows:
</p>
<p>
          </p>
<ol class="text">
<li>The client makes an initial request and then waits for a response.
</li>
<li>The server defers its response until an update is available, or until a particular status or timeout has occurred.
</li>
<li>When an update is available, the server sends a complete response to the client.
</li>
<li>The client typically sends a new long poll request, either immediately upon receiving a response or after a pause to allow an acceptable latency period.
</li>
</ol><p>
         
</p>
<p>The HTTP long polling mechanism can be applied to either persistent or non-persistent HTTP connections.  The use of persistent HTTP connections will avoid the additional overhead of establishing a new TCP/IP connection <a class='info' href='#TCP'>[TCP]<span> (</span><span class='info'>Postel, J., &ldquo;Transmission Control Protocol,&rdquo; September&nbsp;1981.</span><span>)</span></a> for every long poll request.
</p>
<a name="polling-issues"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.2.2"></a><h3>2.2.&nbsp;
HTTP Long Polling Issues</h3>

<p>The HTTP long polling mechanism introduces the following issues.
</p>
<p>
           </p>
<blockquote class="text"><dl>
<dt>Header Overhead:</dt>
<dd>With the HTTP long polling technique, every long poll request and long poll response is a complete HTTP message and thus contains a full set of HTTP headers in the message framing.  For small, infrequent messages, the headers can represent a large percentage of the data transmitted.  If the network MTU (Maximum Transmission Unit) allows all the information (including the HTTP header) to fit within a single IP packet, this typically does not represent a significant increase in the burden for networking entities.  On the other hand, the amount of transferred data can be significantly larger than the real payload carried by HTTP and this can have a significant impact (e.g., when volume-based charging is in place).
</dd>
<dt>Maximal Latency:</dt>
<dd>After a long polling response is sent to a client, the server needs to wait for the next long polling request before another message can be sent to the client.  This means that while the average latency of long polling is close to one network transit, the maximal latency is over three network transits (long poll response, next long poll request, long poll response).  However, because HTTP is carried over TCP/IP, packet loss and retransmission can occur; therefore maximal latency for any TCP/IP protocol will be more than three network transits (lost packet, next packet, negative ack, retransmit).  When HTTP pipelining (see <a class='info' href='#pipelining'>Section&nbsp;5.2<span> (</span><span class='info'>Pipelined Connections</span><span>)</span></a>) is available, the latency due to the server waiting for a new request can be avoided.
</dd>
<dt>Connection Establishment:</dt>
<dd>A common criticism of both short polling and long polling is that these mechanisms frequently open TCP/IP connections and then close them.  However, both polling mechanisms work well with persistent HTTP connections that can be reused for many poll requests.  Specifically, the short duration of the pause between a long poll response and the next long poll request avoids the closing of idle connections.
</dd>
<dt>Allocated Resources:</dt>
<dd>Operating systems will allocate resources to TCP/IP connections and to HTTP requests outstanding on those connections.  The HTTP long polling mechanism requires that for each client, both a TCP/IP connection and an HTTP request are held open.  Thus it is important to consider the resources related to both of these when sizing an HTTP long polling application.  Typically the resources used per TCP/IP connection are minimal and can scale reasonably.  Frequently the resources allocated to HTTP requests can be significant, and scaling the total number of requests outstanding can be limited on some gateways, proxies, and servers.
</dd>
<dt>Graceful Degradation:</dt>
<dd>A long polling client or server that is under load has a natural tendency to gracefully degrade in performance at a cost of message latency.  If load causes either a client or server to run slowly, then events to be pushed to the client will queue (waiting either for the client to send a long poll request or for the server to free up CPU that can be used to process a long poll request that is being held at the server).  If multiple messages are queued for a client, they might be delivered in a batch within a single long poll response.  This can significantly reduce the per-message overhead and thus ease the work load of the client or server for the given message load.
</dd>
<dt>Timeouts:</dt>
<dd>Long polling requests need to remain pending or "hanging" until the server has something to send to the client.  The timeout issues related to these pending requests are discussed under <a class='info' href='#timeouts'>Section&nbsp;5.5<span> (</span><span class='info'>Timeouts</span><span>)</span></a>.
</dd>
<dt>Caching:</dt>
<dd>Caching mechanisms implemented by intermediate entities can interfere with long polling requests.  This issue is discussed under <a class='info' href='#network'>Section&nbsp;5.6<span> (</span><span class='info'>Impact on Intermediary Entities</span><span>)</span></a>.
</dd>
</dl></blockquote><p>
         
</p>
<a name="streaming"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.3"></a><h3>3.&nbsp;
HTTP Streaming</h3>

<a name="streaming-definition"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.3.1"></a><h3>3.1.&nbsp;
Definition</h3>

<p>The "HTTP streaming" mechanism keeps a request open indefinitely.  It never terminates the request or closes the connection, even after the server pushes data to the client.  This mechanism significantly reduces the network latency because the client and the server do not need to open and close the connection.
</p>
<p>The basic life cycle of an application using "HTTP streaming" is as follows:
</p>
<p>
           </p>
<ol class="text">
<li>The client makes an initial request and then waits for a response.
</li>
<li>The server defers the response to a poll request until an update is available, or until a particular status or timeout has occurred.
</li>
<li>Whenever an update is available, the server sends it back to the client as a part of the response.
</li>
<li>The data sent by the server does not terminate the request or the connection.  The server returns to step 3.
</li>
</ol><p>
         
</p>
<p>The HTTP streaming mechanism is based on the capability of the server to send several pieces of information on the same response, without terminating the request or the connection.  This result can be achieved by both HTTP/1.1 and HTTP/1.0 servers.
</p>
<p>An HTTP response content length can be defined using 3 options:
</p>
<p>
           </p>
<blockquote class="text"><dl>
<dt>Content-Length header:</dt>
<dd>This indicates the size of the entity body in the message, in bytes.
</dd>
<dt>Transfer-Encoding header:</dt>
<dd>The 'chunked' valued in this header indicates the message will break into chunks of known size if needed.
</dd>
<dt>End of File (EOF):</dt>
<dd>This is actually the default approach for HTTP/1.0 where the connections are not persistent.  Clients do not need to know the size of the body they are reading; instead they expect to read the body until the server closes the connection.  Although with HTTP/1.1 the default is for persistent connections, it is still possible to use EOF by setting the 'Connection:close' header in either the request or the response, to indicate that the connection is not to be considered 'persistent' after the current request/response is complete.  The client's inclusion of the 'Connection: close' header field in the request will also prevent pipelining.
</dd>
<dt></dt>
<dd>The main issue with EOF is that it is difficult to tell the difference between a connection terminated by a fault and one that is correctly terminated.
</dd>
</dl></blockquote><p>
         
</p>
<p>An HTTP/1.0 server can use only EOF as a streaming mechanism.  By contrast, both EOF and "chunked transfer" are available to an HTTP/1.1 server.
</p>
<p>The "chunked transfer" mechanism is the one typically used by HTTP/1.1 servers for streaming.  This is accomplished by including the header "Transfer-Encoding: chunked" at the beginning of the response, which enables it to send the following parts of the response in different "chunks" over the same connection.  Each chunk starts with the hexadecimal expression of the length of its data, followed by CR/LF (the end of the response is indicated with a chunk of size 0).
</p><br /><hr class="insert" />
<a name="notifier"></a>
<div style='display: table; width: 0; margin-left: 3em; margin-right: auto'><pre>
        HTTP/1.1 200 OK
        Content-Type: text/plain
        Transfer-Encoding: chunked

        25
        This is the data in the first chunk

        1C
        and this is the second one

        0
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Figure&nbsp;1: Transfer-Encoding response&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<p>An HTTP/1.0 server will omit the Content-Length header in the response to achieve the same result, so it will be able to send the subsequent parts of the response on the same connection (in this case the different parts of the response are not explicitly separated by HTTP protocol, and the end of the response is achieved by closing the connection).
</p>
<a name="streaming-issues"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.3.2"></a><h3>3.2.&nbsp;
HTTP Streaming Issues</h3>

<p>The HTTP streaming mechanism introduces the following issues.
</p>
<p>
           </p>
<blockquote class="text"><dl>
<dt>Network Intermediaries:</dt>
<dd>The HTTP protocol allows for intermediaries (proxies, transparent proxies, gateways, etc.) to be involved in the transmission of a response from the server to the client.  There is no requirement for an intermediary to immediately forward a partial response and it is legal for it to buffer the entire response before sending any data to the client (e.g., caching transparent proxies).  HTTP streaming will not work with such intermediaries.
</dd>
<dt>Maximal Latency:</dt>
<dd>Theoretically, on a perfect network, an HTTP streaming protocol's average and maximal latency is one network transit.  However, in practice the maximal latency is higher due to network and browser limitations.  The browser techniques used to terminate HTTP streaming connections are often associated with JavaScript and/or DOM (Document Object Model) elements that will grow in size for every message received.  Thus in order to avoid unlimited memory growth in the client, an HTTP streaming implementation occasionally needs to terminate the streaming response and send a request to initiate a new streaming response (which is essentially equivalent to a long poll).  Thus the maximal latency is at least three network transits.  Also, because HTTP is carried over TCP/IP, packet loss and retransmission can occur; therefore maximal latency for any TCP/IP protocol will be more than three network transits (lost packet, next packet, negative ack, retransmit).
</dd>
<dt>Client Buffering:</dt>
<dd>There is no requirement in existing HTTP specifications for a client library to make the data from a partial HTTP response available to the client application.  For example, if each response chunk contains a statement of JavaScript, there is no requirement in the browser to execute that JavaScript before the entire response is received.   However, in practice most browsers do execute JavaScript received in partial responses, although some require a buffer overflow to trigger execution; in most implementations, blocks of white space can be sent to achieve buffer overflow.
</dd>
<dt>Framing Techniques:</dt>
<dd>Using HTTP streaming, several application messages can be sent within a single HTTP response.  The separation of the response stream into application messages needs to be perfomed at the application level and not at the HTTP level.  In particular it is not possible to use the HTTP chunks as application message delimiters, since intermediate proxies might "re-chunk" the message stream (for example by combining different chunks into a longer one).  This issue does not affect the HTTP long polling technique, which provides a canonical framing technique: each application message can be sent in a different HTTP response.
</dd>
</dl></blockquote><p>
         
</p>
<a name="tech"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.4"></a><h3>4.&nbsp;
Overview of Technologies</h3>

<p>This section provides an overview of existing technologies that implement HTTP-based server-push mechanisms to asynchronously deliver messages from the server to the client.
</p>
<a name="bayeux"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.4.1"></a><h3>4.1.&nbsp;
Bayeux</h3>

<p>The Bayeux protocol <a class='info' href='#BAYEUX'>[BAYEUX]<span> (</span><span class='info'>Russell, A., Wilkins, G., Davis, D., and M. Nesbitt, &ldquo;Bayeux Protocol -- Bayeux 1.0.0,&rdquo; 2007.</span><span>)</span></a> was developed in 2006-2007 by the Dojo Foundation.  Bayeux can use both the HTTP long polling and HTTP streaming mechanisms.
</p>
<p>In order to achieve bidirectional communications, a Bayeux client will use two HTTP connections to a Bayeux server so that both server-to-client and client-to-server messaging can occur asynchronously.
</p>
<p>The Bayeux specification requires that implementations control pipeling of HTTP requests, so that requests are not pipelined inappropriately (e.g., a client-to-server message pipelined behind a long poll request).
</p>
<p>In practice, for JavaScript clients, such control over pipelining is not possible in current browsers.  Therefore JavaScript implementations of Bayeux attempt to meet this requirement by limiting themselves to a maximum of two outstanding HTTP requests at any one time, so that browser connection limits will not be applied and the requests will not be queued or pipelined.  While broadly effective, this mechanism can be disrupted by non-Bayeux JavaScript simultaneously issuing requests to the same host.
</p>
<p>Bayeux connections are negotiated between client and server with handshake messages that allow the connection type, authentication method, and other parameters to be agreed upon between the client and the server.  Furthermore, during the handshake phase, the client and the server reveal to each other their acceptable bidirectional techniques and the client selects one from the intersection of those sets.
</p>
<p>For non-browser or same-domain Bayeux, clients use HTTP POST requests to the server for both the long poll request and the request to send messages to the server.  The Bayeux protocol packets are sent as the body of the HTTP messages using the "application/json" Internet media type <a class='info' href='#RFC4627'>[RFC4627]<span> (</span><span class='info'>Crockford, D., &ldquo;The application/json Media Type for JavaScript Object Notation (JSON),&rdquo; July&nbsp;2006.</span><span>)</span></a>.
</p>
<p>For browsers that are operating in cross-domain mode, Bayeux attempts to use Cross-Origin Resource Sharing <a class='info' href='#CORS'>[CORS]<span> (</span><span class='info'>van Kesteren, A., &ldquo;Cross-Origin Resource Sharing,&rdquo; July&nbsp;2010.</span><span>)</span></a> checking if the browser and server support it, so that normal HTTP POST requests can be used.  If this mechanism fails, Bayeux clients use the "JSONP" mechanism as described in <a class='info' href='#JSONP'>[JSONP]<span> (</span><span class='info'>, &ldquo;JSON with padding,&rdquo; .</span><span>)</span></a>.  In this last case, client-to-server messages are sent as encoded JSON on the URL query parameters and server-to-client messages are sent as a JavaScript program that wraps the message JSON with a JavaScript function call to the already loaded Bayeux implementation.
</p>
<a name="bosh"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.4.2"></a><h3>4.2.&nbsp;
BOSH</h3>

<p>BOSH, which stands for Bidirectional-streams Over Synchronous HTTP <a class='info' href='#BOSH'>[BOSH]<span> (</span><span class='info'>Paterson, I., Smith, D., and P. Saint-Andre, &ldquo;Bidirectional-streams Over Synchronous HTTP (BOSH),&rdquo; February&nbsp;2007.</span><span>)</span></a>, was developed by the XMPP Standards Foundation in 2003-2004.  The purpose of BOSH is to emulate normal TCP connections over HTTP (TCP is the standard connection mechanism used in the Extensible Messaging and Presence Protocol as described in <a class='info' href='#XMPP'>[XMPP]<span> (</span><span class='info'>Saint-Andre, P., &ldquo;Extensible Messaging and Presence Protocol (XMPP): Core,&rdquo; December&nbsp;2010.</span><span>)</span></a>).  BOSH employs the HTTP long polling mechanism by allowing the server (called a "BOSH connection manager") to defer its response to a request until it actually has data to send to the client from the application server itself (typically an XMPP server).  As soon as the client receives a response from the connection manager, it sends another request to the connection manager, thereby ensuring that the connection manager is (almost) always holding a request that it can use to "push" data to the client.
</p>
<p>In some situations, the client needs to send data to the server while it is waiting for data to be pushed from the connection manager.  To prevent data from being pipelined behind the long poll request that is on hold, the client can send its outbound data in a second HTTP request over a second TCP connection.  BOSH forces the server to respond to the request it has been holding on the first connection as soon as it receives a new request from the client, even if it has no data to send to the client.  It does so to make sure that the client can send more data immediately if necessary even in the case where the client is not able to pipeline the requests, respecting at the same time the two-connection limit discussed under <a class='info' href='#connectionlimit'>Section&nbsp;5.1<span> (</span><span class='info'>Limits to the Maximum Number of Connections</span><span>)</span></a>.
</p>
<p>The number of long polling request-response pairs is negotiated during the first request sent from the client to the connection manager.  Typically BOSH clients and connection managers will negotiate the use of two pairs, although it is possible to use only one pair or to use more than two pairs.
</p>
<p>The roles of the two request-response pairs typically switch whenever the client sends data to the connection manager.  This means that when the client issues a new request, the connection manager immediately answers the blocked request on the other TCP connection, thus freeing it; in this way, in a scenario where only the client sends data, all the even requests are sent over one connection and the odd ones are sent over the other connection.
</p>
<p>BOSH is able to work reliably both when network conditions force every HTTP request to be made over a different TCP connection and when it is possible to use HTTP/1.1 and then relay on two persistent TCP connections.
</p>
<p>If the connection manager has no data to send to the client for an agreed amount of time (also negotiated during the first request), then the connection manager will respond to the request it has been holding with no data, and that response immediately triggers a fresh client request.  The connection manager does so to ensure that if a network connection is broken then both parties will realise that fact within a reasonable amount of time.
</p>
<p>Moreover BOSH defines the negotiation of an "inactivity period" value that specifies the longest allowable inactivity period (in seconds).  This enables the client to ensure that the periods with no requests pending are never too long.
</p>
<p>BOSH allows data to be pushed immediately when HTTP Pipelining is available.  However if HTTP Pipelining is not available and one of the endpoints has just pushed some data, BOSH will usually need to wait for a network round trip time until the server is able to again push data to the client.
</p>
<p>BOSH uses standard HTTP POST request and response bodies to encode all information.
</p>
<p>BOSH normally uses HTTP Pipelining over a persistent HTTP/1.1 connection.  However, a client can deliver its POST requests in any way permitted by HTTP 1.0 or HTTP 1.1.  (Although the use of HTTP POST with pipelining is discouraged in RFC 2616, BOSH employs various methods (such as request identifiers) to ensure that this usage does not lead to indeterminate results if the transport connection is terminated prematurely.)
</p>
<p>BOSH clients and connection managers are not allowed to use Chunked Transfer Coding, since intermediaries might buffer each partial HTTP request or response and only forward the full request or response once it is available.
</p>
<p>BOSH allows the usage of the Accept-Encoding and Content-Encoding headers in the request and in the response respectively, and then compresses the response body accordingly.
</p>
<p>Each BOSH session can share the HTTP connection(s) it uses with other HTTP traffic, including other BOSH sessions and HTTP requests and responses completely unrelated to the BOSH protocol (e.g., web page downloads).
</p>
<a name="server-sent-events"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.4.3"></a><h3>4.3.&nbsp;
Server-Sent Events</h3>

<p>W3C Server-Sent Events specification <a class='info' href='#WD-eventsource'>[WD&#8209;eventsource]<span> (</span><span class='info'>Hickson, I., &ldquo;Server-Sent Events,&rdquo; December&nbsp;2009.</span><span>)</span></a> defines an API that enables servers to push data to Web pages over HTTP in the form of DOM events.
</p>
<p>The data is encoded as text/event-stream content and pushed using an HTTP streaming mechanism, but the specification suggests to disable HTTP chunking for serving event streams unless the rate of messages is high enough to avoid the possible negative effects of this technique as described under <a class='info' href='#streaming-issues'>Section&nbsp;3.2<span> (</span><span class='info'>HTTP Streaming Issues</span><span>)</span></a>.
</p>
<p>However it is not clear if there are significant benefits of using EOF rather than chunking with regards to intermediaries, unless they support only HTTP/1.0.
</p>
<a name="practices"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.5"></a><h3>5.&nbsp;
HTTP Best Practices</h3>

<a name="connectionlimit"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.5.1"></a><h3>5.1.&nbsp;
Limits to the Maximum Number of Connections</h3>

<p>HTTP <a class='info' href='#RFC2616'>[RFC2616]<span> (</span><span class='info'>Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter, L., Leach, P., and T. Berners-Lee, &ldquo;Hypertext Transfer Protocol -- HTTP/1.1,&rdquo; June&nbsp;1999.</span><span>)</span></a> section 8.1.4 recommended that a single user client not maintain more than two connections to any server or proxy, in order to prevent the server from being overloaded and to avoid unexpected side effects in congested networks.  This limit was until recently implemented by most commonly deployed browsers, thus making connections a scarce resource that needed to be shared within the browser.  Note that the available JavaScript APIs in the browsers hide the connections and the security model inhibits the sharing of any resource between frames.  The new HTTP specification <a class='info' href='#HTTPBIS'>[HTTPBIS]<span> (</span><span class='info'>Fielding, R., Gettys, J., Mogul, J., Nielsen, H., Masinter, L., Leach, P., Berners-Lee, T., Lafon, Y., and J. Reschke, &ldquo;HTTP/1.1, part 1: URIs, Connections, and Message Parsing,&rdquo; October&nbsp;2010.</span><span>)</span></a> removes the two connection limitation, only encouraging clients to be conservative when opening multiple connections.  In fact, recent browsers have increased this limit to 6 or 8 connections; however, it is still not possible to discover the local limit, and usage of multiple frames and tabs still places 8 connections within easy reach.
</p>
<p>Web applications need to limit the number of long poll requests initiated, ideally to a single long poll that is shared between frames, tabs, or windows of the same browser.  However the security constraints of the browsers make such sharing difficult.
</p>
<p>A best practice for a server is to use cookies <a class='info' href='#COOKIE'>[COOKIE]<span> (</span><span class='info'>Barth, A., &ldquo;HTTP State Management Mechanism,&rdquo; December&nbsp;2010.</span><span>)</span></a> to detect multiple long poll requests from the same browser and to avoid deferring both requests since this might cause connection starvation and/or pipeline issues.
</p>
<a name="pipelining"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.5.2"></a><h3>5.2.&nbsp;
Pipelined Connections</h3>

<p>HTTP <a class='info' href='#RFC2616'>[RFC2616]<span> (</span><span class='info'>Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter, L., Leach, P., and T. Berners-Lee, &ldquo;Hypertext Transfer Protocol -- HTTP/1.1,&rdquo; June&nbsp;1999.</span><span>)</span></a> permits optional request pipelining over persistent connections.  Multiple requests can be enqueued before the responses arrive.
</p>
<p>In the case of HTTP long polling, the use of HTTP pipelining can reduce latency when multiple messages need to be sent by a server to a client in a short period of time.  With HTTP pipelining the server can receive and "enqueue" a set of HTTP requests.  Therefore the server does not need to to receive a new HTTP request from the client after it has sent a message to the client within an HTTP response.  In principle the HTTP pipelining can be applied to HTTP GET and HTTP POST requests, but using HTTP POST request is more critical.  In fact, the use of HTTP POST with pipelining is discouraged in RFC 2616 and needs to be handled with special care.
</p>
<p>There is an issue regarding the inability to control "pipelining".  Normal requests can be pipelined behind a long poll, and are thus delayed until the long poll completes.
</p>
<p>Mechanisms for bidirectional HTTP that want exploit HTTP pipelining need to verify that HTTP pipelining is available (e.g., supported by the client, the intermediaries, and the server); if not they need to fall back to solutions without HTTP pipelining.
</p>
<a name="proxies"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.5.3"></a><h3>5.3.&nbsp;
Proxies</h3>

<p>Most proxies work well with HTTP long polling, because a complete HTTP response will be sent either on an event or a timeout.  Proxies are advised to return that response immediately to the user-agent, which immediately acts on it.
</p>
<p>The HTTP streaming mechanism uses partial responses and sends some JavaScript in an HTTP/1.1 chunk as described under <a class='info' href='#streaming'>Section&nbsp;3<span> (</span><span class='info'>HTTP Streaming</span><span>)</span></a>.  This mechanism can face problems caused by two factors: (1) it relies on proxies to forward each chunk (even though there is no requirement for them to do so, and some caching proxies do not), and (2) it relies on user-agents to execute the chunk of JavaScript as it arrives (even though there is also no requirement for them to do so).
</p>
<p>A "reverse proxy" basically is a proxy that pretends to be the actual server (as far as any client or client proxy is concerned), but it passes on the request to the actual server that is usually sitting behind another layer of firewalls.  Any HTTP short polling or HTTP long polling solution will work fine with this, as will most HTTP streaming solutions.  The main downside is performance, since most proxies are not designed to hold many open connections.
</p>
<p>Reverse proxies can come to grief when they try to share connections to the servers between multiple clients.  As an example, Apache with mod_jk shares a small set of connections (often 8 or 16) between all clients.  If long polls are sent on those shared connections, then the proxy can be starved of connections, which means that other requests (either long poll or normal) can be held up.  Thus Comet mechanisms currently need to avoid any connection sharing -- either in the browser or in any intermediary -- because the HTTP assumption is that each request will complete as fast as possible.
</p>
<p>One of the main reasons why both HTTP long polling and HTTP streaming are perceived as having a negative impact on servers and proxies is that they use a synchronous programming model for handling requests, since the resources allocated to each request are held for the duration of the request.  Asynchronous proxies and servers can handle long polls with few resources above that of normal HTTP traffic.  Unfortunately some synchronous proxies do exist (e.g., Apache mod_jk) and many HTTP application servers also have a blocking model for their request handling (e.g., the Java servlet 2.5 specification).
</p>
<a name="responses"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.5.4"></a><h3>5.4.&nbsp;
HTTP Responses</h3>

<p>In accordance with <a class='info' href='#RFC2616'>[RFC2616]<span> (</span><span class='info'>Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter, L., Leach, P., and T. Berners-Lee, &ldquo;Hypertext Transfer Protocol -- HTTP/1.1,&rdquo; June&nbsp;1999.</span><span>)</span></a>, the server responds to a request it has successfully received by sending a 200 OK answer, but only when a particular event, status, or timeout has occurred.  The 200 OK body section contains the actual event, status, or timeout that occurred.  This "best practice" is simply standard HTTP.
</p>
<a name="timeouts"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.5.5"></a><h3>5.5.&nbsp;
Timeouts</h3>

<p>The HTTP long polling mechanism allows the server to respond to a request only when a particular event, status, or timeout has occurred.  In order to minimize as much as possible both latency in server-client message delivery and the processing/network resources needed, the long polling request timeout ought to be set to a high value.
</p>
<p>However, the timeout value has to be chosen carefully; indeed, problems can occur if this value is set too high (e.g., the client might receive a 408 Request Timeout answer from the server or a 504 Gateway Timeout answer from a proxy).  The default timeout value in a browser is 300 seconds, but most network infrastructures include proxies and servers whose timeout is not that long.
</p>
<p>Several experiments have shown success with timeouts as high as 120 seconds, but generally 30 seconds is a safer value.  Therefore vendors of network equipment wishing to be compatible with the HTTP long polling mechanism are advised to implement a timeout substantially greater than 30 seconds (where "substantially" means several times more than the medium network transit time).
</p>
<a name="network"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.5.6"></a><h3>5.6.&nbsp;
Impact on Intermediary Entities</h3>

<p>There is no way for an end client or host to signal to HTTP intermediaries that long polling is in use; therefore long poll requests are completely transparent for intermediary entities and are handled as normal requests.  This can have an impact on intermediary entities that perform operations that are not useful in case of long-polling.  However any capabilities that might interfere with bidirectional flow (e.g., caching) can be controlled with standard headers or cookies.
</p>
<p>As a best practice, caching is always intentionally suppressed in a long poll request or response: i.e., the "Cache-Control" header is set to "no-cache".
</p>
<a name="anchor1"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6"></a><h3>6.&nbsp;
Acknowledgments</h3>

<p>Thanks to Joe Hildebrand, Julien Laganier, Jack Moffitt, Subramanian Moonesamy, Mark Nottingham, Julian Reschke, Martin Thomson, and Martin Tyler for their feedback.
</p>
<a name="iana"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.7"></a><h3>7.&nbsp;
IANA Considerations</h3>

<p>This document does not require any actions by the IANA.
</p>
<a name="security"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8"></a><h3>8.&nbsp;
Security Considerations</h3>

<p>This document is meant to describe current usage of HTTP to enable asynchronous or server-initiated communication.  It does not propose any change to the HTTP protocol or to the expected behavior of HTTP entities.  Therefore this document does not introduce new security concerns into existing HTTP infrastructure.  The considerations reported hereafter refer to the solutions that are already implemented and deployed.
</p>
<p>One security concern with cross-domain HTTP long polling is related to the fact that often the mechanism is implemented by executing the JavaScript returned from the long poll request.  If the server is prone to an injection attacks, then it could be far easier to trick a browser into executing the code <a class='info' href='#CORS'>[CORS]<span> (</span><span class='info'>van Kesteren, A., &ldquo;Cross-Origin Resource Sharing,&rdquo; July&nbsp;2010.</span><span>)</span></a>.
</p>
<p>Another security concern is that the number of open connections that needs to be maintained by a server in HTTP long polling and HTTP streaming could more easily lead to Denial of Service (DOS) attacks.<a class='info' href='#RFC4732'>[RFC4732]<span> (</span><span class='info'>Handley, M., Rescorla, E., and IAB, &ldquo;Internet Denial-of-Service Considerations,&rdquo; December&nbsp;2006.</span><span>)</span></a>.
</p>
<a name="rfc.references"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.9"></a><h3>9.&nbsp;
References</h3>

<a name="rfc.references1"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<h3>9.1.&nbsp;Normative References</h3>
<table width="99%" border="0">
<tr><td class="author-text" valign="top"><a name="RFC1945">[RFC1945]</a></td>
<td class="author-text"><a href="mailto:timbl@w3.org">Berners-Lee, T.</a>, <a href="mailto:fielding@ics.uci.edu">Fielding, R.</a>, and <a href="mailto:frystyk@w3.org">H. Nielsen</a>, &ldquo;<a href="http://tools.ietf.org/html/rfc1945">Hypertext Transfer Protocol -- HTTP/1.0</a>,&rdquo; RFC&nbsp;1945, May&nbsp;1996 (<a href="http://www.rfc-editor.org/rfc/rfc1945.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC2616">[RFC2616]</a></td>
<td class="author-text"><a href="mailto:fielding@ics.uci.edu">Fielding, R.</a>, <a href="mailto:jg@w3.org">Gettys, J.</a>, <a href="mailto:mogul@wrl.dec.com">Mogul, J.</a>, <a href="mailto:frystyk@w3.org">Frystyk, H.</a>, <a href="mailto:masinter@parc.xerox.com">Masinter, L.</a>, <a href="mailto:paulle@microsoft.com">Leach, P.</a>, and <a href="mailto:timbl@w3.org">T. Berners-Lee</a>, &ldquo;<a href="http://tools.ietf.org/html/rfc2616">Hypertext Transfer Protocol -- HTTP/1.1</a>,&rdquo; RFC&nbsp;2616, June&nbsp;1999 (<a href="http://www.rfc-editor.org/rfc/rfc2616.txt">TXT</a>, <a href="http://www.rfc-editor.org/rfc/rfc2616.ps">PS</a>, <a href="http://www.rfc-editor.org/rfc/rfc2616.pdf">PDF</a>, <a href="http://xml.resource.org/public/rfc/html/rfc2616.html">HTML</a>, <a href="http://xml.resource.org/public/rfc/xml/rfc2616.xml">XML</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC4732">[RFC4732]</a></td>
<td class="author-text">Handley, M., Rescorla, E., and IAB, &ldquo;<a href="http://tools.ietf.org/html/rfc4732">Internet Denial-of-Service Considerations</a>,&rdquo; RFC&nbsp;4732, December&nbsp;2006 (<a href="http://www.rfc-editor.org/rfc/rfc4732.txt">TXT</a>).</td></tr>
</table>

<a name="rfc.references2"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<h3>9.2.&nbsp;Informative References</h3>
<table width="99%" border="0">
<tr><td class="author-text" valign="top"><a name="BAYEUX">[BAYEUX]</a></td>
<td class="author-text"><a href="mailto:">Russell, A.</a>, <a href="mailto:">Wilkins, G.</a>, <a href="mailto:">Davis, D.</a>, and <a href="mailto:">M. Nesbitt</a>, &ldquo;<a href="http://svn.cometd.com/trunk/bayeux/bayeux.html">Bayeux Protocol -- Bayeux 1.0.0</a>,&rdquo; 2007 (<a href="http://svn.cometd.com/trunk/bayeux/bayeux.html">HTML</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="BOSH">[BOSH]</a></td>
<td class="author-text"><a href="mailto:ian.paterson@clientside.co.uk">Paterson, I.</a>, <a href="mailto:dizzyd@jabber.org">Smith, D.</a>, and <a href="mailto:stpeter@jabber.org">P. Saint-Andre</a>, &ldquo;<a href="http://www.xmpp.org/extensions/xep-0124.html">Bidirectional-streams Over Synchronous HTTP (BOSH)</a>,&rdquo; XSF XEP&nbsp;0124, February&nbsp;2007.</td></tr>
<tr><td class="author-text" valign="top"><a name="COMET">[COMET]</a></td>
<td class="author-text"><a href="mailto:">Russell, A.</a>, &ldquo;<a href="http://alex.dojotoolkit.org/?p=545">Comet: Low Latency Data for the Browser</a>,&rdquo; March&nbsp;2006.</td></tr>
<tr><td class="author-text" valign="top"><a name="COOKIE">[COOKIE]</a></td>
<td class="author-text">Barth, A., &ldquo;<a href="http://www.ietf.org/internet-drafts/draft-ietf-httpstate-cookie-20.txt">HTTP State Management Mechanism</a>,&rdquo; draft-ietf-httpstate-cookie-20 (work in progress), December&nbsp;2010 (<a href="http://www.ietf.org/internet-drafts/draft-ietf-httpstate-cookie-20.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="CORS">[CORS]</a></td>
<td class="author-text">van Kesteren, A., &ldquo;<a href="http://www.w3.org/TR/2010/WD-cors-20100727/">Cross-Origin Resource Sharing</a>,&rdquo; W3C Working Draft&nbsp;WD-cors-20100727, July&nbsp;2010.<p>
Latest version available at
    <a href='http://www.w3.org/TR/cors/'>http://www.w3.org/TR/cors/</a>.
</p>
</td></tr>
<tr><td class="author-text" valign="top"><a name="HTTPBIS">[HTTPBIS]</a></td>
<td class="author-text">Fielding, R., Gettys, J., Mogul, J., Nielsen, H., Masinter, L., Leach, P., Berners-Lee, T., Lafon, Y., and J. Reschke, &ldquo;<a href="http://www.ietf.org/internet-drafts/draft-ietf-httpbis-p1-messaging-12.txt">HTTP/1.1, part 1: URIs, Connections, and Message Parsing</a>,&rdquo; draft-ietf-httpbis-p1-messaging-12 (work in progress), October&nbsp;2010 (<a href="http://www.ietf.org/internet-drafts/draft-ietf-httpbis-p1-messaging-12.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="JSONP">[JSONP]</a></td>
<td class="author-text">&ldquo;<a href="http://en.wikipedia.org/wiki/JSONP#JSONP">JSON with padding</a>&rdquo; (<a href="http://en.wikipedia.org/wiki/JSONP#JSONP">HTML</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC4627">[RFC4627]</a></td>
<td class="author-text">Crockford, D., &ldquo;<a href="http://tools.ietf.org/html/rfc4627">The application/json Media Type for JavaScript Object Notation (JSON)</a>,&rdquo; RFC&nbsp;4627, July&nbsp;2006 (<a href="http://www.rfc-editor.org/rfc/rfc4627.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="TCP">[TCP]</a></td>
<td class="author-text">Postel, J., &ldquo;<a href="http://tools.ietf.org/html/rfc793">Transmission Control Protocol</a>,&rdquo; STD&nbsp;7, RFC&nbsp;793, September&nbsp;1981 (<a href="http://www.rfc-editor.org/rfc/rfc793.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="WD-eventsource">[WD-eventsource]</a></td>
<td class="author-text">Hickson, I., &ldquo;<a href="http://www.w3.org/TR/2009/WD-eventsource-20091222/">Server-Sent Events</a>,&rdquo; W3C Working Draft&nbsp;WD-eventsource-20091222, December&nbsp;2009.<p>
Latest version available at
    <a href='http://www.w3.org/TR/eventsource/'>http://www.w3.org/TR/eventsource/</a>.
</p>
</td></tr>
<tr><td class="author-text" valign="top"><a name="XMPP">[XMPP]</a></td>
<td class="author-text">Saint-Andre, P., &ldquo;<a href="http://www.ietf.org/internet-drafts/draft-ietf-xmpp-3920bis-22.txt">Extensible Messaging and Presence Protocol (XMPP): Core</a>,&rdquo; draft-ietf-xmpp-3920bis-22 (work in progress), December&nbsp;2010 (<a href="http://www.ietf.org/internet-drafts/draft-ietf-xmpp-3920bis-22.txt">TXT</a>).</td></tr>
</table>

<a name="rfc.authors"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<h3>Authors' Addresses</h3>
<table width="99%" border="0" cellpadding="0" cellspacing="0">
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Salvatore Loreto</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Ericsson</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Hirsalantie 11</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Jorvas  02420</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Finland</td></tr>
<tr><td class="author" align="right">Email:&nbsp;</td>
<td class="author-text"><a href="mailto:salvatore.loreto@ericsson.com">salvatore.loreto@ericsson.com</a></td></tr>
<tr cellpadding="3"><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Peter Saint-Andre</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Cisco</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">1899 Wyknoop Street, Suite 600</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Denver, CO  80202</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">USA</td></tr>
<tr><td class="author" align="right">Phone:&nbsp;</td>
<td class="author-text">+1-303-308-3282</td></tr>
<tr><td class="author" align="right">Email:&nbsp;</td>
<td class="author-text"><a href="mailto:psaintan@cisco.com">psaintan@cisco.com</a></td></tr>
<tr cellpadding="3"><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Stefano Salsano</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Univ.  of Rome "Tor Vergata"</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Via del Politecnico, 1</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Rome  00133</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Italy</td></tr>
<tr><td class="author" align="right">Email:&nbsp;</td>
<td class="author-text"><a href="mailto:stefano.salsano@uniroma2.it">stefano.salsano@uniroma2.it</a></td></tr>
<tr cellpadding="3"><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Greg Wilkins</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Webtide</td></tr>
<tr><td class="author" align="right">Email:&nbsp;</td>
<td class="author-text"><a href="mailto:gregw@webtide.com">gregw@webtide.com</a></td></tr>
</table>
</body></html>
