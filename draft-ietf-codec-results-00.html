<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" 
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head profile="http://www.w3.org/2006/03/hcard%20http://dublincore.org/documents/2008/08/04/dc-html/">
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />

  <title>Summary of Opus listening test results</title>

  <style type="text/css" title="Xml2Rfc (sans serif)">
  /*<![CDATA[*/
	  a {
	  text-decoration: none;
	  }
	  a.smpl {
	  color: black;
	  }
	  a:hover {
	  text-decoration: underline;
	  }
	  a:active {
	  text-decoration: underline;
	  }
	  address {
	  margin-top: 1em;
	  margin-left: 2em;
	  font-style: normal;
	  }
	  body {
	  color: black;
	  font-family: verdana, helvetica, arial, sans-serif;
	  font-size: 10pt;
	  
	  }
	  cite {
	  font-style: normal;
	  }
	  dd {
	  margin-right: 2em;
	  }
	  dl {
	  margin-left: 2em;
	  }
	
	  ul.empty {
	  list-style-type: none;
	  }
	  ul.empty li {
	  margin-top: .5em;
	  }
	  dl p {
	  margin-left: 0em;
	  }
	  dt {
	  margin-top: .5em;
	  }
	  h1 {
	  font-size: 14pt;
	  line-height: 21pt;
	  page-break-after: avoid;
	  }
	  h1.np {
	  page-break-before: always;
	  }
	  h1 a {
	  color: #333333;
	  }
	  h2 {
	  font-size: 12pt;
	  line-height: 15pt;
	  page-break-after: avoid;
	  }
	  h3, h4, h5, h6 {
	  font-size: 10pt;
	  page-break-after: avoid;
	  }
	  h2 a, h3 a, h4 a, h5 a, h6 a {
	  color: black;
	  }
	  img {
	  margin-left: 3em;
	  }
	  li {
	  margin-left: 2em;
	  margin-right: 2em;
	  }
	  ol {
	  margin-left: 2em;
	  margin-right: 2em;
	  }
	  ol p {
	  margin-left: 0em;
	  }
	  p {
	  margin-left: 2em;
	  margin-right: 2em;
	  }
	  pre {
	  margin-left: 3em;
	  background-color: lightyellow;
	  padding: .25em;
	  }
	  pre.text2 {
	  border-style: dotted;
	  border-width: 1px;
	  background-color: #f0f0f0;
	  width: 69em;
	  }
	  pre.inline {
	  background-color: white;
	  padding: 0em;
	  }
	  pre.text {
	  border-style: dotted;
	  border-width: 1px;
	  background-color: #f8f8f8;
	  width: 69em;
	  }
	  pre.drawing {
	  border-style: solid;
	  border-width: 1px;
	  background-color: #f8f8f8;
	  padding: 2em;
	  }
	  table {
	  margin-left: 2em;
	  }
	  table.tt {
	  vertical-align: top;
	  }
	  table.full {
	  border-style: outset;
	  border-width: 1px;
	  }
	  table.headers {
	  border-style: outset;
	  border-width: 1px;
	  }
	  table.tt td {
	  vertical-align: top;
	  }
	  table.full td {
	  border-style: inset;
	  border-width: 1px;
	  }
	  table.tt th {
	  vertical-align: top;
	  }
	  table.full th {
	  border-style: inset;
	  border-width: 1px;
	  }
	  table.headers th {
	  border-style: none none inset none;
	  border-width: 1px;
	  }
	  table.left {
	  margin-right: auto;
	  }
	  table.right {
	  margin-left: auto;
	  }
	  table.center {
	  margin-left: auto;
	  margin-right: auto;
	  }
	  caption {
	  caption-side: bottom;
	  font-weight: bold;
	  font-size: 9pt;
	  margin-top: .5em;
	  }
	
	  table.header {
	  border-spacing: 1px;
	  width: 95%;
	  font-size: 10pt;
	  color: white;
	  }
	  td.top {
	  vertical-align: top;
	  }
	  td.topnowrap {
	  vertical-align: top;
	  white-space: nowrap; 
	  }
	  table.header td {
	  background-color: gray;
	  width: 50%;
	  }
	  table.header a {
	  color: white;
	  }
	  td.reference {
	  vertical-align: top;
	  white-space: nowrap;
	  padding-right: 1em;
	  }
	  thead {
	  display:table-header-group;
	  }
	  ul.toc, ul.toc ul {
	  list-style: none;
	  margin-left: 1.5em;
	  margin-right: 0em;
	  padding-left: 0em;
	  }
	  ul.toc li {
	  line-height: 150%;
	  font-weight: bold;
	  font-size: 10pt;
	  margin-left: 0em;
	  margin-right: 0em;
	  }
	  ul.toc li li {
	  line-height: normal;
	  font-weight: normal;
	  font-size: 9pt;
	  margin-left: 0em;
	  margin-right: 0em;
	  }
	  li.excluded {
	  font-size: 0pt;
	  }
	  ul p {
	  margin-left: 0em;
	  }
	
	  .comment {
	  background-color: yellow;
	  }
	  .center {
	  text-align: center;
	  }
	  .error {
	  color: red;
	  font-style: italic;
	  font-weight: bold;
	  }
	  .figure {
	  font-weight: bold;
	  text-align: center;
	  font-size: 9pt;
	  }
	  .filename {
	  color: #333333;
	  font-weight: bold;
	  font-size: 12pt;
	  line-height: 21pt;
	  text-align: center;
	  }
	  .fn {
	  font-weight: bold;
	  }
	  .hidden {
	  display: none;
	  }
	  .left {
	  text-align: left;
	  }
	  .right {
	  text-align: right;
	  }
	  .title {
	  color: #990000;
	  font-size: 18pt;
	  line-height: 18pt;
	  font-weight: bold;
	  text-align: center;
	  margin-top: 36pt;
	  }
	  .vcardline {
	  display: block;
	  }
	  .warning {
	  font-size: 14pt;
	  background-color: yellow;
	  }
	
	
	  @media print {
	  .noprint {
		display: none;
	  }
	
	  a {
		color: black;
		text-decoration: none;
	  }
	
	  table.header {
		width: 90%;
	  }
	
	  td.header {
		width: 50%;
		color: black;
		background-color: white;
		vertical-align: top;
		font-size: 12pt;
	  }
	
	  ul.toc a::after {
		content: leader('.') target-counter(attr(href), page);
	  }
	
	  ul.ind li li a {
		content: target-counter(attr(href), page);
	  }
	
	  .print2col {
		column-count: 2;
		-moz-column-count: 2;
		column-fill: auto;
	  }
	  }
	
	  @page {
	  @top-left {
		   content: "Internet-Draft"; 
	  } 
	  @top-right {
		   content: "December 2010"; 
	  } 
	  @top-center {
		   content: "Abbreviated Title";3
	  } 
	  @bottom-left {
		   content: "Doe"; 
	  } 
	  @bottom-center {
		   content: "Expires June 2011"; 
	  } 
	  @bottom-right {
		   content: "[Page " counter(page) "]"; 
	  } 
	  }
	
	  @page:first { 
		@top-left {
		  content: normal;
		}
		@top-right {
		  content: normal;
		}
		@top-center {
		  content: normal;
		}
	  }
  /*]]>*/
  </style>

  <link href="#rfc.toc" rel="Contents">
<link href="#rfc.section.1" rel="Chapter" title="1 Introduction">
<link href="#rfc.section.2" rel="Chapter" title="2 Opus listening tests on final bit-stream">
<link href="#rfc.section.2.1" rel="Chapter" title="2.1 Google listening tests">
<link href="#rfc.section.2.1.1" rel="Chapter" title="2.1.1 Google narrowband listening test">
<link href="#rfc.section.2.1.2" rel="Chapter" title="2.1.2 Google wideband and fullband listening test">
<link href="#rfc.section.2.1.3" rel="Chapter" title="2.1.3 Google stereo music listening test">
<link href="#rfc.section.2.1.4" rel="Chapter" title="2.1.4 Google transcoding test">
<link href="#rfc.section.2.1.5" rel="Chapter" title="2.1.5 Google mandarin tests">
<link href="#rfc.section.2.2" rel="Chapter" title="2.2 HydrogenAudio stereo music listening test">
<link href="#rfc.section.2.3" rel="Chapter" title="2.3 Nokia Interspeech 2011 listening test">
<link href="#rfc.section.2.4" rel="Chapter" title="2.4 Universitaet Tuebingen stereo and binaural tests">
<link href="#rfc.section.3" rel="Chapter" title="3 Conclusion on the requirements">
<link href="#rfc.section.3.1" rel="Chapter" title="3.1 Comparison to Speex (narrowband)">
<link href="#rfc.section.3.2" rel="Chapter" title="3.2 Comparison to iLBC">
<link href="#rfc.section.3.3" rel="Chapter" title="3.3 Comparison to Speex (wideband)">
<link href="#rfc.section.3.4" rel="Chapter" title="3.4 Comparison to G.722.1">
<link href="#rfc.section.3.5" rel="Chapter" title="3.5 Comparison to G.722.1C">
<link href="#rfc.section.3.6" rel="Chapter" title="3.6 Comparison to AMR-NB">
<link href="#rfc.section.3.7" rel="Chapter" title="3.7 Comparison to AMR-WB">
<link href="#rfc.section.4" rel="Chapter" title="4 Security Considerations">
<link href="#rfc.section.5" rel="Chapter" title="5 IANA Considerations ">
<link href="#rfc.section.6" rel="Chapter" title="6 Acknowledgments">
<link href="#rfc.references" rel="Chapter" title="7 References">
<link href="#rfc.appendix.Appendix%20A" rel="Chapter" title="Appendix A Pre-Opus listening tests">
<link href="#rfc.appendix.Appendix%20A.1" rel="Chapter" title="Appendix A.1 SILK Dynastat listening test">
<link href="#rfc.appendix.Appendix%20A.2" rel="Chapter" title="Appendix A.2 SILK Deutsche Telekom test">
<link href="#rfc.appendix.Appendix%20A.3" rel="Chapter" title="Appendix A.3 SILK Nokia test">
<link href="#rfc.appendix.Appendix%20A.4" rel="Chapter" title="Appendix A.4 CELT 0.3.2 listening test">
<link href="#rfc.appendix.Appendix%20A.5" rel="Chapter" title="Appendix A.5 CELT 0.5.0 listening test">
<link href="#rfc.appendix.Appendix%20B" rel="Chapter" title="Appendix B Opus listening tests on non-final bit-stream">
<link href="#rfc.appendix.Appendix%20B.1" rel="Chapter" title="Appendix B.1 First hybrid mode test">
<link href="#rfc.appendix.Appendix%20B.2" rel="Chapter" title="Appendix B.2 Broadcom stereo music test">
<link href="#rfc.appendix.Appendix%20C" rel="Chapter" title="Appendix C In-the-field testing">
<link href="#rfc.authors" rel="Chapter">


  <meta name="generator" content=
  "http://greenbytes.de/tech/webdav/rfc2629.xslt, Revision 1.539, 2011-01-02 17:13:00, XSLT vendor: SAXON 6.5.5 from Michael Kay http://saxon.sf.net/" />
  <link rel="schema.dct" href="http://purl.org/dc/terms/" />
  <meta name="dct.creator" content="Doe, J." />
  <meta name="dct.identifier" content="urn:ietf:id:draft-sample-input-00" />
  <meta name="dct.issued" scheme="ISO8601" content="2010-12" />
  
  <meta name="dct.abstract" content="This document describes and examines listening test results obtained for the Opus codec and how they relate to the requirements." />
  <meta name="description" content="This document describes and examines listening test results obtained for the Opus codec and how they relate to the requirements." />
  <meta name="keywords" content="audio codec, Opus" />

</head>

<body>

  <table class="header">
    <tbody>
    
    	<tr>
<td class="left">codec</td>
<td class="right">C. Hoene, Ed.</td>
</tr>
<tr>
<td class="left">Internet-Draft</td>
<td class="right">Universitaet Tuebingen</td>
</tr>
<tr>
<td class="left">Intended status: Informational</td>
<td class="right">JM. Valin</td>
</tr>
<tr>
<td class="left">Expires: April 27, 2012</td>
<td class="right">Mozilla Corporation</td>
</tr>
<tr>
<td class="left"></td>
<td class="right">K. Vos</td>
</tr>
<tr>
<td class="left"></td>
<td class="right">Skype Technologies S.A.</td>
</tr>
<tr>
<td class="left"></td>
<td class="right">J. Skoglund</td>
</tr>
<tr>
<td class="left"></td>
<td class="right">Google</td>
</tr>
<tr>
<td class="left"></td>
<td class="right">October 25, 2011</td>
</tr>

    	
    </tbody>
  </table>

  <p class="title">Summary of Opus listening test results<br />
  <span class="filename">draft-ietf-codec-results-00</span></p>
  
  <h1 id="rfc.abstract"><a href="#rfc.abstract">Abstract</a></h1>
<p>This document describes and examines listening test results obtained for the Opus codec and how they relate to the requirements.</p>
<h1 id="rfc.status"><a href="#rfc.status">Status of this Memo</a></h1>
<p>This Internet-Draft is submitted in full conformance with the provisions of BCP 78 and BCP 79.</p>
<p>Internet-Drafts are working documents of the Internet Engineering Task Force (IETF).  Note that other groups may also distribute working documents as Internet-Drafts.  The list of current Internet- Drafts is at http://datatracker.ietf.org/drafts/current/.</p>
<p>Internet-Drafts are draft documents valid for a maximum of six months and may be updated, replaced, or obsoleted by other documents at any time.  It is inappropriate to use Internet-Drafts as reference material or to cite them other than as "work in progress."</p>
<p>This Internet-Draft will expire on April 27, 2012.</p>
<h1 id="rfc.copyrightnotice"><a href="#rfc.copyrightnotice">Copyright Notice</a></h1>
<p>Copyright (c) 2011 IETF Trust and the persons identified as the document authors.  All rights reserved.</p>
<p>This document is subject to BCP 78 and the IETF Trust's Legal Provisions Relating to IETF Documents (http://trustee.ietf.org/license-info) in effect on the date of publication of this document.  Please review these documents carefully, as they describe your rights and restrictions with respect to this document.  Code Components extracted from this document must include Simplified BSD License text as described in Section 4.e of the Trust Legal Provisions and are provided without warranty as described in the Simplified BSD License.</p>

  
  <hr class="noprint" />
  <h1 class="np" id="rfc.toc"><a href="#rfc.toc">Table of Contents</a></h1>
  <ul class="toc">

  	<li>1.   <a href="#rfc.section.1">Introduction</a>
</li>
<li>2.   <a href="#rfc.section.2">Opus listening tests on final bit-stream</a>
</li>
<li>2.1.   <a href="#rfc.section.2.1">Google listening tests</a>
</li>
<li>2.1.1.   <a href="#rfc.section.2.1.1">Google narrowband listening test</a>
</li>
<li>2.1.2.   <a href="#rfc.section.2.1.2">Google wideband and fullband listening test</a>
</li>
<li>2.1.3.   <a href="#rfc.section.2.1.3">Google stereo music listening test</a>
</li>
<li>2.1.4.   <a href="#rfc.section.2.1.4">Google transcoding test</a>
</li>
<li>2.1.5.   <a href="#rfc.section.2.1.5">Google mandarin tests</a>
</li>
<li>2.2.   <a href="#rfc.section.2.2">HydrogenAudio stereo music listening test</a>
</li>
<li>2.3.   <a href="#rfc.section.2.3">Nokia Interspeech 2011 listening test</a>
</li>
<li>2.4.   <a href="#rfc.section.2.4">Universitaet Tuebingen stereo and binaural tests</a>
</li>
<li>3.   <a href="#rfc.section.3">Conclusion on the requirements</a>
</li>
<li>3.1.   <a href="#rfc.section.3.1">Comparison to Speex (narrowband)</a>
</li>
<li>3.2.   <a href="#rfc.section.3.2">Comparison to iLBC</a>
</li>
<li>3.3.   <a href="#rfc.section.3.3">Comparison to Speex (wideband)</a>
</li>
<li>3.4.   <a href="#rfc.section.3.4">Comparison to G.722.1</a>
</li>
<li>3.5.   <a href="#rfc.section.3.5">Comparison to G.722.1C</a>
</li>
<li>3.6.   <a href="#rfc.section.3.6">Comparison to AMR-NB</a>
</li>
<li>3.7.   <a href="#rfc.section.3.7">Comparison to AMR-WB</a>
</li>
<li>4.   <a href="#rfc.section.4">Security Considerations</a>
</li>
<li>5.   <a href="#rfc.section.5">IANA Considerations </a>
</li>
<li>6.   <a href="#rfc.section.6">Acknowledgments</a>
</li>
<li>7.   <a href="#rfc.references">References</a>
</li>
<li>Appendix A.   <a href="#rfc.appendix.Appendix%20A">Pre-Opus listening tests</a>
</li>
<li>Appendix A.1.   <a href="#rfc.appendix.Appendix%20A.1">SILK Dynastat listening test</a>
</li>
<li>Appendix A.2.   <a href="#rfc.appendix.Appendix%20A.2">SILK Deutsche Telekom test</a>
</li>
<li>Appendix A.3.   <a href="#rfc.appendix.Appendix%20A.3">SILK Nokia test</a>
</li>
<li>Appendix A.4.   <a href="#rfc.appendix.Appendix%20A.4">CELT 0.3.2 listening test</a>
</li>
<li>Appendix A.5.   <a href="#rfc.appendix.Appendix%20A.5">CELT 0.5.0 listening test</a>
</li>
<li>Appendix B.   <a href="#rfc.appendix.Appendix%20B">Opus listening tests on non-final bit-stream</a>
</li>
<li>Appendix B.1.   <a href="#rfc.appendix.Appendix%20B.1">First hybrid mode test</a>
</li>
<li>Appendix B.2.   <a href="#rfc.appendix.Appendix%20B.2">Broadcom stereo music test</a>
</li>
<li>Appendix C.   <a href="#rfc.appendix.Appendix%20C">In-the-field testing</a>
</li>
<li><a href="#rfc.authors">Authors' Addresses</a>
</li>


  </ul>

  <h1 id="rfc.section.1">
<a href="#rfc.section.1">1.</a> <a href="#Introduction" id="Introduction">Introduction</a>
</h1>
<p id="rfc.section.1.p.1">This document describes and examines listening test results obtained for the Opus codec. Some of the test results presented are based on older versions of the codec or on older versions of the SILK or CELT components. While they do not necessarily represent the exact quality of the current version, they are nonetheless useful for validating the technology used and as an indication of a lower bound on quality (based on the assumption that the codec has been improved since they were performed).</p>
<p id="rfc.section.1.p.2">Throughout this document, all statements about one codec being better than or worse than another codec are based on 95% confidence. When no statistically significant difference can be shown with 95% confidence, then two codecs are said to be "tied".</p>
<p id="rfc.section.1.p.3">In addition to the results summarized in this draft, Opus has been subjected to many informal subjective listening tests, as well as objective testing.</p>
<h1 id="rfc.section.2">
<a href="#rfc.section.2">2.</a> <a href="#opus" id="opus">Opus listening tests on final bit-stream</a>
</h1>
<p id="rfc.section.2.p.1">The following tests were performed on the Opus codec <em>after</em> the bit-stream was finalized.</p>
<h1 id="rfc.section.2.1">
<a href="#rfc.section.2.1">2.1.</a> <a href="#opus-google" id="opus-google">Google listening tests</a>
</h1>
<p id="rfc.section.2.1.p.1">The tests followed the MUSHRA test methodology. Two anchors were used, one lowpass-filtered at 3.5 kHz and one lowpass-filtered at 7.0 kHz. Both trained and untrained listeners participated in the tests.  The reference signals were manually normalized to the same subjective levels according to the experimenters' opinion. Experiments with automatic normalization with respect to both level and loudness (in Adobe Audition) did not result in signals having equal subjective loudness. The sample magnitude levels were kept lower than 2^14 to provide headroom for possible amplification through the codecs.  However, the normalization exercise was not repeated with the processed sequences as neither the experimenters nor any of the subjects (which included expert listeners) noticed any significant level differences between the conditions in the tests. The only post-processing performed was to remove noticeable delays in the MP3 files, as one could identify the MP3 samples when switching between conditions when the MP3 had the longer delay. The testing tool Step from ARL was used for tests and all listeners were instructed to to carefully listen through the conditions before starting the grading.  The results of the tests are a available on the testing slides <a href="#Prague-80">presented at the Prague meeting</a> <cite title="NONE">[Prague-80]</cite>.</p>
<h1 id="rfc.section.2.1.1">
<a href="#rfc.section.2.1.1">2.1.1.</a> <a href="#opus-google-narrowband" id="opus-google-narrowband">Google narrowband listening test</a>
</h1>
<p id="rfc.section.2.1.1.p.1">The test sequences in Test 1 were mono recordings (between 2 and 6 seconds long) of 4 different male and 4 different female speakers sampled at 48 kHz in low background noise. 17 listeners were presented with 6 stimuli according to <a href="#narrowband-conditions">Table 1</a> for each test sequence. The corresponding bit rate for the reference is 48000 (sampling frequency in Hz) x 16 (bits/sample) = 768 kbps. Since the anchors are low-pass filtered they can also be downsampled for transmission which corresponds to lower bit rates. Three narrowband codecs were compared in this test: Opus NB, the royalty-free iLBC, and the royalty-free Speex. The codecs all have an encoder frame length of 20 ms. Both Opus and Speex had variable rate whereas iLBC operated at a fixed bit rate.</p>
<div id="#rfc.table.1"></div>
<div id="#narrowband-conditions"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Narrowband mono voice: test conditions</caption>
<thead><tr>
<th class="center">Type</th>
<th class="center">Signal bandwidth</th>
<th class="center">Bitrate</th>
</tr></thead>
<tbody>
<tr>
<td class="center">Reference</td>
<td class="center">24 kHz (Fullband)</td>
<td class="center"></td>
</tr>
<tr>
<td class="center">Anchor 1</td>
<td class="center">3.5 kHz (Narrowband)</td>
<td class="center"></td>
</tr>
<tr>
<td class="center">Anchor 2</td>
<td class="center">7 kHz (Wideband)</td>
<td class="center"></td>
</tr>
<tr>
<td class="center">iLBC</td>
<td class="center">4 kHz (Narrowband)</td>
<td class="center">15.2 kbps, CBR</td>
</tr>
<tr>
<td class="center">Opus NB</td>
<td class="center">4 kHz (Narrowband)</td>
<td class="center">11 kbps, VBR</td>
</tr>
<tr>
<td class="center">Speex NB</td>
<td class="center">3.5 kHz (Narrowband)</td>
<td class="center">11 kbps, VBR</td>
</tr>
</tbody>
</table>
<p id="rfc.section.2.1.1.p.2">The overall results of the narrowband test, i.e., averaged over all listeners for all sequences, are presented in <a href="#Prague-80">the Prague meeting slides</a> <cite title="NONE">[Prague-80]</cite>. The results suggest that Opus at 11 kbps is superior to both iLBC at 15 kpbs and Speex at 11 kbps. T-tests performed by Greg Maxwell confirm that there is indeed a statistically significant difference. Note also that Opus has a slightly higher average score than the 3.5 kHz anchor, likely due to the higher bandwidth of Opus.</p>
<h1 id="rfc.section.2.1.2">
<a href="#rfc.section.2.1.2">2.1.2.</a> <a href="#opus-google-wideband" id="opus-google-wideband">Google wideband and fullband listening test</a>
</h1>
<p id="rfc.section.2.1.2.p.1">The eight test sequences for the previous test were also used in this Test. 16 listeners rated the stimuli listed in Table 2. In this test comparisons were made between four wideband codecs: Opus WB, the royalty-free Speex, the royalty-free ITU-T G.722.1, AMR-WB (ITU-T G.722.2), and two fullband codecs: Opus FB and the royalty-free ITU-T G.719. All six codecs utilize 20 ms encoding frames. Opus used variable bitrate, while other codecs used constant bit rate.</p>
<div id="#rfc.table.2"></div>
<div id="#wideband-conditions"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Wideband and fullband mono voice: test conditions</caption>
<thead><tr>
<th class="center">Type</th>
<th class="center">Signal bandwidth</th>
<th class="center">Bitrate</th>
</tr></thead>
<tbody>
<tr>
<td class="center">Reference</td>
<td class="center">24 kHz (Fullband)</td>
<td class="center"></td>
</tr>
<tr>
<td class="center">Anchor 1</td>
<td class="center">3.5 kHz (Narrowband)</td>
<td class="center"></td>
</tr>
<tr>
<td class="center">Anchor 2</td>
<td class="center">7 kHz (Wideband)</td>
<td class="center"></td>
</tr>
<tr>
<td class="center">G.722.1</td>
<td class="center">7 kHz (Wideband)</td>
<td class="center">24 kbps, CBR</td>
</tr>
<tr>
<td class="center">Speex WB</td>
<td class="center">7 kHz (Wideband)</td>
<td class="center">23.8 kbps, CBR</td>
</tr>
<tr>
<td class="center">AMR-WB</td>
<td class="center">7 kHz (Wideband)</td>
<td class="center">19.85 kbps, CBR</td>
</tr>
<tr>
<td class="center">Opus WB</td>
<td class="center">8 kHz (Wideband)</td>
<td class="center">19.85 kbps, VBR</td>
</tr>
<tr>
<td class="center">G.719</td>
<td class="center">~20 kHz (Fullband)</td>
<td class="center">32 kbps, CBR</td>
</tr>
<tr>
<td class="center">Opus FB</td>
<td class="center">~20 kHz (Fullband)</td>
<td class="center">32 kbps, CBR</td>
</tr>
</tbody>
</table>
<p id="rfc.section.2.1.2.p.2">The results from this test are depicted in the Prague meeting slides<a href="#Prague-80">[Prague-80]</a>. Opus at 32 kbps is almost transparent, although there is a small, but statistically significant, difference from the fullband reference material. Opus at 20 kbps is significantly better than all the other codecs, including AMR-WB and the fullband G.719, and both low-pass anchors.</p>
<h1 id="rfc.section.2.1.3">
<a href="#rfc.section.2.1.3">2.1.3.</a> <a href="#opus-google-music" id="opus-google-music">Google stereo music listening test</a>
</h1>
<p id="rfc.section.2.1.3.p.1">The sequences in this test were excerpts from 10 different stereo music files: </p>

<ul>
<li>Rock/RnB (Boz Scaggs)</li>
<li>Soft Rock (Steely Dan)</li>
<li>Rock (Queen)</li>
<li>Jazz (Harry James)</li>
<li>Classical (Purcell)</li>
<li>Electronica (Matmos)</li>
<li>Piano (Moonlight Sonata)</li>
<li>Vocals (Suzanne Vega)</li>
<li>Glockenspiel</li>
<li>Castanets</li>
</ul>
<p id="rfc.section.2.1.3.p.2">These sequences were originally recorded at a sampling frequency of 44.1 kHz and were upsampled to 48 kHz prior to processing. Test 3 included comparisons between six codecs (c.f., Table 3): Opus at three rates, G.719, AAC-LC (Nero 1.5.1), and MP3 (Lame 3.98.4).  G.719 is a mono codec, so the two channels were each coded independently at 32 kbps. 9 listeners participated in Test 3, and the results are depicted in the Prague meeting slides<a href="#Prague-80">[Prague-80]</a>. The codecs operated at constant (or comparable) bit rate.</p>
<div id="#rfc.table.3"></div>
<div id="#google-music-conditions"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Stereo music: Test conditions</caption>
<thead><tr>
<th class="center">Type</th>
<th class="center">Signal bandwidth</th>
<th class="center">Frame size (ms)</th>
<th class="center">Bitrate</th>
</tr></thead>
<tbody>
<tr>
<td class="center">Reference</td>
<td class="center">22 kHz (Fullband)</td>
<td class="center">-</td>
<td class="center">(1536 kbps)</td>
</tr>
<tr>
<td class="center">Anchor 1</td>
<td class="center">3.5 kHz (Narrowband)</td>
<td class="center">-</td>
<td class="center">(256 kbps)</td>
</tr>
<tr>
<td class="center">Anchor 2</td>
<td class="center">7 kHz (Wideband)</td>
<td class="center">-</td>
<td class="center">(512 kbps)</td>
</tr>
<tr>
<td class="center">MP3</td>
<td class="center">16 kHz (Super wideband)</td>
<td class="center">&gt;100</td>
<td class="center">96 kbps, CBR</td>
</tr>
<tr>
<td class="center">AAC-LC</td>
<td class="center">~20 kHz (Fullband)</td>
<td class="center">21</td>
<td class="center">64 kbps, CBR (bit reservoir)</td>
</tr>
<tr>
<td class="center">G.719</td>
<td class="center">~20 kHz (Fullband)</td>
<td class="center">20</td>
<td class="center">64 kbps (2x32), CBR</td>
</tr>
<tr>
<td class="center">Opus FB</td>
<td class="center">~20 kHz (Fullband)</td>
<td class="center">20</td>
<td class="center">64 kbps, constrained VBR</td>
</tr>
<tr>
<td class="center">Opus FB</td>
<td class="center">~20 kHz (Fullband)</td>
<td class="center">10</td>
<td class="center">80 kbps, constrained VBR</td>
</tr>
<tr>
<td class="center">Opus FB</td>
<td class="center">~20 kHz (Fullband)</td>
<td class="center">5</td>
<td class="center">128 kbps, constrained VBR</td>
</tr>
</tbody>
</table>
<p id="rfc.section.2.1.3.p.3">The results indicate that all codecs had comparable performance, except for G.719, which had a considerably lower score. T-tests by Greg Maxwell verified that the low-delay Opus at 128 kbps had a significantly higher performance and that G.719 had a significantly lower performance than the other four.</p>
<h1 id="rfc.section.2.1.4">
<a href="#rfc.section.2.1.4">2.1.4.</a> <a href="#opus-google-transcoding" id="opus-google-transcoding">Google transcoding test</a>
</h1>
<p id="rfc.section.2.1.4.p.1">If two telephone networks of different technology are coupled, frequently speech has to be transcoded: It must be decoded and encoded before it can be forward to the next network. Then, two codecs are cooperating in a row, which is called tandem coding.</p>
<p id="rfc.section.2.1.4.p.2">In the following tests, Jan Skoglund studied the impact of transcoding if Opus call is forwarded to a cellular phone system.  <a href="#Skoglund2011">[Skoglund2011]</a>. Two tests were conducted for both narrowband and wideband speech items. The test conditions of the narrow-band tests are given in Table </p>
<div id="#rfc.table.4"></div>
<div id="#google-tandem-nb-conditions"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Narrowband tandem coding: test conditions</caption>
<thead><tr>
<th class="left">Condition</th>
<th class="left">Value</th>
</tr></thead>
<tbody>
<tr>
<td class="left">Laboratory</td>
<td class="left">Google</td>
</tr>
<tr>
<td class="left">Examiner</td>
<td class="left">Jan Skoglund</td>
</tr>
<tr>
<td class="left">Date</td>
<td class="left">August and September 2011</td>
</tr>
<tr>
<td class="left">Methodology</td>
<td class="left">ITU-R BS.1534-1 (MUSHRA)</td>
</tr>
<tr>
<td class="left">Reference items</td>
<td class="left">Two male and two female speakers from ITU-T P.501. Two male and two female speakers from McGill database. All recorded at 48kHz in a room with low background noise.</td>
</tr>
<tr>
<td class="left">Listeners</td>
<td class="left">19 listeners no listeners rejected / trained and untrained English-speaking listeners</td>
</tr>
<tr>
<td class="left">Anchor 1</td>
<td class="left">Reference file lowpass-filtered at 3.5 kHz</td>
</tr>
<tr>
<td class="left">Anchor 2</td>
<td class="left">Reference file resampled at 8 kHz, with MNRU at 15 dB SNR</td>
</tr>
<tr>
<td class="left">Test Condition 1</td>
<td class="left">G.711 at 64 kbps -&gt; Opus NB at 12.2 kbps, variable bit rate</td>
</tr>
<tr>
<td class="left">Test Condition 2</td>
<td class="left">G.711 at 64 kbps -&gt; AMR NB at 12.2 kbps, constant bit rate</td>
</tr>
<tr>
<td class="left">Test Condition 3</td>
<td class="left">AMR NB at 12.2 kbps -&gt; G.711 at 64 kbps -&gt; Opus NB at 12.2 kbps</td>
</tr>
<tr>
<td class="left">Test Condition 4</td>
<td class="left">Opus NB at 12.2 kbps &gt; G.711 at 64 kbps &gt; AMR NB at 12.2 kbps</td>
</tr>
<tr>
<td class="left">Test Condition 5</td>
<td class="left">AMR NB at 12.2 kbps -&gt; G.711 at 64 kbps -&gt; AMR NB at 12.2 kbps</td>
</tr>
</tbody>
</table>
<div id="#rfc.table.5"></div>
<div id="#google-tandem-nb-results"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Tandem narrowband coding: test results</caption>
<thead><tr>
<th class="left">Test Item</th>
<th class="right">Subjective MUSHRA score</th>
<th class="right">95% CI</th>
</tr></thead>
<tbody>
<tr>
<td class="left">Reference</td>
<td class="right">99.47</td>
<td class="right">0.36</td>
</tr>
<tr>
<td class="left">LP3.5</td>
<td class="right">63.49</td>
<td class="right">3.01</td>
</tr>
<tr>
<td class="left">G.711-&gt;Opus</td>
<td class="right">54.51</td>
<td class="right">2.85</td>
</tr>
<tr>
<td class="left">G.711-&gt;AMR</td>
<td class="right">54.13</td>
<td class="right">2.67</td>
</tr>
<tr>
<td class="left">AMR-&gt;G.711-&gt;Opus</td>
<td class="right">51.11</td>
<td class="right">2.74</td>
</tr>
<tr>
<td class="left">Opus-&gt;G.711-&gt;AMR</td>
<td class="right">50.95</td>
<td class="right">2.76</td>
</tr>
<tr>
<td class="left">AMR-&gt;G.711-&gt;AMR</td>
<td class="right">47.81</td>
<td class="right">2.95</td>
</tr>
<tr>
<td class="left">MNRU</td>
<td class="right">14.94</td>
<td class="right">2.21</td>
</tr>
</tbody>
</table>
<div id="#rfc.table.6"></div>
<div id="#google-tandem-wb-conditions"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Tandem wideband coding: test conditions</caption>
<thead><tr>
<th class="left">Condition</th>
<th class="left">Value</th>
</tr></thead>
<tbody>
<tr>
<td class="left">Laboratory</td>
<td class="left">Google</td>
</tr>
<tr>
<td class="left">Examiner</td>
<td class="left">Jan Skoglund</td>
</tr>
<tr>
<td class="left">Date</td>
<td class="left">August and September 2011</td>
</tr>
<tr>
<td class="left">Methodology</td>
<td class="left">MUSHRA</td>
</tr>
<tr>
<td class="left">Reference items</td>
<td class="left">Two male and two female speakers from ITU-T P.501. Two male and two female speakers recorded at Google at 48kHz in a room with low background noise</td>
</tr>
<tr>
<td class="left">Listeners</td>
<td class="left">18 listeners after post-screening / no listener rejects / untrained and trained English speaking listeners</td>
</tr>
<tr>
<td class="left">Anchor 1</td>
<td class="left">Reference file lowpass-filtered at 3.5 kHz (LP 3.5)</td>
</tr>
<tr>
<td class="left">Anchor 2</td>
<td class="left">Reference file lowpass-filtered at 7 kHz (LP 7)</td>
</tr>
<tr>
<td class="left">Test Condition 1</td>
<td class="left">Opus WB at 19.85 kbps, variable bit rate (Opus)</td>
</tr>
<tr>
<td class="left">Test Condition 2</td>
<td class="left">AMR WB at 19.85 kbps, constant bit rate (AMR WB)</td>
</tr>
<tr>
<td class="left">Test Condition 3</td>
<td class="left">AMR WB at 19.85 kbps &gt; Opus WB at 19.85 kbps</td>
</tr>
<tr>
<td class="left">Test Condition 4</td>
<td class="left">Opus WB at 19.85 kbps -&gt; AMR WB at 19.85 kbps</td>
</tr>
</tbody>
</table>
<div id="#rfc.table.7"></div>
<div id="#google-tandem-wb-results"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Tandem wideband coding: test results</caption>
<thead><tr>
<th class="center">Test Item</th>
<th class="center">Subjective BS.1587 Score</th>
<th class="center">95% CI</th>
</tr></thead>
<tbody>
<tr>
<td class="center">Reference</td>
<td class="center">99.44</td>
<td class="center">0.38</td>
</tr>
<tr>
<td class="center">Opus</td>
<td class="center">78.38</td>
<td class="center">2.16</td>
</tr>
<tr>
<td class="center">LP7</td>
<td class="center">74.24</td>
<td class="center">2.24</td>
</tr>
<tr>
<td class="center">AMR WB</td>
<td class="center">65.26</td>
<td class="center">2.85</td>
</tr>
<tr>
<td class="center">AMR WB-&gt;Opus</td>
<td class="center">63.97</td>
<td class="center">2.95</td>
</tr>
<tr>
<td class="center">Opus-&gt;AMR WB</td>
<td class="center">62.83</td>
<td class="center">2.94</td>
</tr>
<tr>
<td class="center">LP3.5</td>
<td class="center">37.01</td>
<td class="center">2.95</td>
</tr>
</tbody>
</table>
<p id="rfc.section.2.1.4.p.3">Under the given statistical confidence, narrowband tandem coding condition using AMR and/or Opus are of similar quality. However, the results have indications that Opus outperforms AMR NB slightly. In any case, narrow band transcoding is worse than a low pass filtering at 3.5kbps.</p>
<p id="rfc.section.2.1.4.p.4">Opus at 20kbps outperforms AMR WB at a similar coding rate and matches the quality of a 7kHz lowpass filtered signal. Tandem coding with Opus does not reduce the quality of AMR WB encoded speech in the studied conditions.</p>
<h1 id="rfc.section.2.1.5">
<a href="#rfc.section.2.1.5">2.1.5.</a> <a href="#opus-google-mandarin" id="opus-google-mandarin">Google mandarin tests</a>
</h1>
<p id="rfc.section.2.1.5.p.1">Modern Standard Chinese - also called Mandarin - is a tonal language that is spoken by about 845 million persons. In past, codecs have been developed without consideration of the unique properties of tonal languages. For the testing of Opus, Jan Skoglund has conducted subjective listening-only tests to verify <a href="#Skoglund2011">whether Opus can cope well for Mandarin</a> <cite title="NONE">[Skoglund2011]</cite>. Two tests were conducted for both narrow- and wide-band speech items. The test conditions of the narrow-band tests are given in Table </p>
<div id="#rfc.table.8"></div>
<div id="#google-mandarin-nb-conditions"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Narrowband mandarin: test conditions</caption>
<thead><tr>
<th class="left">Condition</th>
<th class="left">Value</th>
</tr></thead>
<tbody>
<tr>
<td class="left">Laboratory</td>
<td class="left">Google</td>
</tr>
<tr>
<td class="left">Examiner</td>
<td class="left">Jan Skoglund</td>
</tr>
<tr>
<td class="left">Date</td>
<td class="left">August and September 2011</td>
</tr>
<tr>
<td class="left">Methodology</td>
<td class="left">ITU-R BS.1534-1 (MUSHRA)</td>
</tr>
<tr>
<td class="left">Reference items</td>
<td class="left">Two male and two female speakers from ITU-T P.501. Two male and two female speakers recorded at Google at 48kHz in a room with low background noise.</td>
</tr>
<tr>
<td class="left">Listeners</td>
<td class="left">21 listeners after post-screening / no listeners rejected / untrained Mandarin-speaking listeners</td>
</tr>
<tr>
<td class="left">Anchor 1</td>
<td class="left">Reference file lowpass-filtered at 3.5 kHz (LP 3.5)</td>
</tr>
<tr>
<td class="left">Anchor 2</td>
<td class="left">Reference file resampled at 8 kHz, with MNRU at 15 dB SNR (MNRU)</td>
</tr>
<tr>
<td class="left">Test Condition 1</td>
<td class="left">Opus NB at 11 kbps, variable bit rate (Opus 11)</td>
</tr>
<tr>
<td class="left">Test Condition 2</td>
<td class="left">Speex NB at 11 kbps, variable bit rate (Speex 11)</td>
</tr>
<tr>
<td class="left">Test Condition 3</td>
<td class="left">iLBC at 15.2 kbps, constant bit rate (iBLC 15)</td>
</tr>
</tbody>
</table>
<div id="#rfc.table.9"></div>
<div id="#google-mandarin-nb-results"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Mandarin narrowband speech: test results</caption>
<thead><tr>
<th class="left">Test Item</th>
<th class="right">Subjective BS.1534-1 Score</th>
<th class="right">95% CI</th>
</tr></thead>
<tbody>
<tr>
<td class="left">Reference</td>
<td class="right">99.79</td>
<td class="right">0.19</td>
</tr>
<tr>
<td class="left">Opus 11</td>
<td class="right">77.90</td>
<td class="right">2.15</td>
</tr>
<tr>
<td class="left">iLBC 15</td>
<td class="right">76.76</td>
<td class="right">2.08</td>
</tr>
<tr>
<td class="left">LP 3.5</td>
<td class="right">76.25</td>
<td class="right">2.34</td>
</tr>
<tr>
<td class="left">Speex 11</td>
<td class="right">63.60</td>
<td class="right">3.30</td>
</tr>
<tr>
<td class="left">MNRU</td>
<td class="right">22.83</td>
<td class="right">2.50</td>
</tr>
</tbody>
</table>
<div id="#rfc.table.10"></div>
<div id="#google-mandarin-wb-conditions"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Mandarin wideband speech: test conditions</caption>
<thead><tr>
<th class="left">Condition</th>
<th class="left">Value</th>
</tr></thead>
<tbody>
<tr>
<td class="left">Laboratory</td>
<td class="left">Google</td>
</tr>
<tr>
<td class="left">Examiner</td>
<td class="left">Jan Skoglund</td>
</tr>
<tr>
<td class="left">Date</td>
<td class="left">August and September 2011</td>
</tr>
<tr>
<td class="left">Methodology</td>
<td class="left">MUSHRA</td>
</tr>
<tr>
<td class="left">Reference items</td>
<td class="left">Two male and two female speakers from ITU-T P.501. Two male and two female speakers recorded at Google at 48kHz in a room with low background noise</td>
</tr>
<tr>
<td class="left">Listeners</td>
<td class="left">19 listeners after post-screening / Rejected 3 listeners having score correlation with the total average lower than R=0.8.</td>
</tr>
<tr>
<td class="left">Anchor 1</td>
<td class="left">Reference file lowpass-filtered at 3.5 kHz (LP 3.5)</td>
</tr>
<tr>
<td class="left">Anchor 2</td>
<td class="left">Reference file lowpass-filtered at 7 kHz (LP 7)</td>
</tr>
<tr>
<td class="left">Test Condition 1</td>
<td class="left">Opus WB at 19.85 kbps, variable bit rate (Opus 20)</td>
</tr>
<tr>
<td class="left">Test Condition 2</td>
<td class="left">Speex WB at 23.8 kbps, constant bit rate (Speex 24)</td>
</tr>
<tr>
<td class="left">Test Condition 3</td>
<td class="left">G.722.1 at 24 kbps, constant bit rate (G.722.1 24)</td>
</tr>
<tr>
<td class="left">Test Condition 4</td>
<td class="left">Opus FB at 32 kbps, constant bit rate (Opus 32)</td>
</tr>
<tr>
<td class="left">Test Condition 5</td>
<td class="left">G.719 at 32 kbps, constant bit rate (G.719 32)</td>
</tr>
</tbody>
</table>
<div id="#rfc.table.11"></div>
<div id="#google-mandarin-wb-results"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Mandarin wideband speech: test results</caption>
<thead><tr>
<th class="center">Test Item</th>
<th class="center">Subjective BS.1587 Score</th>
<th class="center">95% CI</th>
</tr></thead>
<tbody>
<tr>
<td class="center">Reference</td>
<td class="center">98.95</td>
<td class="center">0.59</td>
</tr>
<tr>
<td class="center">Opus 32</td>
<td class="center">98.13</td>
<td class="center">0.72</td>
</tr>
<tr>
<td class="center">G.719 32</td>
<td class="center">93.43</td>
<td class="center">1.51</td>
</tr>
<tr>
<td class="center">Opus 20</td>
<td class="center">81.59</td>
<td class="center">2.48</td>
</tr>
<tr>
<td class="center">LP 7</td>
<td class="center">79.51</td>
<td class="center">2.53</td>
</tr>
<tr>
<td class="center">G.722.1 24</td>
<td class="center">72.55</td>
<td class="center">3.06</td>
</tr>
<tr>
<td class="center">LP 3.5</td>
<td class="center">54.57</td>
<td class="center">3.44</td>
</tr>
<tr>
<td class="center">Speex 24</td>
<td class="center">53.63</td>
<td class="center">4.23</td>
</tr>
</tbody>
</table>
<p id="rfc.section.2.1.5.p.2">Under the given confidence intervals, the quality of Opus at 11 kbps equals the quality of iLBC at 15 kbps and the quality aferlowpass filtering at 3.5 kHz. Speex at 11 kbps does not perform as well. According to the listening-only tests, Opus at 32 kbps is better than G.719 at 32 kbps. Opus at 20 kbps outperforms G.722.1 and Speex at 24 kbps. If one compares the Mandarin results with those for English (<a href="#opus-google-narrowband">Section 2.1.1</a> and <a href="#opus-google-wideband">Section 2.1.2</a>), one can see that are pretty consistent. The only difference is that using English stimuli Opus at 20 kbps outperforms G.719 at 32 kbps. Probabily, this is due to the fact that Mandarin speech does not contain as many high frequency-rich consonants such as [s] as English.</p>
<h1 id="rfc.section.2.2">
<a href="#rfc.section.2.2">2.2.</a> <a href="#opus-ha" id="opus-ha">HydrogenAudio stereo music listening test</a>
</h1>
<p id="rfc.section.2.2.p.1">In March 2011, the HydrogenAudio community conducted a listening test comparing codec performance on <a href="#ha-test">stereo audio at 64 kb/s</a> <cite title="NONE">[ha-test]</cite>. The Opus codec was compared to the Apple and Nero implementations of HE-AAC, as well as to the Vorbis codec. The test included 30 audio samples, including known "hard to code" samples from previous HydrogenAudio listening tests.</p>
<p id="rfc.section.2.2.p.2">A total of 33 listeners participated in the test, 10 of which provided results for all the audio samples. The results of test showed that Opus out-performed both HE-AAC implementations as well as Vorbis.</p>
<h1 id="rfc.section.2.3">
<a href="#rfc.section.2.3">2.3.</a> <a href="#nokia-2011" id="nokia-2011">Nokia Interspeech 2011 listening test</a>
</h1>
<p id="rfc.section.2.3.p.1">In 2011, Anssi Ramo from Nokia <a href="#Ramo2011">submitted</a> <cite title="NONE">[Ramo2011]</cite> the results of a second listening test, focusing specifically on the Opus codec, to Interspeech 2011. As in the previous test, the methodology used was a 9-scale ACR MOS test with clean and noisy speech samples.</p>
<p id="rfc.section.2.3.p.2">The results show Opus clearly out-performing both G.722.1C and G.719 on clean speech at 24 kb/s and above, while on noisy speech all codecs and bit-rates above 24 kb/s are very close. It is also found that the Opus hybrid mode at 28 kb/s has quality that is very close to the recent G.718B standard at the same rate. At 20 kb/s, the Opus wideband mode also out-performs AMR-WB, while the situation is reversed for 12 kb/s and below. The only narrowband rate tested is 6 kb/s, which is below what Opus targets and unsurprisingly shows poorer quality than AMR-NB at 5.9 kb/s.M</p>
<h1 id="rfc.section.2.4">
<a href="#rfc.section.2.4">2.4.</a> <a href="#hoene-2011" id="hoene-2011">Universitaet Tuebingen stereo and binaural tests</a>
</h1>
<p id="rfc.section.2.4.p.1">Modern teleconferencing system use stereo or spatialy rendered speech to enhance the conversation quality. Then, talkers can be identified according to their acoustic locations. Opus allows to encode speech in a stereo mode. In the tests conducted by Christian Hoene<a href="#Hoene2011">[Hoene2011]</a>, the performance of Opus coding stereo and binaural speech was studied.</p>
<div id="#rfc.table.12"></div>
<div id="#tuebingen-binaural-conditions"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Stereo and binaural speech coding: test conditions</caption>
<thead><tr>
<th class="left">Condition</th>
<th class="left">Value</th>
</tr></thead>
<tbody>
<tr>
<td class="left">Laboratory</td>
<td class="left">Univesitaet Tuebingen</td>
</tr>
<tr>
<td class="left">Examiner</td>
<td class="left">Christian Hoene and Mansoor Hyder</td>
</tr>
<tr>
<td class="left">Date</td>
<td class="left">August 2011</td>
</tr>
<tr>
<td class="left">Methodology</td>
<td class="left">ITU-R BS.1534-1 (MUSHRA) using a modified "rateit v0.1" software with German translations.</td>
</tr>
<tr>
<td class="left">Reference items</td>
<td class="left">One German female voice recorded in stereo (8s). Two female voices (stereo recording) mixed together (9 s). One moving talker binaural rendered with HTRF and an artificial room impulse response (13 s). Two voices binaural render at two different stationary positions. Acappella Song "Mein Fahrrad" by "Die Prinzen" (10.5s, mono)</td>
</tr>
<tr>
<td class="left">Listeners</td>
<td class="left">20 German native speakers. Age between 20 and 59 (avg. 30.55). 9 male and 11 female. All have academic background. Three listeners were rejected because their rating showed a low correlation (R&lt;0.8) to the average ratings.</td>
</tr>
<tr>
<td class="left">Anchor</td>
<td class="left">Reference file lowpass-filtered at 3.5 kHz calling "sox in.wav -r48000 -c1 out.wav lowpass 3500"</td>
</tr>
<tr>
<td class="left">Test Condition 1</td>
<td class="left">Opus in the SILK mode, 12kbps, stereo, 60ms calling "draft-ietf-codec-opus-07/test_opus 0 48000 2 12000 -cbr -framesize 60 -bandwidth NB"</td>
</tr>
<tr>
<td class="left">Test Condition 2</td>
<td class="left">Opus in the SILK mode, 16kbps, stereo, 20ms calling "draft-ietf-codec-opus-07/test_opus 0 48000 2 16000 -cbr -framesize 20 -bandwidth WB"</td>
</tr>
<tr>
<td class="left">Test Condition 3</td>
<td class="left">Opus in the HYBRID mode, 32kbps, stereo, 20ms calling "draft-ietf-codec-opus-07/test_opus 0 48000 2 32000 -cbr -framesize 20 -bandwidth FB"</td>
</tr>
<tr>
<td class="left">Test Condition 4</td>
<td class="left">Opus in the CELT mode, 64kbps, stereo, 20ms calling "draft-ietf-codec-opus-07/test_opus 1 48000 2 64000 -cbr -framesize 20 -bandwidth FB"</td>
</tr>
<tr>
<td class="left">Test Condition 5</td>
<td class="left">AMR-WB+ at 12kbps, 80ms using 26304_ANSI-C_source_code_v6_6_0: Arguments: -rate 12</td>
</tr>
<tr>
<td class="left">Test Condition 6</td>
<td class="left">AMR-WB+ at 15.2kbps, 80ms using 26304_ANSI-C_source_code_v6_6_0: Arguments: -rate 16</td>
</tr>
<tr>
<td class="left">Test Condition 7</td>
<td class="left">AMR-WB+ at 32kbps, 60ms using 26304_ANSI-C_source_code_v6_6_0: Arguments: -rate 32</td>
</tr>
</tbody>
</table>
<div id="#rfc.table.13"></div>
<div id="#tuebingen-binaural-results"></div>
<table cellpadding="3" cellspacing="0" class="tt full center">
<caption>Binaural Speech: Test Results</caption>
<thead><tr>
<th class="left">Test Item</th>
<th class="right">Subjective BS.1534-1 Score</th>
<th class="right">95% CI</th>
</tr></thead>
<tbody>
<tr>
<td class="left">Reference</td>
<td class="right">97.36</td>
<td class="right">1.31</td>
</tr>
<tr>
<td class="left">Opus 64</td>
<td class="right">95.58</td>
<td class="right">1.76</td>
</tr>
<tr>
<td class="left">AMR-WB+ 32</td>
<td class="right">80.11</td>
<td class="right">4.79</td>
</tr>
<tr>
<td class="left">Opus 32</td>
<td class="right">55.42</td>
<td class="right">5.96</td>
</tr>
<tr>
<td class="left">AMR-WB+ 16</td>
<td class="right">49.69</td>
<td class="right">6.05</td>
</tr>
<tr>
<td class="left">LP 3.5</td>
<td class="right">48.35</td>
<td class="right">4.50</td>
</tr>
<tr>
<td class="left">Opus 16</td>
<td class="right">39.31</td>
<td class="right">4.80</td>
</tr>
<tr>
<td class="left">AMR-WP+ 12</td>
<td class="right">35.40</td>
<td class="right">5.79</td>
</tr>
<tr>
<td class="left">Opus 12</td>
<td class="right">16.99</td>
<td class="right">3.49</td>
</tr>
</tbody>
</table>
<p id="rfc.section.2.4.p.2">According to the test results, Opus transmits binaural content well at 64kbps. The other Opus results are not valid anymore as the codec implementation have been updated.</p>
<h1 id="rfc.section.3">
<a href="#rfc.section.3">3.</a> Conclusion on the requirements</h1>
<p id="rfc.section.3.p.1">The requirements call for the Opus codec to be better than Speex and iLBC in narrowband mode, better than Speex and G.722.1 in wideband mode, and better than G.722.1C in super-wideband/fullband mode.</p>
<h1 id="rfc.section.3.1">
<a href="#rfc.section.3.1">3.1.</a> Comparison to Speex (narrowband)</h1>
<p id="rfc.section.3.1.p.1">The Opus codec was compared to Speex in narrowband mode in the <a href="#opus-google-narrowband">Google narrowband test</a> <cite title="NONE">[opus-google-narrowband]</cite>.  This test showed that Opus at 11 kb/s was significantly better than Speex at the same rate. In fact, Opus at 11 kb/s was tied with the 3.5 low-pass of the original. Considering the results, we conclude that the Opus codec is better than the Speex codec.</p>
<h1 id="rfc.section.3.2">
<a href="#rfc.section.3.2">3.2.</a> Comparison to iLBC</h1>
<p id="rfc.section.3.2.p.1">The Opus codec was compared to iLBC in the <a href="#opus-google-narrowband">Google narrowband test</a> <cite title="NONE">[opus-google-narrowband]</cite>. This test showed that Opus at 11 kb/s was significantly better than iLBC running at 15 kb/s. Considering the results, we conclude that the Opus codec is better than the iLBC codec.</p>
<h1 id="rfc.section.3.3">
<a href="#rfc.section.3.3">3.3.</a> Comparison to Speex (wideband)</h1>
<p id="rfc.section.3.3.p.1">The Opus codec was compared to Speex in wideband mode in the <a href="#opus-google-wideband">Google wideband and fullband test</a> <cite title="NONE">[opus-google-wideband]</cite>. This test showed that Opus at 20 kb/s was significantly better than Speex at at 24 kb/s. In fact, Opus at 20 kb/s was better than the 7 kHz low-pass of the original. These results are consistent with an earlier <a href="#silk-dynastat">Dynastat test</a> <cite title="NONE">[silk-dynastat]</cite> that also concluded that SILK had significantly higher quality than Speex in wideband mode at the same bit-rate. Considering the results, we conclude that the Opus codec is better than the Speex codec for wideband.</p>
<h1 id="rfc.section.3.4">
<a href="#rfc.section.3.4">3.4.</a> Comparison to G.722.1</h1>
<p id="rfc.section.3.4.p.1">In the <a href="#opus-google-wideband">Google wideband and fullband test</a> <cite title="NONE">[opus-google-wideband]</cite>, Opus at 20 kb/s was shown to significantly out-perform G.722.1 operating at 24 kb/s. An indirect comparison point also comes from the <a href="#nokia-2011">Nokia Interspeech 2011 listening test</a> <cite title="NONE">[nokia-2011]</cite> that shows Opus out-performing AMR-WB at 20 kb/s, while AMR-WB is known to out-perform G.722.1. Considering these results, we conclude that the Opus codec is better than the G.722.1 codec for wideband.</p>
<h1 id="rfc.section.3.5">
<a href="#rfc.section.3.5">3.5.</a> Comparison to G.722.1C</h1>
<p id="rfc.section.3.5.p.1">Opus has been compared to G.722.1C in multiple listening tests. As early as 2008, an <a href="#celt-aslp">old version of the CELT codec</a> <cite title="NONE">[celt-aslp]</cite> using very short frames was found to have higher quality than G.722.1C at 48 kb/s. More recently, the <a href="#nokia-2011">Nokia Interspeech 2011 listening test</a> <cite title="NONE">[nokia-2011]</cite> showed that Opus out-performed G.722.1C at 24 kb/s, 32 kb/s, and 48 kb/s. We thus conclude that the Opus codec is better than the G.722.1C codec for superwideband/fullband audio.</p>
<h1 id="rfc.section.3.6">
<a href="#rfc.section.3.6">3.6.</a> Comparison to AMR-NB</h1>
<p id="rfc.section.3.6.p.1">In the <a href="#opus-google-narrowband">Google narrowband test</a> <cite title="NONE">[opus-google-narrowband]</cite>, Opus was shown to out-perform AMR-NB at 12 kb/s. On the other hand, in the <a href="#nokia-2011">Nokia Interspeech 2011 listening test</a> <cite title="NONE">[nokia-2011]</cite>, AMB-NB was found to have better quality than Opus at 6 kb/s. This indicates that Opus is better than AMR-NB at higher rates and worse at lower rates, which is to be expected given Opus' emphasis on higher quality and higher rates.</p>
<h1 id="rfc.section.3.7">
<a href="#rfc.section.3.7">3.7.</a> Comparison to AMR-WB</h1>
<p id="rfc.section.3.7.p.1">In the <a href="#opus-google-wideband">Google wideband and fullband test</a> <cite title="NONE">[opus-google-wideband]</cite>, Opus at 20 kb/s was shown to out-perform AMR-WB at the same rate. This was also confirmed by the <a href="#nokia-2011">Nokia Interspeech 2011 listening test</a> <cite title="NONE">[nokia-2011]</cite>, with also found AMR-WB to out-perform Opus at 12 kb/s and below. As with AMR-NB, we conclude that Opus is better than AMR-WB at higher rates and worse at lower rates.</p>
<h1 id="rfc.section.4">
<a href="#rfc.section.4">4.</a> <a href="#Security%20Considerations" id="Security Considerations">Security Considerations</a>
</h1>
<p id="rfc.section.4.p.1">No security considerations.</p>
<h1 id="rfc.section.5">
<a href="#rfc.section.5">5.</a> IANA Considerations </h1>
<p id="rfc.section.5.p.1">This document has no actions for IANA.</p>
<h1 id="rfc.section.6">
<a href="#rfc.section.6">6.</a> <a href="#Acknowledgments" id="Acknowledgments">Acknowledgments</a>
</h1>
<p id="rfc.section.6.p.1">The authors would like to thank Anssi Ramo and the HydrogenAudio community, who conducted some of the Opus listening test cited in this draft.</p>
<h1 id="rfc.references">
<a href="#rfc.references">7.</a> References</h1>
<table><tbody>
<tr>
<td class="reference"><b id="valin2010">[valin2010]</b></td>
<td class="top">
<a>Valin, J.M.</a>, <a>Terriberry, T.</a>, <a>Montgomery, C.</a> and <a>G. Maxwell</a>, "<a>A High-Quality Speech and Audio Codec With Less Than 10 ms delay</a>",  2010, .</td>
</tr>
<tr>
<td class="reference"><b id="valin2009">[valin2009]</b></td>
<td class="top">
<a>Valin, J.M.</a>, <a>Terriberry, T.</a> and <a>G. Maxwell</a>, "<a>A High-Quality Speech and Audio Codec With Less Than 10 ms delay</a>",  2010, .</td>
</tr>
<tr>
<td class="reference"><b id="Wustenhagen2010">[Wustenhagen2010]</b></td>
<td class="top">
<a>W&#252;stenhagen, U.</a>, <a>Feiten, B.</a>, <a>Kroll, J.</a>, <a>Raake, A.</a> and <a>M. W&#228;ltermann</a>, "<a>Evaluation of Super-Wideband Speech and Audio Codecs</a>",  2010, .</td>
</tr>
<tr>
<td class="reference"><b id="Ramo2010">[Ramo2010]</b></td>
<td class="top">
<a>Ramo, A.</a> and <a>H. Toukomaa</a>, "<a>Voice Quality Evaluation of Recent Open Source Codecs</a>",  2010, .</td>
</tr>
<tr>
<td class="reference"><b id="Ramo2011">[Ramo2011]</b></td>
<td class="top">
<a>Ramo, A.</a> and <a>H. Toukomaa</a>, "<a>Voice Quality Characterization of IETF Opus Codec</a>",  2011, .</td>
</tr>
<tr>
<td class="reference"><b id="Maastricht-78">[Maastricht-78]</b></td>
<td class="top">
<a>Valin, J.M.</a> and <a>K. Vos</a>, "<a>Codec Prototype</a>",  2010, .</td>
</tr>
<tr>
<td class="reference"><b id="Prague-80">[Prague-80]</b></td>
<td class="top">
<a>Chen, R.</a>, <a>Terriberry, T.</a>, <a>Maxwell, G.</a>, <a>Skoglund, J.</a> and <a>H. Nguyet</a>, "<a>Testing results</a>",  2011, .</td>
</tr>
<tr>
<td class="reference"><b id="SILK-Dynastat">[SILK-Dynastat]</b></td>
<td class="top">
<a>Skype, </a>, "<a>SILK Datasheet</a>",  2009, .</td>
</tr>
<tr>
<td class="reference"><b id="ha-test">[ha-test]</b></td>
<td class="top">
<a>Dyakonov, </a>, "<a>Results of the public multiformat listening test @ 64 kbps</a>",  2011, .</td>
</tr>
<tr>
<td class="reference"><b id="Skoglund2011">[Skoglund2011]</b></td>
<td class="top">
<a title="Google">Skoglund, </a>, "<a>Listening tests of Opus at Google</a>", September 2011.</td>
</tr>
<tr>
<td class="reference"><b id="Hoene2011">[Hoene2011]</b></td>
<td class="top">
<a title="Universitaet Tuebingen">Hoene, </a> and <a title="Universitaet Tuebingen"> Hyder</a>, "<a>MUSHRA Listening Tests - Focusing on Stereo Voice Coding</a>", August 2011.</td>
</tr>
</tbody></table>
<h1 id="rfc.appendix.Appendix A">
<a href="#rfc.appendix.Appendix%20A">Appendix A.</a> <a href="#pre-opus" id="pre-opus">Pre-Opus listening tests</a>
</h1>
<p id="rfc.section.Appendix A.p.1">Several listening tests have been performed on the SILK and CELT codecs prior to them being merged as part of the Opus codec.</p>
<h1 id="rfc.appendix.Appendix A.1">
<a href="#rfc.appendix.Appendix%20A.1">Appendix A.1.</a> <a href="#silk-dynastat" id="silk-dynastat">SILK Dynastat listening test</a>
</h1>
<p id="rfc.section.Appendix A.1.p.1">The original (pre-Opus) SILK codec was characterized in a <a href="#SILK-Dynastat">Dynastat listening test</a> <cite title="NONE">[SILK-Dynastat]</cite>. The test included 32 conditions with 4 male and 4 female talkers. The test signals were wideband speech with and without office background noise at 15 dB SNR. Packet loss was tested at 2, 5, and 10% loss rates. The bitrates ranged from 8.85 kb/s to 64 kb/s. The codecs included in the test were SILK-WB, AMR-WB, Speex-WB and G.722 (which ran at 64 kb/s).</p>
<p id="rfc.section.Appendix A.1.p.2">The results showed that for clean speech (1) SILK out-performs AMR-WB at all bit-rates except 8.85 kb/s (which was a tie); (2) SILK out-performs Speex at all bit-rates; and (3) SILK running at 18.25 kb/s and above out-performs G.722 at 64 kbps. For noisy speech, tested at 18.25 kb/s, SILK is tied with AMR-WB, and out-performs Speex. For 2, 5 and 10% packet loss, tested at 18.25 kb/s, SILK out-performs both AMR-WB and Speex in all conditions.</p>
<h1 id="rfc.appendix.Appendix A.2">
<a href="#rfc.appendix.Appendix%20A.2">Appendix A.2.</a> <a href="#silk-deutsche-telekom" id="silk-deutsche-telekom">SILK Deutsche Telekom test</a>
</h1>
<p id="rfc.section.Appendix A.2.p.1">In 2010 Deutsche Telekom published <a href="#Wustenhagen2010">results</a> <cite title="NONE">[Wustenhagen2010]</cite> of their evaulation of super-wideband speech and audio codecs. The test included the version of SILK submitted to the IETF. The results showed that for clean speech (item "speechsample") SILK was tied with AMR-WB and G.718, and out-performed Speex. For noisy speech (item "arbeit") SILK out-performed AMR-WB and G.718 at 12 and 24 kb/s, and Speex at all bitrates. At bitrates above 24 kb/s SILK and G.718 were tied.</p>
<h1 id="rfc.appendix.Appendix A.3">
<a href="#rfc.appendix.Appendix%20A.3">Appendix A.3.</a> <a href="#silk-nokia" id="silk-nokia">SILK Nokia test</a>
</h1>
<p id="rfc.section.Appendix A.3.p.1">In 2010, Anssi Ramo from Nokia <a href="#Ramo2010">presented</a> <cite title="NONE">[Ramo2010]</cite> the results of a listening test focusing on open-source codecs at Interspeech 2010. The methodology used was a 9-scale ACR MOS test with clean and noisy speech samples.</p>
<p id="rfc.section.Appendix A.3.p.2">It was noted in the test that:</p>
<p id="rfc.section.Appendix A.3.p.3">"Especially at around 16 kbit/s or above Silk is better than AMR-WB at comparable bitrates. This is due to the fact that Silk wideband is critically sampled up to 8 kHz instead of ITU- T or 3GPP defined 7 kHz. This added bandwidth (from 7 to 8 kHz) shows up in the results favourable to Silk. It seems that Silk provides quite artifact free voice quality for the whole 16- 24 kbit/s range with WB signals. At 32 and 40 kbit/s Silk is SWB and competes quite equally against G.718B or G.722.1C although having a slightly narrower bandwidth than the ITU-T standardized codecs."</p>
<h1 id="rfc.appendix.Appendix A.4">
<a href="#rfc.appendix.Appendix%20A.4">Appendix A.4.</a> <a href="#celt-aslp" id="celt-aslp">CELT 0.3.2 listening test</a>
</h1>
<p id="rfc.section.Appendix A.4.p.1">The first listening tests conducted on CELT version 0.3.2 in 2009 and <a href="#valin2010">published in 2010</a> <cite title="NONE">[valin2010]</cite> included AAC-LD (Apple), G.722.1C and MP3 (Lame). Two MUSHRA tests were conducted: a 48 kb/s test and a 64 kb/s test, both at a 44.1 kHz sampling rate.  CELT was used with 256-sample frames (5.8 ms). All codecs used constant bit-rate (CBR). The algorithmic delay was 8.7 ms for CELT, 34.8 ms for AAC-LD, 40 ms for G.722.1C and more than 100 ms for MP3.</p>
<p id="rfc.section.Appendix A.4.p.2">The 48 kb/s test included two clean speech samples (one male, one female) from the EBU SQAM database, four clean speech files (two male, two female) from the NTT multi-lingual speech database for telephonometry, and two music samples. In this test, CELT out-performed AAC-LD, G.722.1C and MP3.</p>
<p id="rfc.section.Appendix A.4.p.3">The 64 kb/s test included two clean speech samples (one male, one female) from the EBU SQAM database, and six music files. In this test, AAC-LD out-performed CELT, but CELT out-performed both MP3 and G.722.1C (running at its highest rate of 48 kb/s).</p>
<h1 id="rfc.appendix.Appendix A.5">
<a href="#rfc.appendix.Appendix%20A.5">Appendix A.5.</a> <a href="#celt-eusipco" id="celt-eusipco">CELT 0.5.0 listening test</a>
</h1>
<p id="rfc.section.Appendix A.5.p.1">Another CELT listening test was conducted in 2009 on version 0.5.0 and <a href="#valin2009">presented at EUSIPCO 2009</a> <cite title="NONE">[valin2009]</cite>. In that test, CELT was compared to G.722.1C and to the Fraunhofer Ultra Low-Delay (ULD) codec on 9 audio samples: 2 clean speech samples and 7 music samples. At 64 kb/s with 5.3 ms frames, CELT clearly out-performed G.722.1C running at 48 kb/s with 20 ms frames. Also, at 96 kb/s and equal frame size (2.7 ms), CELT clearly out-performed the ULD codec.</p>
<h1 id="rfc.appendix.Appendix B">
<a href="#rfc.appendix.Appendix%20B">Appendix B.</a> <a href="#opus-nonfinal" id="opus-nonfinal">Opus listening tests on non-final bit-stream</a>
</h1>
<p id="rfc.section.Appendix B.p.1">The following listening tests were conducted on the Opus codec on versions prior to the bit-stream freeze. While Opus has evolved since these tests were conducted, the results should be considered as a <em>lower bound</em> on the quality of the final codec.</p>
<h1 id="rfc.appendix.Appendix B.1">
<a href="#rfc.appendix.Appendix%20B.1">Appendix B.1.</a> <a href="#opus-maastricht" id="opus-maastricht">First hybrid mode test</a>
</h1>
<p id="rfc.section.Appendix B.1.p.1">In July 2010, the Opus codec authors conducted a preliminary MUSHRA listening test to evaluate the quality of the recently created "hybrid" mode combining the SILK and CELT codecs. That test was conducted at 32 kb/s and compared the following codecs: </p>

<ul>
<li>Opus hybrid mode (fullband)</li>
<li>G.719 (fullband)</li>
<li>CELT (fullband)</li>
<li>SILK (wideband)</li>
<li>BroadVoice32 (wideband)</li>
</ul>
<p id="rfc.section.Appendix B.1.p.2">The test material consisted of two English speech samples from the EBU SQAM (one male, one female) database and six speech samples (three male, three female) from the NTT multi-lingual speech database for telephonometry. Although only eight listeners participated to the test, the difference between the Opus hybrid mode and all other codecs was large enough to obtain 95% confidence that the Opus hybrid mode provided better quality than all other codecs tested. This test is of interest because it shows that the hybrid clearly out-performs the codecs that it combines (SILK and CELT). It also out-performs G.719, which is the only fullband interactive codec standardized by the ITU-T. These results were <a href="#Maastricht-78">presented</a> <cite title="NONE">[Maastricht-78]</cite> at the 78th IETF meeting Maastricht.</p>
<h1 id="rfc.appendix.Appendix B.2">
<a href="#rfc.appendix.Appendix%20B.2">Appendix B.2.</a> <a href="#opus-broadcom" id="opus-broadcom">Broadcom stereo music test</a>
</h1>
<p id="rfc.section.Appendix B.2.p.1">In December 2010, Broadcom conducted an ITU-R BS.1116-style subjective listening test comparing different configurations of the CELT-only mode of the IETF Opus codec along with MP3 and AAC-LC. The test included stereo 10 audio samples sampled at 44.1 kHz and distributed as follows: </p>

<ul>
<li>2 pure speech</li>
<li>2 vocal</li>
<li>2 solo instruments</li>
<li>1 rock-and-roll</li>
<li>1 pop</li>
<li>1 classical orchestra</li>
<li>1 jazz</li>
</ul>
<p id="rfc.section.Appendix B.2.p.2">A total of 17 listeners participated to the test. The results of the test are a available on the testing slides <a href="#Prague-80">presented at the Prague meeting</a> <cite title="NONE">[Prague-80]</cite>. Although at the time, Opus was not properly optimised for 44.1 kHz audio, the quality of the Opus codec at 96 kb/s with 22 ms frame was significantly better than MP3 and only slightly worse than AAC-LC.  Even in ultra low-delay mode (5.4 ms), Opus still outperformed MP3.  The test also confirmed the usefulness of the prefilter/postfilter contribution by Raymond Chen, showing that this contribution significantly improves quality for small frames (long frames were not tested with the prefilter/postfilter disabled).</p>
<h1 id="rfc.appendix.Appendix C">
<a href="#rfc.appendix.Appendix%20C">Appendix C.</a> <a href="#field" id="field">In-the-field testing</a>
</h1>
<p id="rfc.section.Appendix C.p.1">Various versions of Opus (or SILK/CELT components) are currently in use in production in the following applications: </p>

<ul>
<li>Skype: VoIP client used by hundreds of millions of people</li>
<li>Steam: Gaming distribution and communications platform with over 30 million users</li>
<li>Mumble: Gaming VoIP client with more than 200 thousand users</li>
<li>Soundjack: Client for live network music performances</li>
<li>Freeswitch: Open-source telephony platform</li>
<li>Ekiga: Open-source VoIP client</li>
<li>CHNC: Radio station using CELT for its studio-transmitter link</li>
</ul>
<h1 id="rfc.authors"><a href="#rfc.authors">Authors' Addresses</a></h1>
<div class="avoidbreak">
  <address class="vcard">
	<span class="vcardline">
	  <span class="fn">Christian Hoene</span> editor
	  <span class="n hidden">
		<span class="family-name">Hoene</span>
	  </span>
	</span>
	<span class="org vcardline">Universitaet Tuebingen</span>
	<span class="adr">
	  <span>Sand 13</span>

	  <span class="vcardline">
		<span class="locality">Tuebingen</span>,  
		<span class="region"></span>
		<span class="code">72076</span>
	  </span>
	  <span class="country-name vcardline">Germany</span>
	</span>
	<span class="vcardline">EMail: <a href="mailto:hoene@uni-tuebingen.de">hoene@uni-tuebingen.de</a></span>

  </address>
</div><div class="avoidbreak">
  <address class="vcard">
	<span class="vcardline">
	  <span class="fn">Jean-Marc Valin</span> 
	  <span class="n hidden">
		<span class="family-name">Valin</span>
	  </span>
	</span>
	<span class="org vcardline">Mozilla Corporation</span>
	<span class="adr">
	  <span>650 Castro Street</span>

	  <span class="vcardline">
		<span class="locality">Mountain View</span>,  
		<span class="region">CA</span> 
		<span class="code">94041</span>
	  </span>
	  <span class="country-name vcardline">USA</span>
	</span>
	<span class="vcardline">Phone: +1 650 903-0800</span>

<span class="vcardline">EMail: <a href="mailto:jmvalin@jmvalin.ca">jmvalin@jmvalin.ca</a></span>

  </address>
</div><div class="avoidbreak">
  <address class="vcard">
	<span class="vcardline">
	  <span class="fn">Koen Vos</span> 
	  <span class="n hidden">
		<span class="family-name">Vos</span>
	  </span>
	</span>
	<span class="org vcardline">Skype Technologies S.A.</span>
	<span class="adr">
	  <span>Stadsgarden 6</span>

	  <span class="vcardline">
		<span class="locality">Stockholm</span>,  
		<span class="region"></span>
		<span class="code">11645</span>
	  </span>
	  <span class="country-name vcardline">Sweden</span>
	</span>
	<span class="vcardline">EMail: <a href="mailto:koen.vos@skype.net">koen.vos@skype.net</a></span>

  </address>
</div><div class="avoidbreak">
  <address class="vcard">
	<span class="vcardline">
	  <span class="fn">Jan Skoglund</span> 
	  <span class="n hidden">
		<span class="family-name">Skoglund</span>
	  </span>
	</span>
	<span class="org vcardline">Google</span>
	<span class="adr">
	  
	  <span class="vcardline">
		<span class="locality"></span> 
		<span class="region"></span>
		<span class="code"></span>
	  </span>
	  <span class="country-name vcardline"></span>
	</span>
	<span class="vcardline">EMail: <a href="mailto:jks@google.com">jks@google.com</a></span>

  </address>
</div>

</body>
</html>