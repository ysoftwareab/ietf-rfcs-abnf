<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE rfc SYSTEM "rfc2629-xhtml.ent">
<rfc xmlns:xi="http://www.w3.org/2001/XInclude" ipr="trust200902"
 docName="draft-ietf-dnsop-serve-stale-10" number="8767" category="std" updates="1034, 1035, 2181" obsoletes="" submissionType="IETF" consensus="true" xml:lang="en" tocInclude="true" symRefs="true" sortRefs="true" version="3">
  <!-- xml2rfc v2v3 conversion 2.39.0 -->
  <front>
    <title abbrev="DNS Serve-Stale">Serving Stale Data to Improve DNS Resiliency</title>

    <seriesInfo name="RFC" value="8767"/>
    <author initials="D." surname="Lawrence" fullname="David C Lawrence">
      <organization>Oracle</organization>
      <address>
        <email>tale@dd.org</email>
      </address>
    </author>
    <author initials="W." surname="Kumari" fullname="Warren &quot;Ace&quot; Kumari">
      <organization>Google</organization>
      <address>
        <postal>
          <street>1600 Amphitheatre Parkway</street>
          <city>Mountain View</city>
          <region>CA</region>
          <code>94043</code>
          <country>United States of America</country>
        </postal>
        <email>warren@kumari.net</email>
      </address>
    </author>
    <author initials="P." surname="Sood" fullname="Puneet Sood">
      <organization>Google</organization>
      <address>
        <email>puneets@google.com</email>
      </address>
    </author>
    <date year="2020" month="March"/>

<keyword>DNS</keyword>
<keyword>DDoS</keyword>
<keyword>Resiliency</keyword>
<keyword>Denial-of-Service</keyword>
<keyword>Expired</keyword>

    <abstract>
      <t>This document defines a method (serve-stale) for recursive resolvers to
use stale DNS data to avoid outages when authoritative nameservers
cannot be reached to refresh expired data. One of the motivations
for serve-stale is to make the DNS more resilient to DoS attacks
and thereby make them less attractive as an attack vector.
This document updates the definitions of TTL from RFCs 1034
and 1035 so that data can be kept in the cache beyond
the TTL expiry; it also updates RFC 2181 by interpreting
values with the high-order bit set as being positive, rather
than 0, and suggests a cap of 7 days.</t>
    </abstract>
  </front>
  <middle>
    <section anchor="introduction" numbered="true" toc="default">
      <name>Introduction</name>
      <t>Traditionally, the Time To Live (TTL) of a DNS Resource Record (RR) has been
understood to represent the maximum number of seconds that a record
can be used before it must be discarded, based on its description and
usage in <xref target="RFC1035" format="default"/> and clarifications in <xref target="RFC2181" format="default"/>.</t>
      <t>This document expands the definition of the TTL
to explicitly allow for expired data to be used in the exceptional
circumstance that a recursive resolver is unable to refresh the
information.  It is predicated on the observation that authoritative
answer unavailability can cause outages even when the underlying data
those servers would return is typically unchanged.</t>
      <t>We describe a method below for this use of stale data, balancing the
competing needs of resiliency and freshness.</t>
      <t>This document updates the definitions of TTL from <xref target="RFC1034" format="default"/>
and <xref target="RFC1035" format="default"/> so that data can be kept in the cache beyond 
the TTL expiry; it also updates <xref target="RFC2181" format="default"/> by interpreting
values with the high-order bit set as being positive, rather
than 0, and also suggests a cap of 7 days.</t>
    </section>
    <section anchor="terminology" numbered="true" toc="default">
      <name>Terminology</name>
       <t>The key words "<bcp14>MUST</bcp14>", "<bcp14>MUST NOT</bcp14>",
       "<bcp14>REQUIRED</bcp14>", "<bcp14>SHALL</bcp14>",
       "<bcp14>SHALL NOT</bcp14>", "<bcp14>SHOULD</bcp14>",
       "<bcp14>SHOULD NOT</bcp14>",
       "<bcp14>RECOMMENDED</bcp14>", "<bcp14>NOT RECOMMENDED</bcp14>",
       "<bcp14>MAY</bcp14>", and "<bcp14>OPTIONAL</bcp14>" in this document
       are to be interpreted as described in BCP&nbsp;14
       <xref target="RFC2119"/> <xref target="RFC8174"/> when, and only
       when, they appear in all capitals, as shown here.</t>
      <t>For a glossary of DNS terms, please see <xref target="RFC8499" format="default"/>.</t>
    </section>
    <section anchor="background" numbered="true" toc="default">
      <name>Background</name>

      <t>There are a number of reasons why an authoritative server may become
unreachable, including Denial-of-Service (DoS) attacks, network
issues, and so on.  If a recursive server is unable to contact the
authoritative servers for a query but still has relevant data that has
aged past its TTL, that information can still be useful for generating
an answer under the metaphorical assumption that "stale bread is
better than no bread."</t>
      <t><xref target="RFC1035" sectionFormat="comma" section="3.2.1"/>
 says that the TTL "specifies the time
interval that the resource record may be cached before the source of
the information should again be consulted." <xref target="RFC1035" sectionFormat="comma" section="4.1.3"/> further
says that the TTL "specifies the time interval (in seconds) that the
resource record may be cached before it should be discarded."</t>
      <t>A natural English interpretation of these remarks would seem to be
clear enough that records past their TTL expiration must not be used.
However, <xref target="RFC1035" format="default"/> predates the more rigorous terminology of
<xref target="RFC2119" format="default"/>, which softened the interpretation of "may" and "should".</t>
      <t><xref target="RFC2181" format="default"/> aimed to provide "the
      precise definition of the Time to
Live," but <xref target="RFC2181" sectionFormat="of" section="8"/>
was mostly concerned with the numeric range of
values rather than data expiration behavior.  It does, however, close
that section by noting, "The TTL specifies a maximum time to live, not
a mandatory time to live."  This wording again does not contain BCP 14
key words <xref target="RFC2119" format="default"/>, but it does convey the natural language
connotation that data becomes unusable past TTL expiry.</t>
      <t>As of the time of this writing, several large-scale operators use stale
data for answers in some way.
 A number of recursive resolver packages,
including BIND, Knot Resolver, OpenDNS, and Unbound, provide options to use stale data.
Apple macOS can also use stale data as part of the Happy Eyeballs algorithms in
mDNSResponder.  The collective operational experience is that using stale data
can provide significant benefit with minimal downside.</t>
    </section>
    <section anchor="standards-action" numbered="true" toc="default">
      <name>Standards Action</name>
      <t>The definition of TTL in Sections&nbsp;<xref target="RFC1035" section="3.2.1"
 sectionFormat="bare"/> and <xref target="RFC1035" section="4.1.3"
 sectionFormat="bare"/> of <xref target="RFC1035"/> is
amended to read:</t>
      <dl newline="false" spacing="normal" indent="5">
        <dt>TTL</dt>
        <dd>
  a 32-bit unsigned integer number of seconds that specifies the
duration that the resource record <bcp14>MAY</bcp14> be cached before the source of
the information <bcp14>MUST</bcp14> again be consulted.  Zero values are interpreted
to mean that the RR can only be used for the transaction in progress,
and should not be cached.  Values <bcp14>SHOULD</bcp14> be capped on the order of
days to weeks, with a recommended cap of 604,800 seconds (7&nbsp;days). If the
data is unable to be authoritatively refreshed when the TTL expires,
the record <bcp14>MAY</bcp14> be used as though it is unexpired. See Sections&nbsp;<xref target="example-method" format="counter"/>
and <xref target="implementation-considerations" format="counter"/> of
[RFC8767] for details.</dd>
      </dl>
      <t>Interpreting values that have the high-order bit set as being
positive, rather than 0, is a change from <xref target="RFC2181" format="default"/>, the rationale
for which is explained in <xref target="implementation-considerations" format="default"/>.
Suggesting a cap of 7&nbsp;days, rather than the 68 years allowed by the full
31 bits of 
<xref target="RFC2181" sectionFormat="of" section="8"/>, reflects the current practice of major modern DNS
resolvers.</t>
      <t>When returning a response containing stale records, a recursive
resolver <bcp14>MUST</bcp14> set the TTL of each expired record in the message to a
value greater than 0, with a <bcp14>RECOMMENDED</bcp14> value of 30 seconds. See
<xref target="implementation-considerations" format="default"/> for explanation.</t>
      <t>Answers from authoritative servers that have a DNS response code of
either 0 (NoError) or 3 (NXDomain) and the Authoritative Answer (AA)
bit set <bcp14>MUST</bcp14> be considered to have refreshed the data at the resolver.
Answers from authoritative servers that have any other response code
<bcp14>SHOULD</bcp14> be considered a failure to refresh the data and therefore leave
any previous state intact. See <xref target="implementation-considerations" format="default"/> for
a discussion.</t>
    </section>
    <section anchor="example-method" numbered="true" toc="default">
      <name>Example Method</name>
      <t>There is more than one way a recursive resolver could
responsibly implement this resiliency feature while still respecting
the intent of the TTL as a signal for when data is to be refreshed.</t>
      <t>In this example method, four notable timers drive considerations for
the use of stale data:</t>
      <ul spacing="normal">
        <li>A client response timer, which is the maximum amount of time a
recursive resolver should allow between the receipt of a resolution
request and sending its response.</li>
        <li>A query resolution timer, which caps the total amount of time a
recursive resolver spends processing the query.</li>
        <li>A failure recheck timer, which limits the frequency at which a
failed lookup will be attempted again.</li>
        <li>A maximum stale timer, which caps the amount of time
that records will be kept past their expiration.</li>
      </ul>
      <t>Most recursive resolvers already have the query resolution timer and,
effectively, some kind of failure recheck timer.  The client
response timer and maximum stale timer are new concepts for this
mechanism.</t>
      <t>When a recursive resolver receives a request, it should start
the client response timer.  This timer is used to avoid client
timeouts.  It should be configurable, with a recommended value of 1.8
seconds as being just under a common timeout value of 2 seconds while
still giving the resolver a fair shot at resolving the name.</t>
      <t>The resolver then checks its cache for any unexpired records that
satisfy the request and returns them if available.  If it
finds no relevant unexpired data and the Recursion Desired flag is not
set in the request, it should immediately return the response without
consulting the cache for expired records.  Typically, this response
would be a referral to authoritative nameservers covering the zone,
but the specifics are implementation dependent.</t>
      <t>If iterative lookups will be done, then the failure recheck timer is
consulted.  Attempts to refresh from non-responsive or otherwise
failing authoritative nameservers are recommended to be done no more
frequently than every 30 seconds.  If this request was received within
this period, the cache may be immediately consulted for stale data to
satisfy the request.</t>
      <t>Outside the period of the failure recheck timer, the resolver
should start the query resolution timer and begin the iterative
resolution process.  This timer bounds the work done by the resolver
when contacting external authorities and is commonly around 10 to 30
seconds.  If this timer expires on an attempted lookup that is still
being processed, the resolution effort is abandoned.</t>
      <t>If the answer has not been completely determined by the time the
client response timer has elapsed, the resolver should then check its
cache to see whether there is expired data that would satisfy the
request.  If so, it adds that data to the response message with a TTL
greater than 0 (as specified in <xref target="standards-action" format="default"/>).  The response is then sent to
the client while the resolver continues its attempt to refresh the
data.</t>
      <t>When no authorities are able to be reached during a resolution
attempt, the resolver should attempt to refresh the delegation and
restart the iterative lookup process with the remaining time on the
query resolution timer. This resumption should be done only once
per resolution effort.</t>
      <t>Outside the resolution process, the maximum stale timer is used for
cache management and is independent of the query resolution
process. This timer is conceptually different from the maximum cache
TTL that exists in many resolvers, the latter being a clamp on the
value of TTLs as received from authoritative servers and recommended
to be 7&nbsp;days in the TTL definition in <xref target="standards-action" format="default"/>.
The maximum stale timer
should be configurable. It defines the length of time after a record
expires that it should be retained in the cache.  The suggested value
is between 1 and 3 days.</t>
    </section>
    <section anchor="implementation-considerations" numbered="true" toc="default">
      <name>Implementation Considerations</name>
      <t>This document mainly describes the issues behind serving stale data
and intentionally does not provide a formal algorithm. The concept is
not overly complex, and the details are best left to resolver authors
to implement in their codebases. The processing of serve-stale is a
local operation, and consistent variables between deployments are not
needed for interoperability.  However, we would like to highlight the
impact of various implementation choices, starting with the timers
involved.</t>
      <t>The most obvious of these is the maximum stale timer. If this variable
is too large, it could cause excessive cache memory usage, but if it is
too small, the serve-stale technique becomes less effective, as the
record may not be in the cache to be used if needed.  Shorter values,
even less than a day, can effectively handle the vast majority of
outages.  Longer values, as much as a week, give time for monitoring
systems to notice a resolution problem and for human intervention to
fix it; operational experience has been that sometimes the right
people can be hard to track down and unfortunately slow to remedy the
situation.</t>
      <t>Increased memory consumption could be mitigated by prioritizing
  removal of stale records over non-expired records during cache
  exhaustion.  Eviction strategies could consider additional factors,
  including the last time of use or the popularity of a record, to
  retain active but stale records.  A feature to manually flush
  only stale records could also be useful.</t>
      <t>The client response timer is another variable that deserves
consideration. If this value is too short, there exists the risk that
stale answers may be used even when the authoritative server is
actually reachable but slow; this may result in undesirable answers
being returned. Conversely, waiting too long will negatively impact
user experience.</t>
      <t>The balance for the failure recheck timer is responsiveness in
detecting the renewed availability of authorities versus the extra
resource use for resolution. If this variable is set too large, stale
answers may continue to be returned even after the authoritative
server is reachable; per <xref target="RFC2308" sectionFormat="comma" section="7"/>, this should be no
more than 5&nbsp;minutes.  If this variable is too small, authoritative
servers may be targeted with a significant amount of excess traffic.</t>
      <t>Regarding the TTL to set on stale records in the response,
historically TTLs of 0&nbsp;seconds have been problematic for some
implementations, and negative values can't effectively be communicated
to existing software.  Other very short TTLs could lead to congestive
collapse as TTL-respecting clients rapidly try to refresh.  The
recommended value of 30 seconds not only sidesteps those potential problems
with no practical negative consequences, it also rate-limits
further queries from any client that honors the TTL, such as a
forwarding resolver.</t>
      <t>As for the change to treat a TTL with the high-order bit set as
positive and then clamping it, as opposed to <xref target="RFC2181" format="default"/> treating it
as zero, the rationale here is basically one of engineering simplicity
versus an inconsequential operational history.  Negative TTLs had no
rational intentional meaning that wouldn't have been satisfied by just
sending 0 instead, and similarly there was realistically no practical
purpose for sending TTLs of 2^25 seconds (1 year) or more.  There's
also no record of TTLs in the wild having the most significant bit set
in the DNS Operations, Analysis, and Research Center's (DNS-OARC's) "Day in the Life" samples <xref target="DITL" format="default"/>.  With no apparent
reason for
operators to use them intentionally, that leaves either errors or
non-standard experiments as explanations as to why such TTLs might be
encountered, with neither providing an obviously compelling reason as
to why having the leading bit set should be treated differently from
having any of the next eleven bits set and then capped per
<xref target="standards-action" format="default"/>.</t>
      <t>Another implementation consideration is the use of
stale nameserver addresses for lookups.  This is mentioned explicitly
because, in some resolvers, getting the addresses for nameservers is
a separate path from a normal cache lookup. If authoritative server
addresses are not able to be refreshed, resolution can possibly still
be successful if the authoritative servers themselves are up.  For
instance, consider an attack on a top-level domain that takes its
nameservers offline; serve-stale resolvers that had expired glue
addresses for subdomains within that top-level domain would still be able to
resolve names within those subdomains, even those it had not
previously looked up.</t>
      <t>The directive in <xref target="standards-action" format="default"/> that only NoError and NXDomain
responses should invalidate any previously associated answer stems
from the fact that no other RCODEs that a resolver normally
encounters make any assertions regarding the name in the question or
any data associated with it.  This comports with existing resolver
behavior where a failed lookup (say, during prefetching) doesn't
impact the existing cache state.  Some authoritative server operators
have said that they would prefer stale answers to be used in the event
that their servers are responding with errors like ServFail instead of
giving true authoritative answers.  Implementers <bcp14>MAY</bcp14> decide to return
stale answers in this situation.</t>
      <t>Since the goal of serve-stale is to provide resiliency for all obvious
errors to refresh data, these other RCODEs are treated as though they
are equivalent to not getting an authoritative response.  Although
NXDomain for a previously existing name might well be an error, it is
not handled that way because there is no effective way to distinguish
operator intent for legitimate cases versus error cases.</t>
      <t>During discussion in the IETF, it was suggested that,
if all authorities return responses with an RCODE of Refused,
it may be an explicit signal to take down the zone from
servers that still have the zone's delegation pointed to them.
Refused, however, is also
overloaded to mean multiple possible failures that could represent
transient configuration failures.  Operational experience has shown
that purposely returning Refused is a poor way to achieve an
explicit takedown of a zone compared to either updating the delegation
or returning NXDomain with a suitable SOA for extended negative
caching.  Implementers <bcp14>MAY</bcp14> nonetheless consider whether to
treat all authorities returning Refused as preempting the use of stale
data.</t>
    </section>
    <section anchor="implementation-caveats" numbered="true" toc="default">
      <name>Implementation Caveats</name>
      <t>Stale data is used only when refreshing has failed in order to adhere
to the original intent of the design of the DNS and the behavior
expected by operators.  If stale data were to always be used
immediately and then a cache refresh attempted after the client
response has been sent, the resolver would frequently be sending data
that it would have had no trouble refreshing.  Because modern resolvers use
techniques like prefetching and request coalescing for efficiency, it
is not necessary that every client request needs to trigger a new
lookup flow in the presence of stale data, but rather that a
good-faith effort has been recently made to refresh the stale data
before it is delivered to any client.</t>
      <t>It is important to continue the resolution attempt after the stale
response has been sent, until the query resolution timeout, because
some pathological resolutions can take many seconds to succeed as they
cope with unavailable servers, bad networks, and other problems.
Stopping the resolution attempt when the response with expired data
has been sent would mean that answers in these pathological cases
would never be refreshed.</t>
      <t>The continuing prohibition against using data with a 0-second TTL
beyond the current transaction explicitly extends to it being unusable
even for stale fallback, as it is not to be cached at all.</t>
      <t>Be aware that Canonical Name (CNAME) and DNAME records <xref target="RFC6672" format="default"/> mingled in the expired
cache with other records at the same owner name can cause surprising
results.  This was observed with an initial implementation in BIND
when a hostname changed from having an IPv4 Address (A) record to a
CNAME.  The version of BIND being used did not evict other types in
the cache when a CNAME was received, which in normal operations is not
a significant issue.  However, after both records expired and the
authorities became unavailable, the fallback to stale answers returned
the older A instead of the newer CNAME.</t>
    </section>
    <section anchor="implementation-status" numbered="true" toc="default">
      <name>Implementation Status</name>
      <t>The algorithm described in <xref target="example-method" format="default"/> was
originally implemented as a patch to BIND 9.7.0.  It has been in use
on Akamai's production network since 2011; it effectively
smoothed over transient failures and longer outages that would have
resulted in major incidents.  The patch was contributed to the Internet
Systems Consortium, and the functionality is now available in BIND 9.12
and later via the options stale-answer-enable, stale-answer-ttl, and
max-stale-ttl.</t>
      <t>Unbound has a similar feature for serving stale answers and will
respond with stale data immediately if it has recently tried and
failed to refresh the answer by prefetching.  Starting from
version 1.10.0, Unbound can also be configured to follow the
algorithm described in <xref target="example-method"/>.  Both behaviors can be
configured and fine-tuned with the available serve-expired-*
options.</t>
      <t>Knot Resolver has a demo module here:
<eref
    target="https://knot-resolver.readthedocs.io/en/stable/modules-serve_stale.html" brackets="angle"/>.</t>
      <t>Apple's system resolvers are also known to use stale answers, but the
details are not readily available.</t>
      <t>In the research paper "When the Dike Breaks: Dissecting DNS Defenses
During DDoS" <xref target="DikeBreaks" format="default"/>, the authors detected some use of
stale answers by resolvers when authorities came under attack.  Their
research results suggest that more widespread adoption of the technique
would significantly improve resiliency for the large number of requests
that fail or experience abnormally long resolution times during an attack.</t>
    </section>
    <section anchor="edns-option" numbered="true" toc="default">
      <name>EDNS Option</name>
      <t>During the discussion of serve-stale in the IETF,
it was suggested that an EDNS option <xref target="RFC6891"/> should be
available.  One proposal was to use it to opt in to getting data that is
possibly stale, and another was to signal when stale data has been used for a response.</t>
      <t>The opt-in use case was rejected, as the technique was meant to be
immediately useful in improving DNS resiliency for all clients.</t>
      <t>The reporting case was ultimately also rejected because
even the simpler version of a proposed
option was still too much bother to implement for too little perceived
value.</t>
    </section>
    <section anchor="security-considerations" numbered="true" toc="default">
      <name>Security Considerations</name>
      <t>The most obvious security issue is the increased likelihood of DNSSEC
validation failures when using stale data because signatures could be
returned outside their validity period. Stale negative records can increase
the time window where newly published TLSA or DS RRs may not be used due
to cached NSEC or NSEC3 records. These scenarios would only be an issue if
the authoritative servers are unreachable (the only time the techniques in
this document are used), and thus serve-stale does not introduce a new
failure in place of what would have otherwise been success.</t>
      <t>Additionally, bad actors have been known to use DNS caches to keep
records alive even after their authorities have gone away. The serve-stale
feature potentially makes the attack easier, although without introducing
a new risk. In addition, attackers could combine this with a DDoS attack on
authoritative servers with the explicit intent of having stale information
cached for a longer period of time. But if attackers have this capacity, they probably could
do much worse than prolonging the life of old data.</t>
      <t>In <xref target="CloudStrife" format="default"/>, it was demonstrated how stale DNS data, namely
hostnames pointing to addresses that are no longer in use by the owner
of the name, can be used to co-opt security -- for example, to get
domain-validated certificates fraudulently issued to an attacker.
While this document does not create a new vulnerability in this area, it
does potentially enlarge the window in which such an attack could be
made.  A proposed mitigation is that certificate authorities should fully
look up each name starting at the DNS root for every name lookup.
Alternatively, certificate authorities should use a resolver that is not serving stale data.</t>
    </section>
    <section anchor="privacy-considerations" numbered="true" toc="default">
      <name>Privacy Considerations</name>
      <t>This document does not add any practical new privacy issues.</t>
    </section>
    <section anchor="nat-considerations" numbered="true" toc="default">
      <name>NAT Considerations</name>
      <t>The method described here is not affected by the use of NAT devices.</t>
    </section>
    <section anchor="iana-considerations" numbered="true" toc="default">
      <name>IANA Considerations</name>
      <t>This document has no IANA actions.</t>
    </section>
  </middle>
  <back>
    <references>
      <name>References</name>
      <references>
        <name>Normative References</name>
<xi:include href="https://xml2rfc.ietf.org/public/rfc/bibxml/reference.RFC.1035.xml"/>
<xi:include href="https://xml2rfc.ietf.org/public/rfc/bibxml/reference.RFC.2181.xml"/>
<xi:include href="https://xml2rfc.ietf.org/public/rfc/bibxml/reference.RFC.1034.xml"/>
<xi:include href="https://xml2rfc.ietf.org/public/rfc/bibxml/reference.RFC.2119.xml"/>
<xi:include href="https://xml2rfc.ietf.org/public/rfc/bibxml/reference.RFC.8174.xml"/>
<xi:include href="https://xml2rfc.ietf.org/public/rfc/bibxml/reference.RFC.2308.xml"/>
      </references>
      <references>
        <name>Informative References</name>
        <reference anchor="DikeBreaks" target="https://www.isi.edu/~johnh/PAPERS/Moura18b.pdf">
          <front>
            <title>When the Dike Breaks: Dissecting DNS Defenses During DDoS</title>
            <seriesInfo name="DOI" value="10.1145/3278532.3278534"/>
            <seriesInfo name="ACM" value="2018 Internet Measurement Conference"/>
            <author initials="G.C.M." surname="Moura" fullname="Giovane C. M. Moura">
              <organization/>
            </author>
            <author initials="J." surname="Heidemann" fullname="John Heidemann">
              <organization/>
            </author>
            <author initials="M." surname="Müller" fullname="Moritz Müller">
              <organization/>
            </author>
            <author initials="R. de O." surname="Schmidt" fullname="Ricardo de O. Schmidt">
              <organization/>
            </author>
            <author initials="M." surname="Davids" fullname="Marco Davids">
              <organization/>
            </author>
            <date year="2018" month="October"/>
          </front>
        </reference>
        <reference anchor="CloudStrife" target="https://www.ndss-symposium.org/wp-content/uploads/2018/02/ndss2018_06A-4_Borgolte_paper.pdf">
          <front>
            <title>Cloud Strife: Mitigating the Security Risks of Domain-Validated Certificates</title>
            <seriesInfo name="DOI" value="10.1145/3232755.3232859"/>
            <seriesInfo name="ACM" value="2018 Applied Networking Research Workshop"/>
            <author initials="K." surname="Borgolte" fullname="Kevin Borgolte">
              <organization/>
            </author>
            <author initials="T." surname="Fiebig" fullname="Tobias Fiebig">
              <organization/>
            </author>
            <author initials="S." surname="Hao" fullname="Shuang Hao">
              <organization/>
            </author>
            <author initials="C." surname="Kruegel" fullname="Christopher Kruegel">
              <organization/>
            </author>
            <author initials="G." surname="Vigna" fullname="Giovanni Vigna">
              <organization/>
            </author>
            <date year="2018" month="July"/>
          </front>
        </reference>
        <reference anchor="DITL" target="https://www.dns-oarc.net/oarc/data/ditl">
          <front>
            <title>DITL Traces and Analysis</title>
             <author><organization>DNS-OARC</organization></author>
            <date month="January" year="2018"/>
          </front>
        </reference>
<xi:include href="https://xml2rfc.ietf.org/public/rfc/bibxml/reference.RFC.8499.xml"/>
<xi:include href="https://xml2rfc.ietf.org/public/rfc/bibxml/reference.RFC.6672.xml"/>
<xi:include href="https://xml2rfc.ietf.org/public/rfc/bibxml/reference.RFC.6891.xml"/>

      </references>
    </references>
    <section anchor="acknowledgements" numbered="false" toc="default">
      <name>Acknowledgements</name>
      <t>The authors wish to thank <contact fullname="Brian Carpenter"/>,
      <contact fullname="Vladimir Cunat"/>, <contact fullname="Robert Edmonds"/>, <contact fullname="Tony Finch"/>,
<contact fullname="Bob Harold"/>, <contact fullname="Tatuya Jinmei"/>, <contact fullname="Matti Klock"/>, <contact fullname="Jason Moreau"/>, <contact fullname="Giovane Moura"/>,
<contact fullname="Jean Roy"/>, <contact fullname="Mukund Sivaraman"/>, <contact fullname="Davey Song"/>, <contact fullname="Paul Vixie"/>, <contact fullname="Ralf Weber"/>, and
<contact fullname="Paul Wouters"/> for their review and feedback.  <contact fullname="Paul Hoffman"/> deserves
special thanks for submitting a number of Pull Requests.</t>
      <t>Thank you also to the following members of the IESG for their final
review:  <contact fullname="Roman Danyliw"/>, <contact fullname="Benjamin
Kaduk"/>, <contact fullname="Suresh Krishnan"/>, <contact fullname="Mirja
Kühlewind"/>, and <contact fullname="Adam Roach"/>.</t>
    </section>
  </back>
</rfc>
