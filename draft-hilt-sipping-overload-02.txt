


SIPPING Working Group                                            V. Hilt
Internet-Draft                                                I. Widjaja
Expires: January 9, 2008                        Bell Labs/Alcatel-Lucent
                                                                D. Malas
                                                  Level 3 Communications
                                                          H. Schulzrinne
                                                     Columbia University
                                                            July 8, 2007


           Session Initiation Protocol (SIP) Overload Control
                     draft-hilt-sipping-overload-02

Status of this Memo

   By submitting this Internet-Draft, each author represents that any
   applicable patent or other IPR claims of which he or she is aware
   have been or will be disclosed, and any of which he or she becomes
   aware will be disclosed, in accordance with Section 6 of BCP 79.

   Internet-Drafts are working documents of the Internet Engineering
   Task Force (IETF), its areas, and its working groups.  Note that
   other groups may also distribute working documents as Internet-
   Drafts.

   Internet-Drafts are draft documents valid for a maximum of six months
   and may be updated, replaced, or obsoleted by other documents at any
   time.  It is inappropriate to use Internet-Drafts as reference
   material or to cite them other than as "work in progress."

   The list of current Internet-Drafts can be accessed at
   http://www.ietf.org/ietf/1id-abstracts.txt.

   The list of Internet-Draft Shadow Directories can be accessed at
   http://www.ietf.org/shadow.html.

   This Internet-Draft will expire on January 9, 2008.

Copyright Notice

   Copyright (C) The IETF Trust (2007).

Abstract

   Overload occurs in Session Initiation Protocol (SIP) networks when
   SIP servers have insufficient resources to handle all SIP messages
   they receive.  Even though the SIP protocol provides a limited
   overload control mechanism through its 503 (Service Unavailable)



Hilt, et al.             Expires January 9, 2008                [Page 1]

Internet-Draft              Overload Control                   July 2007


   response code, SIP servers are still vulnerable to overload.  This
   document proposes several new overload control mechanisms for the SIP
   protocol.


Table of Contents

   1.  Introduction . . . . . . . . . . . . . . . . . . . . . . . . .  3
   2.  Terminology  . . . . . . . . . . . . . . . . . . . . . . . . .  4
   3.  Design Considerations  . . . . . . . . . . . . . . . . . . . .  4
     3.1.  System Model . . . . . . . . . . . . . . . . . . . . . . .  4
     3.2.  Hop-by-Hop vs. End-to-End  . . . . . . . . . . . . . . . .  5
     3.3.  Topologies . . . . . . . . . . . . . . . . . . . . . . . .  7
     3.4.  Overload Control Method  . . . . . . . . . . . . . . . . . 10
       3.4.1.  Rate-based Overload Control  . . . . . . . . . . . . . 10
       3.4.2.  Loss-based Overload Control  . . . . . . . . . . . . . 11
       3.4.3.  Window-based Overload Control  . . . . . . . . . . . . 11
     3.5.  Load Status  . . . . . . . . . . . . . . . . . . . . . . . 12
     3.6.  SIP Mechanism  . . . . . . . . . . . . . . . . . . . . . . 13
     3.7.  Backwards Compatibility  . . . . . . . . . . . . . . . . . 14
     3.8.  Interaction with Local Overload Control  . . . . . . . . . 15
   4.  SIP Application Considerations . . . . . . . . . . . . . . . . 15
     4.1.  How to Calculate Load Levels . . . . . . . . . . . . . . . 15
     4.2.  Responding to an Overload Indication . . . . . . . . . . . 15
     4.3.  Emergency Services Requests  . . . . . . . . . . . . . . . 16
     4.4.  Privacy Considerations . . . . . . . . . . . . . . . . . . 16
       4.4.1.  Critical Notify  . . . . . . . . . . . . . . . . . . . 17
       4.4.2.  Overload Suppression . . . . . . . . . . . . . . . . . 17
     4.5.  Operations and Management  . . . . . . . . . . . . . . . . 18
   5.  SIP Load Header Field  . . . . . . . . . . . . . . . . . . . . 18
     5.1.  Generating the Load Header . . . . . . . . . . . . . . . . 18
     5.2.  Determining the Load Header Value  . . . . . . . . . . . . 19
     5.3.  Determining the Throttle Parameter Value . . . . . . . . . 19
     5.4.  Processing the Load Header . . . . . . . . . . . . . . . . 20
     5.5.  Using the Load Header Value  . . . . . . . . . . . . . . . 21
     5.6.  Using the Throttle Parameter Value . . . . . . . . . . . . 21
     5.7.  Rejecting Requests . . . . . . . . . . . . . . . . . . . . 21
   6.  Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
   7.  Security Considerations  . . . . . . . . . . . . . . . . . . . 23
   8.  IANA Considerations  . . . . . . . . . . . . . . . . . . . . . 24
   Appendix A.  Acknowledgements  . . . . . . . . . . . . . . . . . . 24
   9.  References . . . . . . . . . . . . . . . . . . . . . . . . . . 24
     9.1.  Normative References . . . . . . . . . . . . . . . . . . . 24
     9.2.  Informative References . . . . . . . . . . . . . . . . . . 25
   Authors' Addresses . . . . . . . . . . . . . . . . . . . . . . . . 25
   Intellectual Property and Copyright Statements . . . . . . . . . . 27





Hilt, et al.             Expires January 9, 2008                [Page 2]

Internet-Draft              Overload Control                   July 2007


1.  Introduction

   As with any network element, a Session Initiation Protocol (SIP) [2]
   server can suffer from overload when the number of SIP messages it
   receives exceeds the number of messages it can process.  Overload can
   pose a serious problem for a network of SIP servers.  During periods
   of overload, the throughput of a SIP server can be significantly
   degraded.  In particular, overload may lead to a situation in which
   the throughput drops to a small fraction of the original server
   capacity.  This is often called congestion collapse.

   Overload is said to occur if a SIP server does not have sufficient
   resources to process all incoming SIP messages.  These resources may
   include CPU processing capacity, memory, network bandwidth, input/
   output, or disk resources.  Generally speaking, overload occurs if a
   SIP server can no longer process or respond to all incoming SIP
   messages.

   For overload control, we only consider failure cases where SIP
   servers are unable to process all SIP requests.  There are other
   failure cases where the SIP server can process, but not fulfill,
   requests.  These cases are beyond the scope of this document since
   SIP provides other response codes for them and overload control MUST
   NOT be used to handle these scenarios.  For example, a PSTN gateway
   that runs out of trunk lines but still has plenty of capacity to
   process SIP messages should reject incoming INVITEs using a 488 (Not
   Acceptable Here) response [4].  Similarly, a SIP registrar that has
   lost connectivity to its registration database but is still capable
   of processing SIP messages should reject REGISTER requests with a 500
   (Server Error) response [2].

   The SIP protocol provides a limited mechanism for overload control
   through its 503 (Service Unavailable) response code.  However, this
   mechanism cannot prevent overload of a SIP server and it cannot
   prevent congestion collapse.  In fact, the use of the 503 (Service
   Unavailable) response code may cause traffic to oscillate and to
   shift between SIP servers and thereby worsen an overload condition.
   A detailed discussion of the SIP overload problem, the problems of
   the 503 (Service Unavailable) response code and the requirements for
   a SIP overload control mechanism can be found in [6].

   This specification is structured as follows: Section 3 discusses
   general design principles of an SIP overload control mechanism.
   Section 4 discusses general considerations for applying SIP overload
   control.  Section 5 defines a SIP protocol extension for overload
   control and Section 6 introduces the syntax of this extension.
   Section 7 and Section 8 discuss security and IANA considerations
   respectively.



Hilt, et al.             Expires January 9, 2008                [Page 3]

Internet-Draft              Overload Control                   July 2007


2.  Terminology

   In this document, the key words "MUST", "MUST NOT", "REQUIRED",
   "SHALL", "SHALL NOT", "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT
   RECOMMENDED", "MAY", and "OPTIONAL" are to be interpreted as
   described in BCP 14, RFC 2119 [1] and indicate requirement levels for
   compliant implementations.


3.  Design Considerations

   This section discusses key design considerations for a SIP overload
   control mechanism.  The design goal for this mechanism is to enable a
   SIP server to control the load it receives from its upstream
   neighbors.

3.1.  System Model

   The model shown in Figure 1 identifies fundamental components of an
   SIP overload control system:

   o  SIP Processor: processes SIP messages.  It is the component that
      is protected by overload control.
   o  Monitor: monitors the current load of the SIP processor on the
      receiving entity.  It implements the mechanisms needed to measure
      the current usage of resources relevant for the SIP processor and
      reports load samples (S) to the Control Function.
   o  Control Function: implements the overload control mechanism on the
      receiving and sending entity.  The control function uses the load
      samples (S).  It determines if overload has occurred and a
      throttle (T) needs to be set to adjust the load sent to the SIP
      processor on the receiving entity.  The control function on the
      receiving entity sends load feedback (F) to the control function
      sending entity.
   o  Actuator: implements the algorithms needed to act on the throttles
      (T) and to adjust the load forwarded to the receiving entity.  For
      example, a throttle may instruct the actuator to reduce the load
      destined to the receiving entity by 10%.  The algorithms in the
      actuator then determine how the load reduction is achieved, e.g.,
      by selecting the messages that will be affected and determining
      whether they are rejected or redirected.

   The type of feedback (F) conveyed from the receiving to the sending
   entity depends on the overload control method used (i.e., loss-based,
   rate-based or window-based overload control; see Section 3.4.3) as
   well as other design parameters (e.g., whether load status
   information is included or not).  In any case, the feedback (F)
   informs the sending entity that overload has occurred and that the



Hilt, et al.             Expires January 9, 2008                [Page 4]

Internet-Draft              Overload Control                   July 2007


   traffic forward to the receiving entity needs to be reduced to a
   lower rate.

          Sending                Receiving
           Entity                  Entity
     +----------------+      +----------------+
     |    Server A    |      |    Server B    |
     |  +----------+  |      |  +----------+  |    -+
     |  | Control  |  |  F   |  | Control  |  |     |
     |  | Function |<-+------+--| Function |  |     |
     |  +----------+  |      |  +----------+  |     |
     |     T |        |      |       ^        |     | Overload
     |       v        |      |       | S      |     | Control
     |  +----------+  |      |  +----------+  |     |
     |  | Actuator |  |      |  | Monitor  |  |     |
     |  +----------+  |      |  +----------+  |     |
     |       |        |      |       ^        |    -+
     |       v        |      |       |        |    -+
     |  +----------+  |      |  +----------+  |     |
   <-+--|   SIP    |  |      |  |   SIP    |  |     |  SIP
   --+->|Processor |--+------+->|Processor |--+->   | System
     |  +----------+  |      |  +----------+  |     |
     +----------------+      +----------------+    -+


                Figure 1: System Model for Overload Control

3.2.  Hop-by-Hop vs. End-to-End

   A SIP request is often processed by more than one SIP server on its
   path to the destination.  Thus, a design choice for overload control
   involves the level of cooperation between the SIP servers on the path
   of a request.  Overload control can be implemented hop-by-hop, i.e.,
   independently between each pair of servers, or end-to-end as a single
   control loop that stretches across the entire path from UAC to UAS
   (see Figure 2).















Hilt, et al.             Expires January 9, 2008                [Page 5]

Internet-Draft              Overload Control                   July 2007


               +---------+             +-------+----------+
      +------+ |         |             |       ^          |
      |      | |        +---+          |       |         +---+
      v      | v    //=>| C |          v       |     //=>| C |
   +---+    +---+ //    +---+       +---+    +---+ //    +---+
   | A |===>| B |                   | A |===>| B |
   +---+    +---+ \\    +---+       +---+    +---+ \\    +---+
               ^    \\=>| D |          ^       |     \\=>| D |
               |        +---+          |       |         +---+
               |         |             |       v          |
               +---------+             +-------+----------+

      (a) hop-by-hop loop              (b) end-to-end loop

    ==> SIP request flow
    <-- Load feedback loop


                    Figure 2: Hop-by-Hop vs. End-to-End

   In the hop-by-hop model, a separate control loop is instantiated
   between all neighboring SIP servers that directly exchange traffic.
   This control loop is completely independent of the control loops
   between other servers.  In the example in Figure 2(a), three
   independent overload control loops are instantiated: A - B, B - C and
   B - D. Thus, each overload control loop only covers a single hop.  In
   the hop-by-hop model, each SIP server provides load feedback to its
   direct upstream neighbors, which then adjust the amount of traffic
   they forward to the SIP server.  These neighbors do not forward the
   received feedback information further upstream.  Instead, they act on
   the feedback and resolve the overload condition if needed, for
   example, by re-routing or rejecting traffic.

   The upstream neighbor of a server instantiates a separate overload
   control loop with its upstream neighbors.  If the neighbor becomes
   overloaded, it will report this problem to its upstream neighbors,
   which again take action based on the reported feedback.  Thus, in
   hop-by-hop overload control, overload is always resolved by the
   direct upstream neighbors of the overloaded server without the need
   to involve entities that are located multiple SIP hops away.

   Hop-by-hop overload control can effectively reduce the impact of
   overload on a SIP network and, in particular, can avoid congestion
   collapse.  In addition, hop-by-hop overload control is simple and
   scales well to networks with many SIP entities.  It does not require
   a SIP entity to aggregate a large number of load status values or
   keep track of the load status of SIP servers it is not communicating
   with.



Hilt, et al.             Expires January 9, 2008                [Page 6]

Internet-Draft              Overload Control                   July 2007


   End-to-end overload control implements an overload control loop along
   the entire path of a SIP request, from UAC to UAS.  An end-to-end
   overload control mechanism needs to consider load information from
   all SIP servers on the way (including all proxies and the UAS).  It
   has to be able to frequently collect the load status of all servers
   on the potential path(s) to a destination and combine this data into
   meaningful load feedback.

   A UA or SIP server should only throttle requests, if it knows that
   these requests will eventually be forwarded to an overloaded server.
   For example, if D is overload in Figure 2(b), A should only throttle
   requests it forwards to B, when it knows that they will be forwarded
   to D. It should not throttle requests that will eventually forward to
   C, since server C is doing fine.  In many cases, it is hard for A to
   determine which requests will be routed to C and D since this depends
   on the local routing decision made by B.

   The main problem of end-to-end path overload control is its inherent
   complexity since a UAC or SIP server would need to monitor all
   potential paths to a destination in order to determine which requests
   should be throttled and which requests may be sent.  Therefore, end-
   to-end overload control is likely to only work in simple, well-known
   topologies (e.g. a server is known to only have one downstream
   neighbor) or if a UA/server sends lots of requests to the exact same
   destination or .

3.3.  Topologies

   In a simple topology, a SIP server traffic from a single source (as
   shown in Figure 3(a)).  A load balancer is a typical example for this
   configuration.  Overload control needs to prevent the upstream server
   from sending too much traffic to its downstream neighbors.

   In more complex topology, a SIP server receives traffic from multiple
   upstream sources, as shown in Figure 3(b).  Here, SIP servers A, B
   and C forward traffic to server D. It is important to note that each
   of these servers may contribute a different amount of load to the
   overall load of D. This load mix may vary over time.  If server D
   becomes overloaded, it needs to generate feedback to reduce the
   amount of traffic it receives from its upstream neighbors (i.e., A, B
   and C respectively).  The server needs to decide how overload control
   feedback is balanced across upstream neighbors.  This decision needs
   to account for the actual amount of traffic received from each
   upstream neighbor.  The decision may need to be re-adjusted as the
   load contributed by each upstream neighbor varies over time.  A
   server may use a local policy to decide how much load it wants to
   receive from each upstream neighbor.  For example, a server may
   throttle all upstream sources equally (e.g., all sources need to



Hilt, et al.             Expires January 9, 2008                [Page 7]

Internet-Draft              Overload Control                   July 2007


   reduce traffic forwarded by 10%) or to prefer some servers over
   others.  For example, it may want to throttle a less preferred
   upstream neighbor earlier than a preferred neighbor or throttle the
   neighbor first that sends the most traffic.  Since this decision is
   made by the receiving entity (i.e., server D), all senders for this
   entity are governed by the same overload control algorithm.

   In many network configurations, upstream servers (A, B and C in
   Figure 3(c)) have multiple alternative servers (servers D and E) to
   which they can forward traffic.  In this case, they can choose to
   redirect a message to the alternate server if the primary target is
   overloaded.  This is in particular useful if servers D and E differ
   in their processing capacity and are not load balanced otherwise.
   When redirecting messages, the upstream servers need to ensure that
   these messages do not overload the alternate server.  An overload
   control mechanism needs to enable upstream servers to only choose
   alternative servers that have enough capacity to handle the
   redirected requests.

































Hilt, et al.             Expires January 9, 2008                [Page 8]

Internet-Draft              Overload Control                   July 2007


                   +---+              +---+
                /->| D |              | A |-\
               /   +---+              +---+  \
              /                               \   +---+
       +---+-/     +---+              +---+    \->|   |
       | A |------>| E |              | B |------>| D |
       +---+-\     +---+              +---+    /->|   |
              \                               /   +---+
               \   +---+              +---+  /
                \->| F |              | C |-/
                   +---+              +---+

     (a) load balancer w/           (b) multiple upstream
      alternate servers                   neighbors

       +---+
       | A |---\                        a--\
       +---+=\  \---->+---+                 \
              \/----->| D |             b--\ \--->+---+
       +---+--/\  /-->+---+                 \---->|   |
       | B |    \/                      c-------->| D |
       +---+===\/\===>+---+                       |   |
               /\====>| E |            ...   /--->+---+
       +---+--/   /==>+---+                 /
       | C |=====/                      z--/
       +---+

     (c) multiple upstream         (d) very large number of
   neighbors w/ alternate server      upstream neighbors


                           Figure 3: Topologies

   Overload control that is based on throttling the message rate is not
   suited for servers that receive requests from a very large population
   of senders, which only infrequently send requests as shown in
   Figure 3(d).  An edge proxy that is connected to many UAs is an
   example for such a configuration.  Since each UA typically only
   contributes a few requests, which are often related to the same call,
   it can't decrease its message rate to resolve the overload.  In such
   a configuration, a SIP server can gradually reduce its load by
   rejecting a percentage of the requests it receives, e.g., with 503
   (Service Unavailable) responses.  Since there are many upstream
   neighbors that contribute to the overall load, sending 503 (Service
   Unavailable) to a fraction of them gradually reduces load without
   entirely stopping the incoming traffic.





Hilt, et al.             Expires January 9, 2008                [Page 9]

Internet-Draft              Overload Control                   July 2007


3.4.  Overload Control Method

   The method used by an overload control mechanism to limit the amount
   of traffic forwarded to an element is a key aspect of the design.  We
   discuss the following three different types of overload control
   methods: rate-based, loss-based and window-based overload control.

3.4.1.  Rate-based Overload Control

   The key idea of rate-based overload control is to limit the message
   rate that an upstream element is allowed to forward to the downstream
   neighbor.  If overload occurs, a SIP server instructs each upstream
   neighbor to send at most X messages per second.  This rate cap
   ensures that the offered load for the SIP server never increases
   beyond the sum of the rate caps granted to all upstream neighbors and
   can protect a SIP server from overload even during extreme load
   spikes.

   An algorithm for the sending entity to implement a rate cap of a
   given number of messages per second X is message gapping.  After
   transmitting a message to a downstream neighbor, a server waits for
   1/X seconds before it transmits the next message to the same
   neighbor.  Messages that arrive during the waiting period are not
   forwarded and are either redirected, rejected or buffered.

   The main drawback of this mechanism is that it requires a SIP server
   to assign a certain rate cap to each of its upstream neighbors based
   on its overall capacity.  Effectively, a server assigns a share of
   its capacity to each upstream neighbor.  The server needs to ensure
   that the sum of all rate caps assigned to upstream neighbors is not
   (significantly) higher than its actual processing capacity.  This
   requires a SIP server to continuously evaluate the amount of load it
   receives from an upstream neighbor and assign a rate cap that is
   suitable for this neighbor.  For example, in a non-overloaded
   situation, it could assign a rate cap that is 10% higher than the
   current load received from this neighbor.  The rate cap needs to be
   adjusted if the load offered by upstream neighbors changes and new
   upstream neighbors appear or an existing neighbor stops transmitting.
   If the cap assigned to an upstream neighbor is too high, the server
   may still experience overload.  However, if the cap is too low, the
   upstream neighbors will reject messages even though they could be
   processed by the server.  Thus, rate-based overload control is likely
   to work well only if the number of upstream servers is small and
   constant, e.g., as shown in the example in Figure 3(d).







Hilt, et al.             Expires January 9, 2008               [Page 10]

Internet-Draft              Overload Control                   July 2007


3.4.2.  Loss-based Overload Control

   A loss percentage enables a SIP server to ask its upstream neighbor
   to reduce the amount of traffic it would normally forward to this
   server by a percentage X. For example, a SIP server can ask its
   upstream neighbors to lower the traffic it would normally forward to
   it by 10%.  The upstream neighbor then redirects or rejects X percent
   of the traffic that is destined for this server.

   An algorithm for the sending entity to implement a loss percentage is
   to draw a random number between 1 and 100 for each request to be
   forwarded.  The request is not forwarded to the server if the random
   number is less than or equal to X.

   For loss-based overload control, the receiving entity does not need
   to track the message rate it receives from each upstream neighbor.
   To reduce load, a server can ask each upstream neighbor to lower
   traffic by a certain percentage.  This percentage can be determined
   independent of the actual message rate contributed by each server.
   The loss percentage depends on the loss percentage currently used by
   the upstream servers and the current system load of the server.  For
   example, if the server load approaches 90% and the current loss
   percentage is set to a 50% load reduction, then the server may decide
   to increase the loss percentage to 55% in order to get back to a
   system load of 80%.  Similarly, the server can lower the loss
   percentage if permitted by the system utilization.  This requires
   that system load can be accurately measured and that these
   measurements are reasonably stable.

   The main drawback of percentage throttling is that the throttle
   percentage needs to be adjusted to the offered load, in particular,
   if the load fluctuates quickly.  For example, if a SIP server sets a
   throttle value of 10% at time t1 and load increases by 20% between
   time t1 and t2 (t1<t2), then the server will see a load increase by
   10% between time t1 and t2.  This is true even though all upstream
   neighbors reduced traffic by 10% as told.  Thus, percentage
   throttling requires the quick adjustment of the throttling percentage
   and may not always be able to prevent a server from encountering
   brief periods of overload in extreme cases.

3.4.3.  Window-based Overload Control

   The key idea of window-based overload control is to allow an entity
   to transmit a certain number of messages before it needs to receive a
   confirmation for the messages in transit.  Each sender maintains an
   overload window that limits the number of messages that can be in
   transit without being confirmed.




Hilt, et al.             Expires January 9, 2008               [Page 11]

Internet-Draft              Overload Control                   July 2007


   Each sender maintains a unconfirmed message counter for each
   downstream neighbor it is communicating with.  For each message sent
   to the downstream neighbor, the counter is increased by one.  For
   each confirmation received, the counter is decreased by one.  The
   sender stops transmitting messages to the downstream neighbor when
   the unconfirmed message counter has reached the current window size.

   A crucial parameter for the performance of window-based overload
   control is the window size.  The windows size together with the
   round-trip time between sender and receiver determines the effective
   message rate that can be achieved.  Each sender has an initial window
   size it uses when first sending a request.  This window size can
   change based on the feedback it receives from the receiver.  The
   receiver can require a decrease in window size to throttle the sender
   or allow an increase to allow an increasing message rate.

   The sender adjusts its window size as soon as it receives the
   corresponding feedback from the receiver.  If the new window size is
   smaller than the current unconfirmed message counter, the sender MUST
   stop transmitting messages until more messages are confirmed and the
   current unconfirmed message counter is less than the window size.

   A sender should not treat the reception of a 100 Trying response as
   an implicit confirmation for a message. 100 Trying responses are
   often created by a SIP server very early in the process and do not
   indicate that a message has been successfully processed and cleared
   from the input buffer.  If the downstream neighbor is a stateless
   proxy, it will not create 100 Trying responses at all and instead
   pass through 100 Trying responses created by the next stateful
   server.  Also, 100 Trying response are typically only created for
   INVITE requests.  Explicit message confirmations in a load feedback
   report do not have these problems.

   The behavior and issues of window-based overload control are similar
   to rate-based overload control, in that the total available receiver
   buffer space needs to be divided among all upstream neighbors.
   However, unlike rate-based overload control, it can normally ensure
   that the receiver buffer does not overflow.  The transmission of
   messages by senders is effectively clocked by message confirmations
   received from the receiver.

3.5.  Load Status

   It may be useful for a SIP server to frequently provide its current
   load status to upstream neighbors.  The load status indicates to
   which degree the resources needed by a SIP server to process SIP
   messages are utilized.  SIP servers can use the load status to
   balance load between alternative proxies and to find under-utilized



Hilt, et al.             Expires January 9, 2008               [Page 12]

Internet-Draft              Overload Control                   July 2007


   servers.  It should be noted, however, that reporting load is not
   intended to replace specialized load balancing mechanisms.

      OPEN ISSUE: reporting load status seems related but somewhat
      orthogonal to overload control.  This could call for a separation
      of overload control and load reporting/balancing.

3.6.  SIP Mechanism

   A SIP mechanism is needed to convey load feedback from the receiving
   to the sending SIP entity.  A number of alternatives exist to
   implement such a mechanism.

   One approach is to define a new SIP request that can be used to
   convey load status reports from the receiving to the sending entity.
   However, sending separate load status requests from receiving to the
   sending entity would create additional messaging overhead, which is
   undesirable during periods of overload.  It would also require each
   SIP server to keep track of all potential upstream neighbors.

   An alternative is to define a new event package for subscriptions to
   overload status.  The goal of such an event package is to enable a
   sending entity to subscribe to the load status of its downstream
   neighbor.  When a sender wants to transmit the first message to a new
   receiver, it creates a subscription to the receiver's load status by
   sending a SUBSCRIBE request to it.  The receiver may choose to
   authenticate the SUBSCRIBE request if it wants limit set of senders
   that can receive overload control information.  It eventually accepts
   the subscription and returns its load status in a NOTIFY request.
   The receiver can update its load status at any time in subsequent
   NOTIFY messages.  The subscription is terminated when no traffic has
   been exchanged for some time.

   An advantage of this approach is that a receiver can update its load
   status at any time, even to senders that are currently inactive.
   This way, inactive senders can be prevented from sending traffic
   during an overload condition and senders can be notified when an
   overload condition has improved.  However, the mechanism does not
   prevent new senders from sending during overload.  A disadvantage of
   this approach is that it requires each receiver to maintain a
   subscription with each potential sender.  Similarly, each sender has
   to maintain subscriptions for all receivers it may forward traffic
   to.  A receiver needs to quickly send NOTIFY messages to all senders
   when it enters an overload condition to request a reduction in load.
   While these requests can be processed with high priority, they create
   additional load for the server at a time it is trying to reduce load.
   Finally, this mechanism requires each proxy to implement a UAS/UAC to
   manage the subscriptions.



Hilt, et al.             Expires January 9, 2008               [Page 13]

Internet-Draft              Overload Control                   July 2007


   Another alternative is to define a new SIP header field for load
   information that can be inserted into SIP responses.  A SIP server
   can add this header to responses to inform its upstream neighbors
   about the current load status.  The server can choose the upstream
   neighbors to which this header is sent and may use transport level
   authentication (e.g. via TLS) to limit set of senders that can
   receive overload control information.  Hop-by-hop overload control
   requires that load feedback is used only by the next upstream
   neighbor of a server.  This can be achieved by inserting the address
   of this neighbor into the load header so that the header can be
   discarded if it is passed on.

   An advantage of this approach is that it is light-weight and creates
   very little overhead.  It does not require the transmission of
   additional messages for controlling overload, which is beneficial for
   overload control.  Servers do not need to manage state in order to
   send or receive load information from upstream or downstream
   neighbors.  The load status of a server is automatically conveyed to
   all upstream neighbors that are currently forwarding traffic to a SIP
   server.  A disadvantage is that load status is not conveyed when
   senders are inactive and no traffic is flowing.  While this is
   usually not a problem, it is possible that an inactive sender starts
   to transmit when the receiver is in overload.  This sender will
   receive load feedback in the first response.  In an extreme overload
   situation that requires 100% throttling, upstream neighbors can
   occasionally forward a request to get the current load status of the
   downstream neighbor.

3.7.  Backwards Compatibility

   An important requirement for an overload control mechanism is that it
   can be gradually introduced into a network and that it functions
   properly if only a fraction of the servers support it.

   Hop-by-hop overload control does not require that all SIP entities in
   a network support it.  It can be used effectively between two
   adjacent SIP servers if both servers support this extension and does
   not depend on the support from any other server or user agent.  The
   more SIP servers in a network support this mechanism, the more
   effective it is since it includes more of the servers in the load
   reporting and offloading process.

   In topologies such as the ones depicted in Figure 3(b) and (c), a SIP
   server has multiple neighbors from which only some may support
   overload control.  If a server would simply use this extension for
   overload control, only those that support it would throttle their
   load.  Others would keep sending at the full rate and benefit from
   the throttling by other servers supporting this extension.  In other



Hilt, et al.             Expires January 9, 2008               [Page 14]

Internet-Draft              Overload Control                   July 2007


   words, upstream neighbors that do not support overload control would
   be better off than those that do.

   A SIP server should therefore use 5xx responses towards upstream
   neighbors that do not support this specification.  The server should
   reject the same amount of requests with 5xx responses that would be
   otherwise be rejected/redirected by the upstream neighbor if it would
   support overload control.  For example, if the server has throttled
   the load by 10%, it should reject 10% of the requests with a 5xx
   response for this neighbor.

3.8.  Interaction with Local Overload Control

   Servers sometimes implement a mechanism that enables them to reject
   requests with minimal effort, i.e., before requests are fully
   processed.  Such a mechanism can be used to quickly reject incoming
   requests that exceed the servers capacity and therefore provides
   protection against overload.  We refer to such mechanisms as local
   overload control.

   Local overload control can be used in conjunction with the mechanisms
   defined in this specification.  It provides an additional layer of
   protection against overload, for example, when upstream servers do
   not support overload control.  In general, servers should start use
   the mechanisms described here to throttle upstream neighbors before
   using local overload control to reject messages as a mechanism of
   last resort.


4.  SIP Application Considerations

4.1.  How to Calculate Load Levels

   Calculating an element's load level is dependent on the limiting
   resource for this element.  There can be several contributing
   factors, such as CPU, memory, queue depth, calls per second,
   application threads.  The element should consider to have reached a
   load level of 100% at a point at which it cannot reliably process any
   more messages.  If an element knows what its limiting resource is, it
   can calculate its load level based on this resource or use a
   combination of resources.  The element should recognize percentages
   of load prior the limit at which the element becomes 100% loaded.

4.2.  Responding to an Overload Indication

   An element may receive a load header indicating that it needs to
   reduce the traffic it sends to its downstream neighbor.  An element
   can accomplish this task by sending some of the requests that would



Hilt, et al.             Expires January 9, 2008               [Page 15]

Internet-Draft              Overload Control                   July 2007


   have gone to the overloaded element to a different destination or by
   altering its load-balancing algorithm to lower the number of requests
   it will offer to the overloaded resource.  It can also buffer
   requests in the hope that the overload condition will resolve quickly
   and the requests still can be forwarded in time.  Finally, it can
   reject these requests.

4.3.  Emergency Services Requests

   It is generally recommended that SIP servers, which need to reject
   requests due to overload, SHOULD treat emergency services request [8]
   with highest priority and preserve them if possible.  When a SIP
   server receives an emergency services request, it should not be
   treated by alleviation methods and should be processed immediately.
   In some cases, a SIP server may receive more emergency services
   requests than it is allowed to forward.  This may happen, for
   example, to a SIP server that is serving an emergency service center.
   In these cases and after rejecting/redirecting all non-emergency
   service requests, a SIP server should also include emergency service
   requests in the alleviation treatment to avoid that the downstream
   server becomes overloaded.

4.4.  Privacy Considerations

   Providers tend to place functional barriers in their networks to
   enforce topology hiding, header filtering, along with other
   functions.  These barriers are often realized as proxies, back-to-
   back user agents (B2BUA), or session border controllers.  In the
   following refer to these devices as border B2BUA.  A border B2BUA
   should be cognizant of the overload header and apply policies based
   on the location and level of privacy desired.  However, it is
   important to understand that manipulating the overload control
   mechanism in any way may have a significant adverse effect on the
   protection against overload.

   The following two examples are not recommended if the desire is to
   achieve protection against overload in all circumstances.  However,
   some service providers may consider the privacy risks to be greater
   than the risks of overload.  Beyond a very basic requirement for the
   border B2BUA to respond to its neighbors with overload information,
   there are two common options of privacy that should be considered:
   "Critical Notify" and "Overload Suppression".  These two options are
   intended to be examples, and should not be considered exclusive.








Hilt, et al.             Expires January 9, 2008               [Page 16]

Internet-Draft              Overload Control                   July 2007


                                  |
         External**               |                 Internal
        +--------+           +---------+           +--------+
        | ProxyA +-----------+  B2BUA  +-----------+ ProxyB |
        +--------+           +---------+           +--------+
                                  |
                                  | domain border

            Figure 4: Example configuration for a border B2BUA

   **In the above diagram, external means outside of a SIP service
   providers network, i.e., and not behind the border B2BUA.  Internal
   means inside the providers network.

4.4.1.  Critical Notify

   A SIP service provider may not want to provide load information to an
   external proxy unless it has reached a critical overload condition.
   This will give the external proxy the implication the border B2BUA
   always has an acceptable level of capacity until it reaches a
   critical point.  The critical point may vary based on the provider's
   desire to limit the level of overload communicated to the external
   proxy.  An example of this is a service provider who does not want a
   customer to turn away traffic until it is in a critical condition.
   In this option, it is still likely the provider expects the B2BUA to
   provide varying levels of downstream overload information to the
   internal proxies.  The service provider may have multiple B2BUA's
   throughout the network to reach the customer and may want to balance
   traffic, as possible, across a cluster to downstream internal
   proxies.

4.4.2.  Overload Suppression

   A SIP service provider may choose to fully suppress all overload
   information to the upstream external proxy.  In this way, the
   provider gives the implication the border B2BUA always has an
   acceptable level of capacity, and will only utilize 503 (Service
   Unavailable) responses to reject traffic in case of overload.  This
   is a potentially dangerous method, because 503 (Service Unavailable)
   responses are known to work very poorly for overload control.  This
   performance impairment may cause greater issues than a more graceful
   overload indication.  An example application for this method is a
   server provider who has provided a static loading allocation and has
   specified a static session limit.  If the customer exceeds the
   session limits, then new session requests are immediately rejected
   with 503 (Service Unavailable) responses without Retry-After header.
   Here, the provider does not want to indicate overload in any
   situation.  The customer will need to react accordingly to the 503



Hilt, et al.             Expires January 9, 2008               [Page 17]

Internet-Draft              Overload Control                   July 2007


   (Service Unavailable) responses and make necessary adjustments for
   new session requests that exceed their limits with the B2BUA.  In
   this option, the provider may still want the B2BUA to provide varying
   levels of downstream overload information to the internal proxies.

4.5.  Operations and Management

   The load header information can be captured within Call Detail
   Records (CDRs) and SNMP traps for use in service reports.  These
   service reports could be used for future network optimization.


5.  SIP Load Header Field

   This section defines a new SIP header field for overload control, the
   Load header.  This header field follows the above design
   considerations for an overload control mechanism.

      Note: the Load header field is an initial proposal for a overload
      feedback mechanism.  The actual design of this mechanism depends
      on many of the design aspects discussed above.

5.1.  Generating the Load Header

   A SIP server compliant to this specification SHOULD frequently
   provide load feedback to its upstream neighbors in a timely manner.
   It does so by inserting a Load header field into the SIP responses it
   is forwarding or creating.  The Load header is a new header field
   defined in this specification.  The Load header can be inserted into
   all response types, including provisional, success and failure
   response types.  A SIP server SHOULD insert a Load header into all
   responses.

   A SIP server MAY choose to insert Load headers less frequently, for
   example, once every x milliseconds.  This may be useful for SIP
   servers that receive a very high number of messages from the same
   upstream neighbor or servers with a very low variability of the load
   measure.  In any case, a SIP server SHOULD insert a Load header into
   a response well before the previous Load header sent to the same
   upstream neighbor expires.  Only SIP servers that frequently insert
   Load header into responses are protected against overload.

   The Load header is only defined in SIP responses and MUST NOT be used
   in SIP requests.  The Load header is only useful to the upstream
   neighbor of a SIP server since this is the entity that can offload
   traffic by redirecting/rejecting new requests.  If requests are
   forwarded in both directions between two SIP servers (i.e., the roles
   of upstream/downstream neighbors change), there are also responses



Hilt, et al.             Expires January 9, 2008               [Page 18]

Internet-Draft              Overload Control                   July 2007


   flowing in both directions, which allow the two SIP servers to
   exchange load information.  While adding Load headers to requests may
   increase the frequency with which load information is exchanged in
   these scenarios, this increase will rarely provide benefits and does
   not seem to justify the added overhead and complexity needed.

   A SIP server MUST insert the address of its upstream neighbor into
   the "target" parameter of the Load header.  It SHOULD use the address
   of the upstream neighbor found in the topmost Via header of the
   response for this purpose.

   The "target" parameter enables the receiver of a Load header to
   determine if it should process the Load header (since it was
   generated by its downstream neighbor) or if the Load header needs to
   be ignored (since it was passed along by an entity that does not
   support this extension).  Effectively, the "target" parameter
   implements the hop-by-hop semantics and prevents the use of load
   status information beyond the next hop.

      OPEN ISSUE: instead of using the address in the Via header it
      might make sense to use an application identifier similar to the
      one defined for SigComp [7].

   A SIP server SHOULD add a "validity" parameter to the Load header.
   The "validity" parameter defines the time in milliseconds during
   which the Load header should be considered valid.  The default value
   of the "validity" parameter is 500.  A SIP server SHOULD use a
   shorter "validity" time if its load status varies quickly and MAY use
   a longer "validity" time if the current load level is more stable.

5.2.  Determining the Load Header Value

   The value of the Load header contains the current load status of the
   SIP server generating this header.  Load header values range from 0
   (idle) to 100 (overloaded) and MUST reflect the current level in the
   usage of SIP message processing resources.  For example, a SIP server
   that is processing SIP messages at a rate that corresponds to 50% of
   its maximum capacity must set the Load header value to 50.

5.3.  Determining the Throttle Parameter Value

   The value of the "throttle" parameter specifies the percentage by
   which the load forwarded to this SIP server should be reduced.
   Possible values range from 0 (the load forwarded is reduced by 0%,
   i.e., all traffic is forwarded) to 100 (the load forwarded is reduced
   by 100%, i.e., no traffic forwarded).  The default value of the
   "throttle" parameter is 0.  The "throttle" parameter value is
   determined by the control function of the SIP server generating the



Hilt, et al.             Expires January 9, 2008               [Page 19]

Internet-Draft              Overload Control                   July 2007


   Load header.

      OPEN ISSUE: this parameter depends on the overload control method
      used (e.g., whether rate-based or window-based overload control is
      used).

5.4.  Processing the Load Header

   A SIP entity compliant to this specification MUST remove all Load
   headers from the SIP messages it receives before forwarding the
   message.  A SIP entity may, of course, insert its own Load header
   into a SIP message.

   A SIP entity MUST ignore all Load headers that were not addressed to
   it.  It MUST compare its own addresses with the address in the
   "target" parameter of the Load header.  If none of its addresses
   match, it MUST ignore the Load header.  This ensures that a SIP
   entity only processes Load headers that were generated by its direct
   neighbors.

   A SIP server MUST store the information received in Load headers from
   a downstream neighbor in a server load table.  Each time a SIP server
   receives a response with a Load header from a downstream neighbor, it
   MUST overwrites the current value it has stored for this neighbor
   with the one received.  Each entry in the server load table has the
   following elements:

   o  Address of the server from which the Load header was received.
   o  Time when the header was received.
   o  Load header value.
   o  Throttle parameter value (default value if not present).
   o  Validity parameter value (default value if not present).

   A SIP entity SHOULD slowly fade out the contents of Load headers that
   have exceeded their expiration time by additively decreasing the Load
   header and throttle parameter values until they reach zero.  This is
   achieved by using the following equation to access stored Load header
   and "throttle" parameter values.  Note that this equation is only
   used to access Load header and "throttle" parameter values and the
   result is not written back into the table.

      result = value - ((cur_t - rec_t) DIV validity) * 20

   If the result is negative, zero is used instead.  Value is the stored
   value of the Load header/the "throttle" parameter.  Cur_t is the
   current time in milliseconds, rec_t is the time the Load header was
   received.  Validity is the "validity" parameter value.  DIV is a
   function that returns the integer portion of a division.



Hilt, et al.             Expires January 9, 2008               [Page 20]

Internet-Draft              Overload Control                   July 2007


   The idea behind this equation is to subtract 20 from the value for
   each validity period that has passed since the header was received.
   A value of 100, for example, will be reduced to 80 after the first
   validity period and it will be completely removed after 5 * validity
   milliseconds.

   A stored Load header is removed from the table when the above
   equation returns zero for both the load header and throttle parameter
   value.

5.5.  Using the Load Header Value

   A SIP entity MAY use the Load header value to balance load or to find
   an underutilized SIP server.

5.6.  Using the Throttle Parameter Value

   A SIP entity compliant to this specific MUST honor "throttle"
   parameter values when forwarding SIP messages to a downstream SIP
   server.

   A SIP entity applies the usual SIP procedures to determine the next
   hop SIP server as, e.g., described in [2] and [3].  After selecting
   the next hop server, the SIP entity MUST determine if it has a stored
   Load header from this server that has not yet fully expired.  If it
   has a Load header and the header contained a throttle parameter that
   is non-zero, the SIP server MUST determine if it can or cannot
   forward the current request within the current throttle conditions.

   The SIP MAY use the following algorithm to determine if it can
   forward the request.  The SIP entity draws a random number between 1
   and 100 for the current request.  If the random number is less than
   or equal to the throttle value, the request is not forwarded.
   Otherwise, the request if forwarded as usual.  Another algorithm for
   SIP entities that processes a large number of requests is to reject/
   redirect the first X of every 100 requests processed.  Other
   algorithms that lead to the same result may be used as well.

   The treatment of SIP requests that cannot be forwarded to the
   selected SIP Server is a matter of local policy.  A SIP entity MAY
   try to find an alternative target or it MAY reject the request (see
   Section 5.7).

5.7.  Rejecting Requests

   A SIP server that rejects a request because of overload MUST reject
   this request with the 5xx response code defined for overload control
   (e.g. 503 (Service Unavailable) or 507 (Server Overload) [5]).  This



Hilt, et al.             Expires January 9, 2008               [Page 21]

Internet-Draft              Overload Control                   July 2007


   response code indicates that the request did not succeed because the
   SIP servers processing the request are under overload.

   A SIP server may determine that an upstream neighbor does not support
   this extension.  If a SIP server is under overload, it SHOULD use 5xx
   responses to reject a fraction of requests from upstream neighbors
   that do not support this extension.  This fraction SHOULD be
   equivalent to the fraction of requests the upstream server would
   reject/redirect if it did support this extension.  This is to ensure
   that SIP entities, which do not support this extension, don't receive
   an unfair advantage over those that do.

   A SIP server that has reached overload (i.e., a load close to 100)
   SHOULD start using 5xx responses in addition to the throttle
   parameter in the Load header for all upstream neighbors.  If the
   proxy has reached a load close to 100, it needs to protect itself
   against overload.  Also, it is likely that upstream proxies have
   ignored the increasing load status reports and thus do not support
   this extension.


6.  Syntax

   This section defines the syntax of a new SIP response header, the
   Load header.  The Load header field is used to advertise the current
   load status information of a SIP entity to its upstream neighbor.

   The value of the Load header is an integer between 0 and 100 with the
   value of 0 indicating that the proxy is least overloaded and the
   value of 100 indicating that the proxy is most overloaded.

   The "target" parameter is mandatory and contains the URI of the next
   hop SIP entity for the response.  I.e., the SIP entity the response
   is forwarded to.  This is the entity that will process the Load
   header.

   The "throttle" parameter is optional and contains a number between 0
   and 100.  It describes the percentage by which the load forwarded by
   "target" SIP entity to the SIP server generating this header should
   be reduced.

   The "validity" parameter is optional and contains an indication of
   how long the reporting proxy is likely to remain in the given load
   status.

   The syntax of the Load header field is:





Hilt, et al.             Expires January 9, 2008               [Page 22]

Internet-Draft              Overload Control                   July 2007


     Load              = "Load" HCOLON loadStatus
     loadStatus        = 0-100 SEMI serverID *( SEMI loadParam )
     loadParam         = throttleRate | validMS | generic-param
     serverID          = "target" EQUAL SIP-URI | SIPS-URI
     throttleRate      = "throttle" EQUAL 0-100
     validMS           = "validity" EQUAL delta-ms
     delta-ms          = 1*DIGIT

   The BNF for SIP-URI, SIPS-URI and generic-param is defined in [2].

   Table 1 extends the Tables 2 and 3 in [2].

     Header field       where   proxy ACK BYE CAN INV OPT REG
     ________________________________________________________
     Load                 r      ard   -   o   o   o   o   o

     Header field       where   proxy NOT PRA SUB UPD MSG REF PUB
     ____________________________________________________________
     Load                 r      ard   o   o   o   o   o   o   o
                    Table 1: Load Header Field

   Example:

      Load: 80;target=p1.example.com;throttle=20;validity=500


7.  Security Considerations

   Overload control mechanisms can be used by an attacker to conduct a
   denial-of-service attack on a SIP entity if the attacker can pretend
   that the SIP entity is overloaded.  When such a forged overload
   indication is received by an upstream SIP entity, it will stop
   sending traffic to the victim.  Thus, the victim is subject to a
   denial-of-service attack.

   An attacker can create forged load status reports by inserting itself
   into the communication between the victim and its upstream neighbors.
   The attacker would need to add status reports indicating a high load
   to the responses passed from the victim to its upstream neighbor.
   Proxies can prevent this attack by communicating via TLS.  Since load
   status reports have no meaning beyond the next hop, there is no need
   to secure the communication over multiple hops.

   Another way to conduct an attack is to send a message containing a
   high load status value through a proxy that does not support this
   extension.  Since this proxy does not remove the load status
   information, it will reach the next upstream proxy.  If the attacker
   can make the recipient believe that the load status was created by



Hilt, et al.             Expires January 9, 2008               [Page 23]

Internet-Draft              Overload Control                   July 2007


   its direct downstream neighbor (and not by the attacker further
   downstream) the recipient stops sending traffic to the victim.  A
   precondition for this attack is that the victim proxy does not
   support this extension since it would not pass through load status
   information otherwise.  The attack also does not work if there is a
   stateful proxy between the attacker and the victim and only 100
   (Trying) responses are used to convey the Load header.

   A malicious SIP entity could gain an advantage by pretending to
   support this specification but never reducing the load it forwards to
   the downstream neighbor.  If its downstream neighbor receives traffic
   from multiple sources which correctly implement overload control, the
   malicious SIP entity would benefit since all other sources to its
   downstream neighbor would reduce load.

      OPEN ISSUE: the solution to this problem depends on the overload
      control algorithm.  For a fixed message rate and window-based
      overload control, it is very easy for a downstream entity to
      monitor if the upstream neighbor throttles load as directed.  For
      percentage throttling this is not always obvious since the load
      forwarded depends on the load received by the upstream neighbor.


8.  IANA Considerations

   [TBD.]


Appendix A.  Acknowledgements

   Many thanks to Rich Terpstra and Jonathan Rosenberg for their
   contributions to this specification.  A big thanks to everyone who
   has provided comments on the SIPPING mailing list.


9.  References

9.1.  Normative References

   [1]  Bradner, S., "Key words for use in RFCs to Indicate Requirement
        Levels", BCP 14, RFC 2119, March 1997.

   [2]  Rosenberg, J., Schulzrinne, H., Camarillo, G., Johnston, A.,
        Peterson, J., Sparks, R., Handley, M., and E. Schooler, "SIP:
        Session Initiation Protocol", RFC 3261, June 2002.

   [3]  Rosenberg, J. and H. Schulzrinne, "Session Initiation Protocol
        (SIP): Locating SIP Servers", RFC 3263, June 2002.



Hilt, et al.             Expires January 9, 2008               [Page 24]

Internet-Draft              Overload Control                   July 2007


   [4]  Schulzrinne, H. and J. Polk, "Communications Resource Priority
        for the Session Initiation Protocol (SIP)", RFC 4412,
        February 2006.

   [5]  Hilt, V. and I. Widjaja, "Essential Correction to the Session
        Initiation Protocol (SIP) 503 (Service Unavailable) Response",
        draft-hilt-sip-correction-503-01 (work in progress).

9.2.  Informative References

   [6]  Rosenberg, J., "Requirements for Management of Overload in the
        Session Initiation Protocol",
        draft-rosenberg-sipping-overload-reqs-02 (work in progress),
        October 2006.

   [7]  Liu, Z., "Applying Signaling Compression (SigComp) to the
        Session Initiation Protocol  (SIP)",
        draft-ietf-rohc-sigcomp-sip-07 (work in progress), July 2007.

   [8]  Rosen, B., "Framework for Emergency Calling in Internet
        Multimedia", draft-ietf-ecrit-framework-01 (work in progress),
        March 2007.


Authors' Addresses

   Volker Hilt
   Bell Labs/Alcatel-Lucent
   791 Holmdel-Keyport Rd
   Holmdel, NJ  07733
   USA

   Email: volkerh@bell-labs.com


   Indra Widjaja
   Bell Labs/Alcatel-Lucent
   600-700 Mountain Avenue
   Murray Hill, NJ  07974
   USA

   Email: iwidjaja@alcatel-lucent.com









Hilt, et al.             Expires January 9, 2008               [Page 25]

Internet-Draft              Overload Control                   July 2007


   Daryl Malas
   Level 3 Communications
   1025 Eldorado Blvd.
   Broomfield, CO
   USA

   Email: daryl.malas@level3.com


   Henning Schulzrinne
   Columbia University/Department of Computer Science
   450 Computer Science Building
   New York, NY  10027
   USA

   Phone: +1 212 939 7004
   Email: hgs@cs.columbia.edu
   URI:   http://www.cs.columbia.edu

































Hilt, et al.             Expires January 9, 2008               [Page 26]

Internet-Draft              Overload Control                   July 2007


Full Copyright Statement

   Copyright (C) The IETF Trust (2007).

   This document is subject to the rights, licenses and restrictions
   contained in BCP 78, and except as set forth therein, the authors
   retain all their rights.

   This document and the information contained herein are provided on an
   "AS IS" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE REPRESENTS
   OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY, THE IETF TRUST AND
   THE INTERNET ENGINEERING TASK FORCE DISCLAIM ALL WARRANTIES, EXPRESS
   OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTY THAT THE USE OF
   THE INFORMATION HEREIN WILL NOT INFRINGE ANY RIGHTS OR ANY IMPLIED
   WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.


Intellectual Property

   The IETF takes no position regarding the validity or scope of any
   Intellectual Property Rights or other rights that might be claimed to
   pertain to the implementation or use of the technology described in
   this document or the extent to which any license under such rights
   might or might not be available; nor does it represent that it has
   made any independent effort to identify any such rights.  Information
   on the procedures with respect to rights in RFC documents can be
   found in BCP 78 and BCP 79.

   Copies of IPR disclosures made to the IETF Secretariat and any
   assurances of licenses to be made available, or the result of an
   attempt made to obtain a general license or permission for the use of
   such proprietary rights by implementers or users of this
   specification can be obtained from the IETF on-line IPR repository at
   http://www.ietf.org/ipr.

   The IETF invites any interested party to bring to its attention any
   copyrights, patents or patent applications, or other proprietary
   rights that may cover technology that may be required to implement
   this standard.  Please address the information to the IETF at
   ietf-ipr@ietf.org.


Acknowledgment

   Funding for the RFC Editor function is provided by the IETF
   Administrative Support Activity (IASA).





Hilt, et al.             Expires January 9, 2008               [Page 27]


