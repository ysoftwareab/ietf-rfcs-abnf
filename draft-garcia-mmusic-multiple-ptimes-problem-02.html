<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en"><head><title>Multiple Packetization Times in the Session Description Protocol (SDP):
      Problem Statement, Requirements &amp; Solutions</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="description" content="Multiple Packetization Times in the Session Description Protocol (SDP):
      Problem Statement, Requirements &amp; Solutions">
<meta name="keywords" content="SDP, ptime, multiple">
<meta name="generator" content="xml2rfc v1.35 (http://xml.resource.org/)">
<meta name="viewport" content="width=600;" />
<style type='text/css'><!--
        body {
                font-family: verdana, charcoal, helvetica, arial, sans-serif;
                font-size: 85%;
		max-width: 40em; 
		color: #000; background-color: #FFF;
                margin: 2em;
        }
        h1, h2, h3, h4, h5, h6 {
                font-family: helvetica, monaco, "MS Sans Serif", arial, sans-serif;
                font-weight: bold; font-style: normal;
        }
        h1 { color: #900; background-color: transparent; text-align: right; }
        h3 { color: #333; background-color: transparent; }

        td.RFCbug {
                font-size: x-small; text-decoration: none;
                width: 30px; height: 30px; padding-top: 2px;
                text-align: justify; vertical-align: middle;
                background-color: #000;
        }
        td.RFCbug span.RFC {
                font-family: monaco, charcoal, geneva, "MS Sans Serif", helvetica, verdana, sans-serif;
                font-weight: bold; color: #666;
        }
        td.RFCbug span.hotText {
                font-family: charcoal, monaco, geneva, "MS Sans Serif", helvetica, verdana, sans-serif;
                font-weight: normal; text-align: center; color: #FFF;
        }

        table.TOCbug { width: 30px; height: 15px; }
        td.TOCbug {
                text-align: center; width: 30px; height: 15px;
                color: #FFF; background-color: #900;
        }
        td.TOCbug a {
                font-family: monaco, charcoal, geneva, "MS Sans Serif", helvetica, sans-serif;
                font-weight: bold; font-size: x-small; text-decoration: none;
                color: #FFF; background-color: transparent;
        }

        td.header {
                font-family: arial, helvetica, sans-serif; font-size: x-small;
                vertical-align: top; width: 33%;
                color: #FFF; background-color: #666;
        }
        td.author { font-weight: bold; font-size: x-small; margin-left: 4em; }
        td.author-text { font-size: x-small; }

        /* info code from SantaKlauss at http://www.madaboutstyle.com/tooltip2.html */
        a.info {
                /* This is the key. */
                position: relative;
                z-index: 24;
                text-decoration: none;
        }
        a.info:hover {
                z-index: 25;
                color: #FFF; background-color: #900;
        }
        a.info span { display: none; }
        a.info:hover span.info {
                /* The span will display just on :hover state. */
                display: block;
                position: absolute;
                font-size: smaller;
                top: 2em; left: -5em; width: 15em;
                padding: 2px; border: 1px solid #333;
                color: #900; background-color: #EEE;
                text-align: left;
        }

        a { font-weight: bold; }
        a:link    { color: #900; background-color: transparent; }
        a:visited { color: #633; background-color: transparent; }
        a:active  { color: #633; background-color: transparent; }

        p { margin-left: 2em; margin-right: 2em; }
        p.copyright { font-size: x-small; }
        p.toc { font-size: 85%;
		max-width: 40em; 
		font-weight: bold; margin-left: 3em; }
        table.toc { margin: 0 0 0 3em; padding: 0; border: 0; vertical-align: text-top; }
        td.toc { font-size: 85%;
		max-width: 40em; 
		font-weight: bold; vertical-align: text-top; }

        ol.text { margin-left: 2em; margin-right: 2em; }
        ul.text { margin-left: 2em; margin-right: 2em; }
        li      { margin-left: 3em; }

        /* RFC-2629 <spanx>s and <artwork>s. */
        em     { font-style: italic; }
        strong { font-weight: bold; }
        dfn    { font-weight: bold; font-style: normal; }
        cite   { font-weight: normal; font-style: normal; }
        tt     { color: #036; }
        tt, pre, pre dfn, pre em, pre cite, pre span {
                font-family: "Courier New", Courier, monospace; font-size: small;
        }
        pre {
                text-align: left; padding: 4px;
                color: #000; background-color: #CCC;
        }
        pre dfn  { color: #900; }
        pre em   { color: #66F; background-color: #FFC; font-weight: normal; }
        pre .key { color: #33C; font-weight: bold; }
        pre .id  { color: #900; }
        pre .str { color: #000; background-color: #CFF; }
        pre .val { color: #066; }
        pre .rep { color: #909; }
        pre .oth { color: #000; background-color: #FCF; }
        pre .err { background-color: #FCC; }

        /* RFC-2629 <texttable>s. */
        table.all, table.full, table.headers, table.none {
                font-size: 85%;
		max-width: 40em; 
		text-align: center; border-width: 2px;
                vertical-align: top; border-collapse: collapse;
        }
        table.all, table.full { border-style: solid; border-color: black; }
        table.headers, table.none { border-style: none; }
        th {
                font-weight: bold; border-color: black;
                border-width: 2px 2px 3px 2px;
        }
        table.all th, table.full th { border-style: solid; }
        table.headers th { border-style: none none solid none; }
        table.none th { border-style: none; }
        table.all td {
                border-style: solid; border-color: #333;
                border-width: 1px 2px;
        }
        table.full td, table.headers td, table.none td { border-style: none; }

        hr { height: 1px; }
        hr.insert {
                width: 80%; border-style: none; border-width: 0;
                color: #CCC; background-color: #CCC;
        }
--></style>
</head>
<body>
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<table summary="layout" width="66%" border="0" cellpadding="0" cellspacing="0"><tr><td><table summary="layout" width="100%" border="0" cellpadding="2" cellspacing="1">
<tr><td class="header">MMUSIC Working Group</td><td class="header">M. Willekens</td></tr>
<tr><td class="header">Internet-Draft</td><td class="header">M. Garcia-Martin</td></tr>
<tr><td class="header">Intended status: Informational</td><td class="header">Nokia Siemens Networks</td></tr>
<tr><td class="header">Expires: August 28, 2008</td><td class="header">P. Xu</td></tr>
<tr><td class="header">&nbsp;</td><td class="header">Huawei Technologies</td></tr>
<tr><td class="header">&nbsp;</td><td class="header">February 25, 2008</td></tr>
</table></td></tr></table>
<h1><br />Multiple Packetization Times in the Session Description Protocol (SDP):
      Problem Statement, Requirements &amp; Solutions<br />draft-garcia-mmusic-multiple-ptimes-problem-02.txt</h1>

<h3>Status of this Memo</h3>
<p>
By submitting this Internet-Draft,
each author represents that any applicable patent or other IPR claims of which
he or she is aware have been or will be disclosed,
and any of which he or she becomes aware will be disclosed,
in accordance with Section&nbsp;6 of BCP&nbsp;79.</p>
<p>
Internet-Drafts are working documents of the Internet Engineering
Task Force (IETF), its areas, and its working groups.
Note that other groups may also distribute working documents as
Internet-Drafts.</p>
<p>
Internet-Drafts are draft documents valid for a maximum of six months
and may be updated, replaced, or obsoleted by other documents at any time.
It is inappropriate to use Internet-Drafts as reference material or to cite
them other than as &ldquo;work in progress.&rdquo;</p>
<p>
The list of current Internet-Drafts can be accessed at
<a href='http://www.ietf.org/ietf/1id-abstracts.txt'>http://www.ietf.org/ietf/1id-abstracts.txt</a>.</p>
<p>
The list of Internet-Draft Shadow Directories can be accessed at
<a href='http://www.ietf.org/shadow.html'>http://www.ietf.org/shadow.html</a>.</p>
<p>
This Internet-Draft will expire on August 28, 2008.</p>

<h3>Abstract</h3>

<p>
        This document provides a problem statement and requirements with respect to the
        presence of a single packetization time (ptime/maxptime) attribute in SDP media
        descriptions that contain several media formats (audio codecs).
        Some methods already proposed and provided as ad-hoc solutions are indicated as
        background information. Furthermore, a clarification is made about a best common
        practice for the use of 'ptime/maxptime'.
      
</p><a name="toc"></a><br /><hr />
<h3>Table of Contents</h3>
<p class="toc">
<a href="#anchor1">1.</a>&nbsp;
Introduction<br />
<a href="#anchor2">2.</a>&nbsp;
Some Definitions<br />
<a href="#anchor3">3.</a>&nbsp;
Some references<br />
<a href="#anchor4">4.</a>&nbsp;
Problem Statement<br />
<a href="#anchor5">5.</a>&nbsp;
Requirements<br />
<a href="#anchor6">6.</a>&nbsp;
Solutions already proposed<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor7">6.1.</a>&nbsp;
Method 1<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor8">6.2.</a>&nbsp;
Method 2<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor9">6.3.</a>&nbsp;
Method 3<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor10">6.4.</a>&nbsp;
Method 4<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor11">6.5.</a>&nbsp;
Method 5<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor12">6.6.</a>&nbsp;
Method 6<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor13">6.7.</a>&nbsp;
Method 7<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor14">6.8.</a>&nbsp;
Method 8<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor15">6.9.</a>&nbsp;
Method 9<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor16">6.10.</a>&nbsp;
Method 10<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor17">6.11.</a>&nbsp;
Method 11<br />
<a href="#anchor18">7.</a>&nbsp;
Clarification<br />
<a href="#anchor19">8.</a>&nbsp;
New proposal<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor20">8.1.</a>&nbsp;
Sending party RTP voice payload<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor21">8.1.1.</a>&nbsp;
ptime(s) - Static<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor22">8.1.2.</a>&nbsp;
ptime(d) - Dynamic<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor23">8.1.3.</a>&nbsp;
ptime(i) - Indicated<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor24">8.1.4.</a>&nbsp;
ptime/maxptime algorithm<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor25">8.1.5.</a>&nbsp;
Algorithm and examples<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor26">8.1.5.1.</a>&nbsp;
Codec independent parameters<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor27">8.1.5.2.</a>&nbsp;
Codec dependent parameters<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor28">8.1.5.3.</a>&nbsp;
Pseudocode algorithm<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor29">8.1.5.4.</a>&nbsp;
Pseudocode examples<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor30">8.2.</a>&nbsp;
Procedures for the SDP offer/answer<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor31">8.2.1.</a>&nbsp;
Procedures for an SDP offerer<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor32">8.2.2.</a>&nbsp;
Procedures for an SDP answerer<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor33">8.3.</a>&nbsp;
Receiving party RTP voice payload<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#anchor34">8.4.</a>&nbsp;
Advantages<br />
<a href="#anchor35">9.</a>&nbsp;
Conclusion and next steps<br />
<a href="#sec-security">10.</a>&nbsp;
Security Considerations<br />
<a href="#sec-iana">11.</a>&nbsp;
IANA Considerations<br />
<a href="#rfc.references1">12.</a>&nbsp;
References<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#rfc.references1">12.1.</a>&nbsp;
Normative References<br />
&nbsp;&nbsp;&nbsp;&nbsp;<a href="#rfc.references2">12.2.</a>&nbsp;
Informative References<br />
<a href="#rfc.authors">&#167;</a>&nbsp;
Authors' Addresses<br />
<a href="#rfc.copyright">&#167;</a>&nbsp;
Intellectual Property and Copyright Statements<br />
</p>
<br clear="all" />

<a name="anchor1"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.1"></a><h3>1.&nbsp;
Introduction</h3>

<p>
        <a class='info' href='#RFC4566'>"Session Description Protocol" (SDP)<span> (</span><span class='info'>Handley, M., Jacobson, V., and C. Perkins, &ldquo;SDP: Session Description Protocol,&rdquo; July&nbsp;2006.</span><span>)</span></a> [RFC4566]
        provides a protocol to describe multimedia sessions
        for the purposes of session announcement, session invitation,
        and other forms of multimedia session initiation. A session
        description in SDP includes the session name and purpose, the
        media comprising the session, information needed to receive the
        media (addresses, ports, formats, etc.) and some other
        information.
      
</p>
<p>
        In the SDP media description part, the m-line contains the
        media type (e.g. audio), a transport port, a transport
        protocol (e.g. RTP/AVP) and a media format description which
        depends on the transport protocol.
      
</p>
<p>
        For the transport protocol RTP/AVP or RTP/SAVP, the media
        format sub-field can contain a list of RTP payload type
        numbers.
        See <a class='info' href='#RFC3551'>"RTP Profile for Audio and Video Conferences with Minimal Control"<span> (</span><span class='info'>Schulzrinne, H. and S. Casner, &ldquo;RTP Profile for Audio and Video Conferences with Minimal Control,&rdquo; July&nbsp;2003.</span><span>)</span></a> [RFC3551],
        Table 4.<br />

        For example: "m=audio 49232 RTP/AVP 3 15 18" indicates the audio encoders 
        GSM, G728, and G729.
      
</p>
<p>
        Further, the media description part can contain additional
        attribute lines that complement or modify the media
        description line. Of interest for this memo, are the 'ptime'
        and 'maxptime' attributes.
        According to <a class='info' href='#RFC4566'>[RFC4566]<span> (</span><span class='info'>Handley, M., Jacobson, V., and C. Perkins, &ldquo;SDP: Session Description Protocol,&rdquo; July&nbsp;2006.</span><span>)</span></a>, the 'ptime' attribute gives
        the length of time in milliseconds represented by the media in
        a packet, and the 'maxptime' gives the maximum amount of media
        that can be encapsulated in each packet, expressed as time in
        milliseconds. These attributes modify the whole media
        description line, which can contain an extensive list of
        payload types. In other words, these attributes are not
        specific to a given codec.
      
</p>
<p>
        <a class='info' href='#RFC4566'>[RFC4566]<span> (</span><span class='info'>Handley, M., Jacobson, V., and C. Perkins, &ldquo;SDP: Session Description Protocol,&rdquo; July&nbsp;2006.</span><span>)</span></a> also indicates that it
        should not be necessary to know 'ptime' to decode RTP or vat
        audio since the 'ptime' attribute is intended as a
        recommendation for the encoding/packetization of
        audio. However, once more, the existing 'ptime' attribute
        defines the desired packetization time for all the payload
        types defined in the corresponding media description line.
      
</p>
<p>
        End-devices can sometimes be configured with different codecs and for
        each codec a different packetization time can be
        indicated. However, there is no clear way to exchange this
        type of information between different user agents and this can
        result in lower voice quality, network problems or performance
        problems in the end-devices.
      
</p>
<a name="anchor2"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.2"></a><h3>2.&nbsp;
Some Definitions</h3>

<p>
        <a class='info' href='#RFC4566'>[RFC4566]<span> (</span><span class='info'>Handley, M., Jacobson, V., and C. Perkins, &ldquo;SDP: Session Description Protocol,&rdquo; July&nbsp;2006.</span><span>)</span></a> defines the 'ptime' and 'maxptime' as:
      
</p>
<p>
        </p>
<blockquote class="text">
<p>
            a=ptime:[packet time]
          
</p>
<p>
            "This gives the length of time in milliseconds represented by
            the media in a packet. This is probably only meaningful for
            audio data, but may be used with other media types if it makes
            sense. It should not be necessary to know ptime to decode RTP
            or vat audio, and it is intended as a recommendation for the
            encoding/packetization of audio. It is a media-level
            attribute, and it is not dependent on charset."
          
</p>
</blockquote><p>
      
</p>
<p>
        </p>
<blockquote class="text">
<p>
            a=maxptime:[maximum packet time]
          
</p>
<p>
            "This gives the maximum amount of media that can be encapsulated
            in each packet, expressed as time in milliseconds. The time
            SHALL be calculated as the sum of the time the media present in
            the packet represents. For frame-based codecs, the time SHOULD
            be an integer multiple of the frame size. This attribute is
            probably only meaningful for audio data, but may be used with
            other media types if it makes sense. It is a media-level
            attribute, and it is not dependent on charset."
          
</p>
</blockquote><p>
      
</p>
<p>
        </p>
<blockquote class="text">
<p>
            "Additional encoding parameters MAY be defined in the future,
            but codec-specific parameters SHOULD NOT be added. Parameters
            added to an "a=rtpmap:" attribute SHOULD only be those required
            for a session directory to make the choice of appropriate media
            to participate in a session. Codec-specific parameters should
            be added in other attributes (for example, "a=fmtp:")."
          
</p>
</blockquote><p>
      
</p>
<p>
        </p>
<blockquote class="text">
<p>
            "Note: RTP audio formats typically do not include information
            about the number of samples per packet. If a non-default (as
            defined in the RTP Audio/Video Profile) packetization is
            required, the 'ptime' attribute is used as given above."
          
</p>
</blockquote><p>
      
</p>
<p>
        Remark:<br />

        'maxptime' was introduced after the release of <a class='info' href='#RFC2327'>[RFC2327]<span> (</span><span class='info'>Handley, M. and V. Jacobson, &ldquo;SDP: Session Description Protocol,&rdquo; April&nbsp;1998.</span><span>)</span></a>,
        and non-updated implementations will ignore this attribute.
      
</p>
<a name="anchor3"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.3"></a><h3>3.&nbsp;
Some references</h3>

<p>
        Many RFCs make references to the 'ptime/maxptime' attribute to 
        give some definitions, recommendations, requirements, default values.
      
</p>
<p>
        <a class='info' href='#RFC4566'>"Session Description Protocol" SDP<span> (</span><span class='info'>Handley, M., Jacobson, V., and C. Perkins, &ldquo;SDP: Session Description Protocol,&rdquo; July&nbsp;2006.</span><span>)</span></a> [RFC4566].<br />

        Definitions for 'ptime/maxptime'.
      
</p>
<p>
        <a class='info' href='#RFC3264'>"SDP Offer/answer model"<span> (</span><span class='info'>Rosenberg, J. and H. Schulzrinne, &ldquo;An Offer/Answer Model with Session Description Protocol (SDP),&rdquo; June&nbsp;2002.</span><span>)</span></a> [RFC3264].<br />

        Describe requirements for the 'ptime' for the SDP offerer and SDP answerer. <br />


        If the 'ptime' attribute is present for a stream, it indicates the
        desired packetization interval that the offerer would like to
        receive. The 'ptime' attribute MUST be greater than zero.<br />


        The answerer MAY include a non-zero 'ptime' attribute for any media
        stream. This indicates the packetization interval that the answerer
        would like to receive.
        There is no requirement for the packetization interval to be the same
        in each direction for a particular stream.
      
</p>
<p>
        <a class='info' href='#RFC3890'>"SDP Transport independent bandwidth modifier"<span> (</span><span class='info'>Westerlund, M., &ldquo;A Transport Independent Bandwidth Modifier for the Session Description Protocol (SDP),&rdquo; September&nbsp;2004.</span><span>)</span></a> [RFC3890].<br />

        Indicates the 'ptime' as a possible candidate for the bandwidth but 
        it should be avoided for that purpose. The use of another parameter is
        indicated as a proposed method.
      
</p>
<p>
        <a class='info' href='#RFC3108'>"SDP Conversions for ATM bearer"<span> (</span><span class='info'>Kumar, R. and M. Mostafa, &ldquo;Conventions for the use of the Session Description Protocol (SDP) for ATM Bearer Connections,&rdquo; May&nbsp;2001.</span><span>)</span></a> [RFC3108].<br />

        It is not recommended to use the 'ptime' in ATM applications since packet 
        period information is provided with other parameters (e.g. the profile type and
        number in the 'm' line, and the 'vsel', 'dsel' and 'fsel'
        attributes).  Also, for AAL1 applications, 'ptime' is not
        applicable and should be flagged as an error.  If used in AAL2
        and AAL5 applications, 'ptime' should be consistent with the
        rest of the SDP description.<br />


        The 'vsel', 'dsel' and 'fsel' attributes refer generically
        to codecs.  These can be used for service-specific codec negotiation and
        assignment in non-ATM as well as for ATM applications.<br />


        The 'vsel' attribute indicates a prioritized list of one or more 3-
        tuples for voice service.  Each 3-tuple indicates a codec, an
        optional packet length and an optional packetization period.  This
        complements the 'm' line information and should be consistent with
        it.<br />


        The 'vsel' attribute refers to all directions of a connection.  For a
        bidirectional connection, these are the forward and backward
        directions.  For a unidirectional connection, this can be either the
        backward or forward direction.<br />


        The 'vsel' attribute is not meant to be used with bidirectional
        connections that have asymmetric codec configurations described in a
        single SDP descriptor.  For these, the 'onewaySel' attribute 
        should be used.<br />

        
        The 'vsel' line is structured with an encodingName, a packetLength and a
        packetTime.<br />

        
        The packetLength is a decimal integer
        representation of the packet length in octets.  The packetTime is a
        decimal integer representation of the packetization interval in
        microseconds.  The parameters packetLength and packetTime can be
        set to "-" when not needed.  Also, the entire 'vsel' media attribute
        line can be omitted when not needed.<br />

      
</p>
<p>
        <a class='info' href='#RFC4504'>"SIP device requirements and configuration"<span> (</span><span class='info'>Sinnreich, H., Lass, S., and C. Stredicke, &ldquo;SIP Telephony Device Requirements and Configuration,&rdquo; May&nbsp;2006.</span><span>)</span></a> [RFC4504].<br />

        In some cases, certain network architectures have constraints influencing
        the end devices. The desired subset of codecs supported by the device
        SHOULD be configurable along with the order of preference.  Service
        providers SHOULD have the possibility of plugging in own preferred codecs.
        The codec settings MAY include the packet length and
        other parameters like silence suppression or comfort noise
        generation.

        The set of available codecs will be used in the codec negotiation
        according to <a class='info' href='#RFC3264'>[RFC3264]<span> (</span><span class='info'>Rosenberg, J. and H. Schulzrinne, &ldquo;An Offer/Answer Model with Session Description Protocol (SDP),&rdquo; June&nbsp;2002.</span><span>)</span></a>.<br />

        Example: Codecs="speex/8000;ptime=20;cng=on,gsm;ptime=30"
      
</p>
<p>
        <a class='info' href='#RFC3441'>"MGCP ATM package"<span> (</span><span class='info'>Kumar, R., &ldquo;Asynchronous Transfer Mode (ATM) Package for the Media Gateway Control Protocol (MGCP),&rdquo; January&nbsp;2003.</span><span>)</span></a> [RFC3441].<br />

        Packet time changed ("ptime(#)"):<br />


        If armed via an R:atm/ptime, a media gateway signals a packetization
        period change through an O:atm/ptime.  The decimal number, in
        parentheses, is optional.  It is the new packetization period in
        milliseconds.  In AAL2 applications, the pftrans event can be used to
        cover packetization period changes (and codec changes).<br />


        Voice codec selection (vsel): This is a prioritized list of one or
        more 3-tuples describing voice service.  Each vsel 3-tuple indicates
        a codec, an optional packet length and an optional packetization
        period.
      
</p>
<p>
        <a class='info' href='#RFC3952'>"RTP payload for iLBC"<span> (</span><span class='info'>Duric, A. and S. Andersen, &ldquo;Real-time Transport Protocol (RTP) Payload Format for internet Low Bit Rate Codec (iLBC) Speech,&rdquo; December&nbsp;2004.</span><span>)</span></a> [RFC3952].<br />

        The 'maxptime' SHOULD be a multiple of
        the frame size.  This attribute is probably only meaningful
        for audio data, but may be used with other media types if it
        makes sense.  It is a media attribute, and is not dependent
        on charset.  Note that this attribute was introduced after
        <a class='info' href='#RFC2327'>[RFC2327]<span> (</span><span class='info'>Handley, M. and V. Jacobson, &ldquo;SDP: Session Description Protocol,&rdquo; April&nbsp;1998.</span><span>)</span></a>, and non updated implementations will ignore this
        attribute.<br />


        Parameter 'ptime' can not be used for the purpose of specifying iLBC
        operating mode, due to fact that for the certain values it will be
        impossible to distinguish which mode is about to be used (e.g., when
        'ptime=60', it would be impossible to distinguish if packet is carrying
        2 frames of 30 ms or 3 frames of 20 ms, etc.).
      
</p>
<p>
        <a class='info' href='#RFC4060'>"RTP payload for distributed speech recognition"<span> (</span><span class='info'>Xie, Q. and D. Pearce, &ldquo;RTP Payload Formats for European Telecommunications Standards Institute (ETSI) European Standard ES 202 050, ES 202 211, and ES 202 212 Distributed Speech Recognition Encoding,&rdquo; May&nbsp;2005.</span><span>)</span></a> [RFC4060].<br />

        If 'maxptime' is not present, 'maxptime' is assumed to be 80ms.<br />


        Note, since the performance of most speech recognizers are
        extremely sensitive to consecutive FP losses, if the user of the
        payload format expects a high packet loss ratio for the session,
        it MAY consider to explicitly choose a 'maxptime' value for the
        session that is shorter than the default value.
      
</p>
<a name="anchor4"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.4"></a><h3>4.&nbsp;
Problem Statement</h3>

<p>
        The packetization time is an important parameter which helps
        in reducing the packet overhead. Many voice codecs define a
        certain frame length used to determine the coded voice filter
        parameters and try to find a certain trade-off between the
        perceived voice quality, measured by the Mean Option Score
        (MOS), and the required bitrate. When a packet
        oriented network is used for the transfer, the packet header
        induces an additional overhead.  As such, it makes sense to
        combine different voice frame data in one packet, up to
        a Maximum Transmission Unit (MTU), to find a good balance
        between the required network resources, end-device resources
        and the perceived voice quality influenced by packet loss,
        packet delay, jitter.  When the packet size decreases, the
        bandwidth efficiency is reduced. When the packet size
        increases, the packetization delay can have a negative impact
        on the perceived voice quality.
      
</p>
<p>
        The <a class='info' href='#RFC3551'>"RTP Profile for Audio and Video
        Conferences with Minimal Control"<span> (</span><span class='info'>Schulzrinne, H. and S. Casner, &ldquo;RTP Profile for Audio and Video Conferences with Minimal Control,&rdquo; July&nbsp;2003.</span><span>)</span></a> [RFC3551], Table 1, indicates
        the frame size and default packetization time for different
        codecs. The G728 codec has a frame size of 2.5 ms/frame and
        a default packetization time of 20 ms/packet.  For G729
        codec, the frame size is 10 ms/frame and a default
        packetization time of 20 ms/packet.
      
</p>
<p>
        When more and more audio streaming traffic is carried over
        IP-networks, the quality as perceived by the end-user should
        be no worse as the classical telephony services. For VoIP
        service providers, it is very important that endpoints receive
        audio with the best possible codec and packetization time. In
        particular, the packetization time depends on the selected
        codec for the audio communication and other factors, such as
        the Maximum Transmission Unit (MTU) of the network and the
        type of access network technology.
      
</p>
<p>
        As such, the packetization time is clearly a function of the
        codec and the network access technology. During the
        establishment of a new session or a modification of an existing
        session, an endpoint should be able to express its preferences
        with respect to the packetization time for each codec. This would
        mean that the creator of the SDP prefers the remote endpoint to
        use certain packetization time when sending media with that
        codec.
      
</p>
<p>
        <a class='info' href='#RFC4566'>SDP<span> (</span><span class='info'>Handley, M., Jacobson, V., and C. Perkins, &ldquo;SDP: Session Description Protocol,&rdquo; July&nbsp;2006.</span><span>)</span></a> [RFC4566] provides the means for
        expressing a packetization time that affects all the payload
        types declared in the media description line. So, there are no
        means to indicate the desired packetization time on a per
        payload type basis. Implementations have been using
        proprietary mechanisms for indicating the packetization time
        per payload type, leading to interoperability problems.
      
</p>
<p>
        One of these mechanisms is the 'maxmptime' attribute, defined in
        <a class='info' href='#ITU.V152'>[ITU.V152]<span> (</span><span class='info'>ITU-T, &ldquo;Procedures for supporting voice-band data over IP networks,&rdquo; January&nbsp;2005.</span><span>)</span></a>, which indicates the supported packetization
        period for all codec payload types.
      
</p>
<p>
        Another one is the 'mptime' attribute, defined by
        <a class='info' href='#PKT.PKT-SP-EC-MGCP'>"PacketCable"<span> (</span><span class='info'>PacketCable, &ldquo;PacketCable Network-Based Call Signaling Protocol Specification,&rdquo; August&nbsp;2005.</span><span>)</span></a> [PKT.PKT&#8209;SP&#8209;EC&#8209;MGCP], which indicates a
        list of packetization period values the endpoint is capable of
        using (sending and receiving) for this connection.
      
</p>
<p>
        While all have similar semantics, there is obviously no interoperability
        between them, creating a nightmare for the implementer who happens to be
        defining a common SDP stack for different applications.
      
</p>
<p>
        A few RTP payload format descriptions, such as: <br />

        <a class='info' href='#RFC3267'>[RFC3267]<span> (</span><span class='info'>Sjoberg, J., Westerlund, M., Lakaniemi, A., and Q. Xie, &ldquo;Real-Time Transport Protocol (RTP) Payload Format and File Storage Format for the Adaptive Multi-Rate (AMR) and Adaptive Multi-Rate Wideband (AMR-WB) Audio Codecs,&rdquo; June&nbsp;2002.</span><span>)</span></a>, <a class='info' href='#RFC3016'>[RFC3016]<span> (</span><span class='info'>Kikuchi, Y., Nomura, T., Fukunaga, S., Matsui, Y., and H. Kimata, &ldquo;RTP Payload Format for MPEG-4 Audio/Visual Streams,&rdquo; November&nbsp;2000.</span><span>)</span></a>, and <a class='info' href='#RFC3952'>[RFC3952]<span> (</span><span class='info'>Duric, A. and S. Andersen, &ldquo;Real-time Transport Protocol (RTP) Payload Format for internet Low Bit Rate Codec (iLBC) Speech,&rdquo; December&nbsp;2004.</span><span>)</span></a>,
        indicate that the packetization time for such payload should
        be indicated in the 'ptime' attribute in SDP. However, since
        the 'ptime' attribute affects all payload formats included
        in the media description line, it would not be possible to
        create a media description line that contains all the
        mentioned payload formats and different packetization
        times. The solutions range from considering a single
        packetization time for all payload types, or creating a
        media description line that contains a single payload type.
      
</p>
<p>
        However, once more, if several payload formats are
        offered in the same media description line in SDP, there is no
        way to indicate different packetization times per payload format.
      
</p>
<a name="anchor5"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.5"></a><h3>5.&nbsp;
Requirements</h3>

<p>
        The main requirement is coming from the implementation and media gateway
        community making use of hardware based solutions, e.g. DSP or FPGA
        implementations with silicon constraints for the amount of buffer space.
      
</p>
<p>
        Some are making use of the ptime/codec information to make certain QoS budget
        calculations.
        When the packetization time is known for a codec with a certain
        frame size and frame data rate, the efficiency of the throughput
        can be calculated.
      
</p>
<p>
        Currently, the 'ptime' and 'maxptime' are "indication" attributes and optional.
        When these parameters are used for resource reservation and for hardware
        initializations, a negotiated value between the SDP offerer and SDP answerer
        can become a requirement.
      
</p>
<p>
        There could be different sources for the 'ptime/maxptime', i.e. from RTP/AVP
        profile, from end-user device configuration, from network architecture, 
        from receiver.
      
</p>
<p>
        The codec and 'ptime/maxptime' in upstream and downstream can be different.
      
</p>
<a name="anchor6"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6"></a><h3>6.&nbsp;
Solutions already proposed</h3>

<p>
        During last years, different solutions were already proposed and
        implemented with the goal to make the 'ptime' in function of the codec
        instead of the media, containing a list of codecs.
        The list of given solutions indicates what kind of logical
        proposals were already made to find a solution for the SDP interworking
        issues due to implementation and RFC interpretations without imposing
        any preference for a certain solution.
      
</p>
<p>
        In all these proposals, a semantic grouping of the codec specific
        information is made by giving a new interpretation of the sequence
        of the parameters or by providing new additional attributes.
      
</p>
<p>
        REMARK:<br />

        All these methods are against the basic rule indicated in the RFCs which
        state that a 'ptime' and 'maxptime' are media specific and NOT codec specific.
        It does not solve the interworking issues! Instead, it makes it worse due
        to many new interpretations and implementations as indicated by following
        examples.
      
</p>
<p>
        To avoid a further divergence, the implementation community is strongly
        asking for a standardized solution.
      
</p>
<a name="anchor7"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.1"></a><h3>6.1.&nbsp;
Method 1</h3>

<p>
          Write the rtpmap first, followed by the 'ptime' when it is related to the
          codec indicated by that rtpmap. 
        
</p>
<p>
          This method tries to correlate a ptime to a specific codec but many existing
          implementations will suffer from such a proposal. 
          Some SDP encoder implementations first write the media line, followed by the
          rtpmap lines and then the other value attributes such as ptime and fmtp.
          So, it is difficult to know to which payload type the
          'ptime' is related. In following example, it's hard to tell if ptime:20
          is related to payload 0 or 4 or both and the interpretation of this information
          by the remote end is unknown. Implementations which are fully compliant with 
          the existing RFCs will suffer from such new proposals.
        
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

m=audio 1234 RTP/AVP 4 0
a=rtpmap:4 G723/8000
a=rtpmap:0 PCMU/8000
a=ptime:20
a=fmtp:4 bitrate=6400
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Method 1&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor8"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.2"></a><h3>6.2.&nbsp;
Method 2</h3>

<p>
          Grouping of all codec specific information together.
        
</p>
<p>
          Most implementers are in favor of this proposal, i.e. writing the value
          attributes associated with an rtpmap listed immediately after it. But, this
          is also a new interpretation. Normally, the ptime refers to all payload types
          indicated in the m-line. All existing implementations will also suffer from 
          such a method.
        
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

m=audio 1234 RTP/AVP 4 0
a=rtpmap:4 G723/8000
a=fmtp:4 bitrate=6400
a=rtpmap:0 PCMU/8000
a=ptime:20
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Method 2&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor9"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.3"></a><h3>6.3.&nbsp;
Method 3</h3>

<p>
          Use the 'ptime' for every codec after its rtpmap definition. This makes the
          'ptime' a required parameter for each payload type. It looks obvious but not
          allowed according the existing RFCs. And will the same construct be used 
          for the 'maxptime'?
        
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

m=audio 1234 RTP/AVP 0 18 4

a=rtpmap:18 G729/8000
a=ptime:30

a=rtpmap:0 PCMU/8000
a=ptime:40

a=rtpmap:4 G723/8000
a=ptime:60
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Method 3&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor10"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.4"></a><h3>6.4.&nbsp;
Method 4</h3>

<p>
          Create a new 'mptime' (multiple ptime) attribute that contains different
          packetization times, each one mapped to its corresponding payload type
          in the preceding 'm=' line. 
          What will happen when the other side sends a RTP stream with a different
          packetization time? Should the elements in the mptime attribute be interpreted
          as required values or preferred values? With this approach, the RFC
          compliant implementations are also affected and have to consider to the new
          mptime attribute.
        
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

m=audio 1234 RTP/AVP 0 18 4
a=mptime 40 30 60
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Method 4&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor11"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.5"></a><h3>6.5.&nbsp;
Method 5</h3>

<p>
          Use of a new 'x-ptime' attribute. However, SDP parsers complained
          about x- headers. It was once indicated to better use something
          without x- (e.g. 'xptime'). This is just another type of encoding
          of method 4 and also doesn't solve anything.
        
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

m=audio 1234 RTP/AVP 0 8
a=x-ptime 20 30
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Method 5&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor12"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.6"></a><h3>6.6.&nbsp;
Method 6</h3>

<p>
          Use of different m-lines with one codec per m-line.<br />

          However this is a misuse because different m-lines means different audio streams
          and not different codec options. So, this is certainly against the existing
          SDP concept.
        
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

m=audio 1234 RTP/AVP 0
a=rtpmap:0 PCMU/8000
a=ptime:40

m=audio 1234 RTP/AVP 18
a=rtpmap:18 G729/8000
a=ptime:30

m=audio 1234 RTP/AVP 4
a=rtpmap:4 G723/8000
a=ptime:60
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Method 6&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor13"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.7"></a><h3>6.7.&nbsp;
Method 7</h3>

<p>
          Use of the 'ptime' in the 'fmtp' attribute
        
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

m=audio 1234 RTP/AVP 4 18
a=rtpmap:18 G729/8000
a=fmtp:18 annexb=yes;ptime=20
a=maxptime:40

a=rtpmap 4 G723/8000
a=fmtp:4 bitrate=6.3;annexa=yes;ptime=30
a=maxptime:60
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Method 7&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor14"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.8"></a><h3>6.8.&nbsp;
Method 8</h3>

<p>
          Use of the vsel parameter as done for ATM bearer connections
          Following example indicates first preference of G.729 or G.729a (both are
          interoperable) as the voice encoding scheme.  A packet length of 10
          octets and a packetization interval of 10 ms are associated with this
          codec.  G726-32 is the second preference stated in this line, with an
          associated packet length of 40 octets and a packetization interval of
          10 ms.  If the packet length and packetization interval are intended
          to be omitted, then this media attribute line contains '-'.
        
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

a=vsel:G729 10 10000 G726-32 40 10000
a=vsel:G729 - - G726-32 - -
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Method 8&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor15"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.9"></a><h3>6.9.&nbsp;
Method 9</h3>

<p>
          Use of <a class='info' href='#ITU.V152'>[ITU.V152]<span> (</span><span class='info'>ITU-T, &ldquo;Procedures for supporting voice-band data over IP networks,&rdquo; January&nbsp;2005.</span><span>)</span></a>'maxmptime' (maximum multiple ptime) attribute,
          which contains different packetization times, each one maps to its
          corresponding payload type described in the preceding 'm=' line to
          indicate the supported packetization period for all codec payload
          types. This attribute is a media-level attribute and defines a list
          of maximum packetization time values, expressed in milliseconds, the
          endpoint is capable of using (sending and receiving) for the connection. When
          the maxmptime attribute is present, the ptime shall be ignored according to
          the V.152 specification. When the maxptime is absent, then the value of ptime
          attribute, if present, shall be taken as indicating the packetization period
          for all codecs present in the 'm=' line.<br />

          The specification doesn't specify what has to be done when a 'maxptime' is also
          present. Does the 'maxmptime' indicates the absolute maximum which can be used
          as packetization time for a certain codec or does it indicate the packetization
          time which has to be used as preference. It's open to many different
          interpretations certainly in interworking scenarios.
        
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

m=audio 3456 RTP/AVP 18 0 13 96 98 99
a=maxmptime:10 10 - - 20 20
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Method 9&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor16"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.10"></a><h3>6.10.&nbsp;
Method 10</h3>

<p>
          Use of PacketCable 'mptime' attribute. See
          <a class='info' href='#PKT.PKT-SP-CODEC-MEDIA'>"Codec and Media Specification"<span> (</span><span class='info'>PacketCable, &ldquo;Codec and Media Specification,&rdquo; October&nbsp;2006.</span><span>)</span></a> [PKT.PKT&#8209;SP&#8209;CODEC&#8209;MEDIA] which
          gives a Note about the 'ptime': <a class='info' href='#RFC4566'>[RFC4566]<span> (</span><span class='info'>Handley, M., Jacobson, V., and C. Perkins, &ldquo;SDP: Session Description Protocol,&rdquo; July&nbsp;2006.</span><span>)</span></a> defines the 'maxptime'
          SDP attribute
          and V.152 defines the 'maxmptime' SDP attribute. The precedence of these
          attributes with respect to the 'ptime' and 'mptime' attributes is not defined
          at this time."<br />
       
        
</p>
<p>
          Remark:<br />

          This method is the same as indicated by method 4. However, in the <a class='info' href='#PKT.PKT-SP-CODEC-MEDIA'>[PKT.PKT&#8209;SP&#8209;CODEC&#8209;MEDIA]<span> (</span><span class='info'>PacketCable, &ldquo;Codec and Media Specification,&rdquo; October&nbsp;2006.</span><span>)</span></a>
          version from 9/2006, the mptime was removed and the maxptime was added. The PacketCable
          seems to move away from the need of having multiple packetization times in
          function of the codec and treat it more in the direction of a maximum end-to-end
          delay aspect.
        
</p>
<a name="anchor17"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.6.11"></a><h3>6.11.&nbsp;
Method 11</h3>

<p>
          Use of SDP capabilities negotiation method. See <a class='info' href='#I-D.ietf-mmusic-sdp-capability-negotiation'>[I&#8209;D.ietf&#8209;mmusic&#8209;sdp&#8209;capability&#8209;negotiation]<span> (</span><span class='info'>Andreasen, F., &ldquo;SDP Capability Negotiation,&rdquo; March&nbsp;2010.</span><span>)</span></a>
          which describes how additional capabilities can be
          negotiated, such as the different supported ptimes. This
          could be a possible solution in certain cases, but it also
          requires updates in implementations which followed the basic
          ptime/maxptime concept to adapt themselves to more
          restricted implementations. It also introduces additional
          complexity by adding new parameters and new semantics.
        
</p>
<a name="anchor18"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.7"></a><h3>7.&nbsp;
Clarification</h3>

<p>
        The "Session Initiation Protocol" (SIP) is used to setup media sessions. 
        In the SIP INVITE message, a "Session Description Protocol" (SDP) is 
        used. In the SDP media description part, the m-line contains the media 
        type (e.g. audio), a transport port, a transport protocol (e.g. RTP/AVP) 
        and a media format description depending on the transport protocol.
        For the transport protocol RTP/AVP or RTP/SAVP, the media format sub-field 
        can contain a list of RTP payload type numbers.<br />

        <br />

        Example:
        m=audio 49232 RTP/AVP 8 0 4<br />

        <br />

        The "8 0 4" is the media format, indicating a list of possible codecs
        indicated by static or dynamic numbers as defined in
        <a class='info' href='#RFC3551'>RFC 3551<span> (</span><span class='info'>Schulzrinne, H. and S. Casner, &ldquo;RTP Profile for Audio and Video Conferences with Minimal Control,&rdquo; July&nbsp;2003.</span><span>)</span></a> [RFC3551].
        <br />

        In the above example, a list of static numbers is used:<br />

        8 = PCMA - G.711 PCM A-law<br />

        0 = PCMU - G.711 PCM u-law<br />

        4 = G723 - G.723.1<br />

      
</p>
<p>
        The PCMA and PCMU are "sample-based" codecs while the G723 is a "frame-based" 
        codec. All of them make use of a sampling rate of 8 kHz or 0.125 ms/sample. 
        PCMA and PMCU encode each sample in 8 bits by making use of the A or u 
        logarithmic companding laws resulting in a datarate of 64 kbps.
        G723 however does not operate on single samples, but on different 
        samples combined together in a "frame". As such, higher compression rates 
        can be achieved. The G723 codec makes use of 240 voice samples corresponding with 
        30 ms speech frame duration. The codec compresses the data in the frame and 
        encodes it with 192 or 160 bits resulting in a datarate of 6.4 or 5.3 kbps. 
        G723 gives the advantage of a lower bit rate at the cost of increased 
        voice delay: 30 ms instead of 0,125 ms
      
</p>
<p>
        The "International Telecommunication Union" (ITU) gives some guidelines 
        on acceptable end-to-end delays in <a class='info' href='#ITU.G114'>[ITU.G114]<span> (</span><span class='info'>ITU-T, &ldquo;One-way transmission time,&rdquo; May&nbsp;2005.</span><span>)</span></a>. A delay up to 
        150 ms is acceptable. Between 150 and 400 ms, there is impact on the 
        perceived voice quality but still acceptable. Above 400 ms it becomes 
        unacceptable. Echo cancellers are required for delays >25 ms.
      
</p>
<p>
        In "time division multiplexing" (TDM) networks, the coding delay is the 
        biggest part contributing to the end-to-end delay. However, in 
        "Packet Oriented" networks, packetization delays are added to the 
        end-to-end delay and can become an issue. Each packet has a certain 
        header which contributes to the bandwidth usage, i.e. the total required 
        bit-rate. The more data can be packed together, the smaller the influence 
        of the header on the total payload and the higher the transmission 
        efficiency. However, combining more data in a packet gives an increase 
        of the end-to-end delay. As such, there is a trade-off between bandwidth 
        usage, amount of packet processing and end-to-end delay. For a higher 
        compression rate, more data in a packet to improve the transmission 
        efficiency gives a quality reduction due to the increased end-to-end delay.
      
</p>
<p>
        An example is indicated in following table where the G.711 (A or u-Law) is
        compared with the G.723.1 for different packetization delays. The headers
        consist of:
      
</p>
<p>
        </p>
<ul class="text">
<li>RTP header: 12 bytes.
</li>
<li>UDP header: 8 bytes.
</li>
<li>IPv4 header: 20 bytes.
</li>
<li>MAC layer: 14 bytes.
</li>
<li>CRC: 4 bytes.
</li>
<li>Start frame + preamble: 20 bytes.
</li>
</ul><p>
      
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

Codec  Packet Datarate Voice    Headers Tot    Payload Throughput
       Delay           Payload
       ms     kbps     bytes    bytes   bytes  %       kbps
-----------------------------------------------------------------
G711   0.125  64          1     78        79    1.3    5056.0
         2.5  64         20     78        98   20.4     313.6
         5    64         40     78       118   33.9     188.8
        10    64         80     78       158   50.6     126.4
        20    64        160     78       238   67.2      95.2
        30    64        240     78       318   75.5      84.8
        90    64        720     78       798   90.2      70.9
       200    64       1600     78      1678   95.4      67.1
-----------------------------------------------------------------
G723.1  30    6.4        24     78       102   23.5      27.2
        60    6.4        48     78       126   38.1      16.8
        90    6.4        72     78       150   48.0      13.3
       150    6.4       120     78       198   60.6      10.6
       300    6.4       240     78       318   75.5       8.5
-----------------------------------------------------------------

</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Packet delay &amp; Throughput&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<p>
        For the same packetization delay of 30 ms, the datarate of the G.723.1 
        is 10 times lower as for the G.711, but the payload efficiency is reduced 
        from 75.5 to 23.5%.  The same efficiency for the G.723.1 is obtained when 
        the packetization delay is 300 ms!  While the packet efficiency is lower, 
        the required bitrate on the link for the G.723.1 is reduced from 84.8 kbps 
        to 27.2 kbps. And when different frames are packed together, e.g. 3 frames 
        of 30 ms, the packetization delay becomes 90 ms resulting in a lower amount 
        of packets which have to be routed and processed and resulting in an 
        improved throughput data rate of 13.3 kbps.
      
</p>
<p>
        The used frame sizes for the different codecs are 0.125 ms (G.711), 2.5 ms 
        (G728), 10 ms (G729); 20 ms (G726, GSM; GSM-EFR, QCELP, LPC) and 30 ms (G723).
        All of them have a default 'ptime' of 20 ms, with the exception of the G723 
        with a default 'ptime' of 30ms.
      
</p>
<p>
        The media description part can contain additional attribute lines which
        complement or modify the media description line: 'ptime' and 'maxptime'
        attributes.
      
</p>
<p>
        Example:<br />

        m=audio 49232 RTP/AVP 8 0 4<br />

        a=ptime:20<br />

        a=maxptime:60
      
</p>
<p>
        <a class='info' href='#RFC3551'>RFC 35551<span> (</span><span class='info'>Schulzrinne, H. and S. Casner, &ldquo;RTP Profile for Audio and Video Conferences with Minimal Control,&rdquo; July&nbsp;2003.</span><span>)</span></a> [RFC3551] defines the default
        packetization time for each codec in Table 1. The PCMA and
        PCMU have 20 ms as default 'ptime' and the G723 has a 30 ms
        default 'ptime'.
      
</p>
<p>
        When, as in the example above, the 'ptime' value is 20, then it is a wrong 
        value for the G723 codec which requires at least a frame size of 30 ms 
        and as such requires a minimal packetization delay of 30 ms. And this causes many 
        different interworking problems between different systems due to different 
        interpretations of the relevant RFCs resulting in bad voice quality or call 
        setup failures.
      
</p>
<p>
        In some APIs, the following functions are provided to interface with the RTP
        and codec hardware layer for encoding voice samples, based on a certain codec,
        in RTP packets.
        </p>
<ol class="text">
<li>
            Set the encoding parameters such as codec type, payload type (for RTP),
            packetization rate. Mostly these parameters are configuration parameters of
            the device.
            Either, these parameters are manually provided based on guidelines from the
            network architecture or are dynamically and automatically provided.
          
</li>
<li>
            Next a transmit buffer has to be allocated. The lower layer provides a function
            to calculate the required buffer size in function of the encoding parameters.
          
</li>
<li>
            A transmit buffer is allocated with the indicated size (as a minimum) by the
            application layer.
          
</li>
<li>
            The synchronous voice data which has to be encoded is passed to the 
            hardware layer which encodes the data (codec and packetization) into the
            provided buffer.
          
</li>
<li>
            The buffer with the RTP data is returned to the application which
            can sent it out on the host network interface towards the packet network.
          
</li>
</ol><p>
      
</p>
<p>
        For the receiving part, required API functions are:
        </p>
<ol class="text">
<li>
            Set the required decoding parameters such as codec type, payload type, 
            initial latency in frames, jitter buffer info. Please note that packetization 
            time is not required because every receiver should be able to handle up 
            to 200 ms, which is in fact the MTU size for which the receiver should 
            have the required resources.
          
</li>
<li>
            The required buffer size which needs to be allocated is requested at 
            the hardware. This size is calculated based on the size of the RTP 
            header and the maximum allowed payload of 200 ms.
          
</li>
</ol><p>
      
</p>
<p>
        * The application however can decide to allocate smaller buffers if the 
        worst case is known for the expected RTP packetization time, i.e. by making
        use of the 'maxptime' attribute.
      
</p>
<p>
        Most implementations make use of a general purpose host processor (GPP) 
        in combination with a digital signal processor (DSP) for the codec/packetization part. 
        The host processor has the interface with the packet oriented world while 
        the DSP has an interface with a real-time synchronous network mostly with 
        special buffer handling mechanism to avoid too many interrupt handling.     
      
</p>
<p>
        Suppose a VoIP call making use of the G711 A or u-law. Most hardware
        solutions are using a DSP to handle the realtime stuff. Most of these
        DSPs have special build-in hardware functionality for PCM samples. The DSP can be
        configured for A or u law and for a specific clock rate. For every transmitted
        or received PCM sample, the hardware can generate an interrupt. But this has of
        course is a big burden on the system performance. As such, the DSPs also
        provide a method to avoid this interrupt burden by providing a mechanism
        based on an internal buffer. An interrupt is only generated when the buffer
        is empty or full.
        The initialization of this DSP hardware for a specific call is done at the
        SIP invite SDP negotiation time.
      
</p><br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

m=audio 1234 RTP/AVP 0 8 4
ptime=30
</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Example&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<p>
        So, if this SDP contains a PT=0,8,4 (i.e. G711u, G711A, G723) and a 'ptime'
        of 30, then this 'ptime' can be used to initialize the DSP port with a buffer
        size for 30 ms PCM voice samples. When the "offerer" sends a RTP packet
        for a G711u or G711A by making use of the default value of 20 ms, then
        the DSP PCM port is waiting for 30ms before sending out the buffer.
        Because only 20 ms are received in the RTP packet, it has to wait for
        the next RTP packet before being able to transmit the buffer causing a
        serious degradation of the voice quality.
      
</p>
<p>
        This could be the problem in DSP based solutions in media gateways between 
        IP and PSTN world but also for end user internet access devices (IAD) providing
        the possibility to attach a normal analog voice phone via a RJ11 jack (ATA -
        analog telephone adapter).
      
</p>
<p>
        For this use case, certain implementers are making arguments in the 
        direction of a complete SDP negotiation mechanism. But this is in conflict 
        with the SDP paradigm where the 'ptime' is an optional parameter and not bound 
        to a specific codec but to the media itself.
        Different proprietary solutions are now implemented causing even more 
        interworking issues.
      
</p>
<a name="anchor19"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8"></a><h3>8.&nbsp;
New proposal</h3>

<p>
        The basic idea of this proposal is to keep the packetization time
        independent from the codec and to consider the main purpose of the 'ptime'
        as follows.
      
</p>
<p>
        The 'ptime' is a parameter indicating the packetization time which is an
        important parameter for the end-to-end delay of the voice signal as
        indicated in the previous clarification section.
        It is defined as a media-attribute in the SDP.
      
</p>
<p>
        The only requirement for the use of the 'ptime' or 'maxptime' is the total
        size of the message which should fit in the MTU and the packetization
        time should be an integer multiple of the codec frame size.
      
</p>
<p>
        If the same session does require different kind of streams, e.g. in a
        conference where some users have a narrowband connection and others
        having a broadband connection, different media can be defined and
        allocated to different ports.
        In that case, different m-lines can be defined and another 'ptime' and
        'maxptime' can be indicated.
      
</p>
<p>
        The IETF RFCs are not clear when the 'ptime' or 'maxptime' in the SDP are not
        an integer multiple of the frame size. What should be used in that case?
        Making use of the default 'ptime', making use of the 'ptime' which is an
        integer multiple of the frame size and lower than the indicated 'ptime'?
        In case of an indicated 'maxptime', taking a value as close as possible to
        the indicated 'ptime' but lower as the 'maxptime'?
      
</p>
<p>
        This proposal takes care about the IETF architectural principle of
        "be strict when sending" and "be tolerant when receiving". Ref. 
        <a class='info' href='#RFC1958'>[RFC1958]<span> (</span><span class='info'>Carpenter, B., &ldquo;Architectural Principles of the Internet,&rdquo; June&nbsp;1996.</span><span>)</span></a>.
      
</p>
<a name="anchor20"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.1"></a><h3>8.1.&nbsp;
Sending party RTP voice payload</h3>

<p>
          The transmitting side of a connection needs to know the packetization
          time it can use for the RTP payload data, i.e. how many speech frames
          it can include in the RTP packet. A trade-off between the packetization
          delay and the transmission efficiency has to be made and this can be a
          static or a dynamic process which involves all elements in the
          end-to-end chain.
        
</p>
<p>
          As such, 3 different sources to determine the packetization time are
          considered.
        
</p>
<a name="anchor21"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.1.1"></a><h3>8.1.1.&nbsp;
ptime(s) - Static</h3>

<p>
            Static provided values in the end-device: default values or manually
            defined values.
          
</p>
<p>
            An end-device implementation must know:<br />

            </p>
<ol class="text">
<li>
                all the codec specific parameters such as:
                
<ol class="text">
<li>Sampling rate (e.g. 8000 Hz).
</li>
<li>Amount of channels (e.g. 1).
</li>
<li>Frame size in ms (e.g. 20 ms).
</li>
<li>Amount of encoded bits per frame (e.g. 264 bits).
</li>
<li>
                    Amount of required octets per frame (e.g. G.723.1 with 6.4 kbps,
                    has 189 bits for the encoded data resulting in a datarate of
                    189/30 ms or 6.3 kbps.
                    However, the packet data is octet aligned and as such, 3 bits are added
                    which results in 24 octets/frame or a datarate of 6.4 kbps).
                  
</li>
</ol>
              
</li>
<li>
                system specific parameters such as:
                
<ol class="text">
<li>MTU supported by the network and by the protocol stack of the end-device.
</li>
<li>Packetization time (e.g. 60 ms) and the maximum packetization time (e.g. 150 ms).
</li>
<li>Supported codecs.
</li>
</ol>
              
</li>
</ol><p>
          
</p>
<a name="anchor22"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.1.2"></a><h3>8.1.2.&nbsp;
ptime(d) - Dynamic</h3>

<p>
            Dynamic provided values defined by the network architecture.
          
</p>
<p>
            The network can indicate, as part of the device management, its supported
            codecs, the 'ptime' and 'maxptime'. These values can also change based on the
            dynamic behavior of the network. During heavy load on the network,
            the network architecture can decide to use lower rate codecs
            (for bandwidth issues) and/or higher packetization times
            (for packet processing performance).
            This dynamic change can be done before, during or after a session.
          
</p>
<a name="anchor23"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.1.3"></a><h3>8.1.3.&nbsp;
ptime(i) - Indicated</h3>

<p>
            Proposed indicated values coming from the receiving side.
          
</p>
<p>
            The receiving side can indicate in the SDP the 'ptime' and 'maxptime' value
            it wants to receive. This is an optional parameter for the media, codec
            independent and considered as an indication only. It should only be
            considered as a hint to the sending party.
          
</p>
<a name="anchor24"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.1.4"></a><h3>8.1.4.&nbsp;
ptime/maxptime algorithm</h3>

<p>
            Instead of indicating a 'ptime/maxptime' on a per-codec basis as done in
            many different proposals, this draft proposes to make use of the 'ptime/maxptime'
            as a common parameter coming from different sources:<br />

            ptime(s), ptime(d), ptime(i) and maxptime(s), maxptime(d), maxptime(i).
          
</p>
<p>
            In function of the available information for the 'ptime' and 'maxptime',
            the packetization time which will be used for the transmission "pt" is
            based on following algorithm.
            </p>
<ol class="text">
<li>
                Determine codec to be used, e.g. G723 based on local info or the
                optional network info.
              
</li>
<li>
                Determine coding data rate, e.g. 6.4 kbps based on local info or the
                optional network info.
              
</li>
<li>
                Based on the codec, the frame size in ms is known: fc = frame size
                of the codec.
              
</li>
<li>
                Determine the MTU size which can be used. Based on this value,
                the codec frame size and datarate, a 'maxptime' related to the codec "mc"
                can be calculated.
              
</li>
<li>
                Check the ptime(s, d, i) and maxptime(s, d, i, mc).
                Take the maximum value from the available set of ptime(s, d, i) which
                is lower or equal than the minimum value in the set maxptime(s, d, i, mc).
              
</li>
<li>
                Normalize this 'ptime' value to the integer multiple of the frame size
                lower or equal to this 'ptime' value and lower or equal to the "mc" but not
                lower then the codec frame size.
              
</li>
</ol><p>
          
</p>
<p>
            Remark:<br />

            It's up to a local policy of the device, to determine which 'ptime/maxptime'
            sources it will use in its calculation, e.g. it is possible to disallow
            the treatment of the 'ptime' indicated by the other side.
            This can easily be done by including/excluding the 'ptime/maxptime' values
            from the vectors used in the calculation.
          
</p>
<p>
            The formula to calculate the packetization time for the transmission of
            voice packets in the RTP payload data has following input parameters.
          
</p>
<p>
            </p>
<ol class="text">
<li>
                The packetization time made available from different sources.
                When no value is known, the frame size of the voice codec is used.
              
</li>
<li>
                The maximum packetization time values made available from different
                sources. When no value is known, the frame size of the voice codec is used.
              
</li>
<li>
                The frame size of the codec.
              
</li>
<li>
                The packetization time corresponding with the selected codec,
                frame size, frame datarate and the network MTU. This packetization time
                has to be larger as the frame size. At least one frame size should fit
                in the MTU!
              
</li>
</ol><p>
          
</p>
<p>
            The function has one output parameter: the packetization time which has
            to be used for the transmission: "pt". It is the frame size of the codec
            multiplied by the number of frames which have to be placed in the RTP
            payload based on the provided 'ptime' and 'maxptime' values.
            In the formula, the maximum packetization time related to the MTU is added
            to the vector which contains one or more packetization time values. The
            minimum value out of this set is determined.
            For the 'ptime' set "p" which contains one or more values, the values of
            the 'ptime' which is higher as the minimum value of the 'maxptime' set "mp"
            is replaced by this value.  Then the maximum value out of this set
            is determined and used to calculate the amount of voice frames which
            can be included with that packetization time.
          
</p>
<p>
            Some examples are provided. The first example is related to the G723
            with a frame size of 30 ms. When the receiver has indicated a 'ptime' of
            20 ms in the SDP, the RTP will be sent with one voice frame of 30 ms.<br />

            In another example, a G711 codec with a default 'ptime' of 20 ms and
            an indicated 'ptime' of 60 ms, 3 speech frames of 20 ms can be transmitted
            in one RTP packet towards the receiver which has indicated his ability to
            receive RTP packets with 60 ms packetization time.
          
</p>
<p>
            This "pt" is used to allocate the PCM buffer size where the voice samples
            from the synchronous network interface are stored before being passed
            in RTP packets towards the packet oriented network.
          
</p>
<p>
            When the 'ptime' and 'maxptime' are lower as the frame size of the codec, no
            packetization time for the transmission can be determined. An invalid value
            (=0) is indicated by the algorithm. In that case, the sender has to select
            another codec with a voice frame size which is lower or equal to the 'ptime' 
            or 'maxptime'.
          
</p>
<a name="anchor25"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.1.5"></a><h3>8.1.5.&nbsp;
Algorithm and examples</h3>

<a name="anchor26"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.1.5.1"></a><h3>8.1.5.1.&nbsp;
Codec independent parameters</h3>

<p>
              </p>
<ul class="text">
<li>
                  p = vector containing all provided packetization time values such as
                  static, dynamic, indicated values.
                
</li>
<li>
                  mp = vector containing all provided maximum packetization time values.
                
</li>
</ul><p>
            
</p>
<p>
              At least, one "p" and "mp" value have to be provided. When no static,
              dynamic or indicated values are known, the frame size of the codec "fc"
              can be used.
            
</p>
<a name="anchor27"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.1.5.2"></a><h3>8.1.5.2.&nbsp;
Codec dependent parameters</h3>

<p>
              </p>
<ul class="text">
<li>
                  fc = frame size of the codec
                
</li>
<li>
                  mc = max packetization time which corresponds with the selected codec,
                  frame size, frame datarate and the network MTU (mc > fc).
                
</li>
</ul><p>
            
</p>
<a name="anchor28"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.1.5.3"></a><h3>8.1.5.3.&nbsp;
Pseudocode algorithm</h3>
<br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

pt(p,mp,fc,mc) := |mp &lt;- stack(mp,mc)
                  |if cols(p)&gt;0
                  |  for i e 0..cols(p)-1
                  |     p(i)&lt;-min(mp) if p(i)&gt;min(mp)
                  |otherwise
                  |     p&lt;-min(mp) if p&gt;min(mp)
                  |nf&lt;-1 if (nf&lt;-floor(max(p)/fc)&lt;=0) &amp; (min(mp)&gt;fc)
                  |fc.nf

</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Pseudocode algorithm&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor29"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.1.5.4"></a><h3>8.1.5.4.&nbsp;
Pseudocode examples</h3>
<br /><hr class="insert" />
<div style='display: table; width: 0; margin-left: auto; margin-right: auto'><pre>

ptime:=20         maxptime:=60          pt(ptime,maxptime,30,100)=30
ptime:=20         maxptime:=20          pt(ptime,maxptime,30,100)=0
ptime:=30         maxptime:=30          pt(ptime,maxptime,30,100)=30
ptime:=60         maxptime:=80          pt(ptime,maxptime,30,100)=60

ptime:=20         maxptime:=60          pt(ptime,maxptime,20,100)=20
ptime:=60         maxptime:=80          pt(ptime,maxptime,20,100)=60
ptime:=70         maxptime:=200         pt(ptime,maxptime,20,100)=60
ptime:=120        maxptime:=60          pt(ptime,maxptime,20,100)=60

ptime:=120        maxptime:=200         pt(ptime,maxptime,10,100)=100
ptime:=[40,50,20] maxptime:=200         pt(ptime,maxptime,10,100)=50
ptime:=[40,50,20] maxptime:=[40,50,20]  pt(ptime,maxptime,10,100)=20
ptime:=[120,40] maxptime:=[150,200,100] pt(ptime,maxptime,10,100)=100

</pre></div><table border="0" cellpadding="0" cellspacing="2" align="center"><tr><td align="center"><font face="monaco, MS Sans Serif" size="1"><b>&nbsp;Pseudocode examples&nbsp;</b></font><br /></td></tr></table><hr class="insert" />

<a name="anchor30"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.2"></a><h3>8.2.&nbsp;
Procedures for the SDP offer/answer</h3>

<p>
          This section contains the procedures related to the calculation of the
          'ptime' and 'maxptime' attributes when they are used by protocols
          following the SDP offer/answer model specified in <a class='info' href='#RFC3264'>[RFC3264]<span> (</span><span class='info'>Rosenberg, J. and H. Schulzrinne, &ldquo;An Offer/Answer Model with Session Description Protocol (SDP),&rdquo; June&nbsp;2002.</span><span>)</span></a>.
        
</p>
<a name="anchor31"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.2.1"></a><h3>8.2.1.&nbsp;
Procedures for an SDP offerer</h3>

<p>
          An SDP offerer may include a 'ptime' value and a 'maxptime' value in the
          SDP. These values are merely an indication of the desired packetization
          times. 
          The same formula as for the "pt" is used to determine
          the 'ptime' in the SDP. When the media line contains different codec
          formats, the 'ptime' value is determined for the first codec in the format
          list (i.e. the codec with the highest priority).
          For the 'maxptime', the minimum value of the 'maxptime' value set is used
          in the SDP and normalized to an integer multiple of the frame size of
          the first codec in the list.
        
</p>
<p>
          It's up to a local policy of the device, to determine which 'ptime/maxptime'
          sources it will use in its calculation, e.g. it is possible to disallow
          the treatment of the 'ptime' indicated by the other side. This can easily
          be done by including/excluding the 'ptime/maxptime' values from the
          vectors used in the calculation.
        
</p>
<a name="anchor32"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.2.2"></a><h3>8.2.2.&nbsp;
Procedures for an SDP answerer</h3>

<p>
            An SDP answerer that receives an SDP offer may also determine the value
            of 'ptime' value and the 'maxptime' value to be included in the SDP answer.
            These parameters are determined in the same way as done
            by the offerer. However, the "answerer" can use another local policy to
            determine which 'time/maxptime' sources will be used in the calculation.
          
</p>
<a name="anchor33"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.3"></a><h3>8.3.&nbsp;
Receiving party RTP voice payload</h3>

<p>
          The receiver has to make use of the information in the RTP to determine
          the codec type, the frame rate and the total packetization time of the
          voice payload data.
        
</p>
<p>
          For the receiver, two parts in the data flow can be considered. First,
          the packet has to be received from the packet oriented network. At the
          other side, mostly a synchronous network is provided where PCM voice
          samples are used.
        
</p>
<p>
          This proposal describes a method how the receiver can handle unknown
          packetization buffer requirements which also allows inband changes
          for the codec datarate and packetization time.
        
</p>
<p>
          As indicated, there are different sources for the 'maxptime' and it
          is already described how a 'maxptime' value can be determined for
          sending it in the SDP indication. The same 'maxptime' is used for
          the allocation of the PCM buffer space where the voice samples
          received in the RTP packets are stored before being transmitted
          towards the synchronous network, after a de-jittering. An indication is given to the
          DSP hardware about the actual packetization length obtained
          from the received RTP packet. When the amount of samples are stored
          in the buffer corresponding to the packetization length, an interrupt
          is generated and the data is transmitted without having to wait for
          another RTP packet to fill-up the remaining space.
        
</p>
<a name="anchor34"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.8.4"></a><h3>8.4.&nbsp;
Advantages</h3>

<p>
          The new proposed method has following advantages:<br />

          <br />

          </p>
<ol class="text">
<li>
              Basic idea of the 'ptime' related RFCs is kept. No new parameters
              have to be added and no new interpretations or semantic reordering
              has to be done.
            
</li>
<li>
              The new method is strict in sending and tolerant in receiving.
              It sends with the maximum allowed 'ptime' lower or equal to the minimal
              'maxptime'.
            
</li>
<li>
              Different sources for the 'ptime' and 'maxptime' are taken into account,
              even more as done in the different current proposals trying to
              negotiate end-to-end.
            
</li>
<li>
              A local policy in the end-device can easily be adopted and
              adapted without requiring changes in the end-to-end protocol.
            
</li>
<li>
              The algorithm makes use of all the provided information about
              'ptime', 'maxptime', codec frame size, MTU size and proposes the most
              optimum 'ptime'.
            
</li>
<li>
              The same algorithm is used at sending and receiving side, for
              SDP indications and RTP packets.
            
</li>
<li>
              The algorithm is small and straight-forward. Codec dependent
              and codec independent parameters are clearly indicated.
            
</li>
</ol><p>
        
</p>
<a name="anchor35"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.9"></a><h3>9.&nbsp;
Conclusion and next steps</h3>

<p>
        This memo advocates for the need of a standardized mechanism to
        indicate the packetization time on a per codec basis, allowing
        the creator of SDP to include several payload formats in the
        same media description line with different packetization
        times.
      
</p>
<p>
        This memo encourage discussion in the MMUSIC WG mailing list
        in the IETF. The ultimate goal is to define a standard
        mechanism that fulfils the requirements highlighted in this
        memo.
      
</p>
<p>
        The goal is finding a solution which does not require changes in
        implementations which have followed the existing RFC guidelines and
        which are able to receive any packetization time.
      
</p>
<a name="sec-security"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.10"></a><h3>10.&nbsp;
Security Considerations</h3>

<p>
        This memo discusses a problem statement and requirements. As
        such, no protocol that can suffer attacks is defined.
      
</p>
<a name="sec-iana"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.11"></a><h3>11.&nbsp;
IANA Considerations</h3>

<p>
        This document does not request IANA to take any action.
      
</p>
<a name="rfc.references"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<a name="rfc.section.12"></a><h3>12.&nbsp;
References</h3>

<a name="rfc.references1"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<h3>12.1.&nbsp;Normative References</h3>
<table width="99%" border="0">
<tr><td class="author-text" valign="top"><a name="RFC4566">[RFC4566]</a></td>
<td class="author-text">Handley, M., Jacobson, V., and C. Perkins, &ldquo;<a href="http://tools.ietf.org/html/rfc4566">SDP: Session Description Protocol</a>,&rdquo; RFC&nbsp;4566, July&nbsp;2006 (<a href="http://www.rfc-editor.org/rfc/rfc4566.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC3264">[RFC3264]</a></td>
<td class="author-text">Rosenberg, J. and H. Schulzrinne, &ldquo;<a href="http://tools.ietf.org/html/rfc3264">An Offer/Answer Model with Session Description Protocol (SDP)</a>,&rdquo; RFC&nbsp;3264, June&nbsp;2002 (<a href="http://www.rfc-editor.org/rfc/rfc3264.txt">TXT</a>).</td></tr>
</table>

<a name="rfc.references2"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<h3>12.2.&nbsp;Informative References</h3>
<table width="99%" border="0">
<tr><td class="author-text" valign="top"><a name="ITU.V152">[ITU.V152]</a></td>
<td class="author-text">ITU-T, &ldquo;<a href="http://www.itu.int/rec/dologin_pub.asp?lang=e&amp;id=T-REC-V.152-200501-I!!PDF-E&amp;type=items">Procedures for supporting voice-band data over IP networks</a>,&rdquo; ITU-T Recommendation&nbsp;V.152, January&nbsp;2005.</td></tr>
<tr><td class="author-text" valign="top"><a name="ITU.G114">[ITU.G114]</a></td>
<td class="author-text">ITU-T, &ldquo;<a href="http://www.itu.int/rec/dologin_pub.asp?lang=e&amp;id=T-REC-G.114-200305-I!!PDF-E&amp;type=items">One-way transmission time</a>,&rdquo; ITU-T Recommendation&nbsp;G.114, May&nbsp;2005.</td></tr>
<tr><td class="author-text" valign="top"><a name="PKT.PKT-SP-EC-MGCP">[PKT.PKT-SP-EC-MGCP]</a></td>
<td class="author-text">PacketCable, &ldquo;<a href="http://www.packetcable.com/downloads/specs/PKT-SP-MGCP-I11-050812.pdf">PacketCable Network-Based Call Signaling Protocol Specification</a>,&rdquo; PacketCable&nbsp;PKT-SP-EC-MGCP-I11-050812, August&nbsp;2005.</td></tr>
<tr><td class="author-text" valign="top"><a name="PKT.PKT-SP-CODEC-MEDIA">[PKT.PKT-SP-CODEC-MEDIA]</a></td>
<td class="author-text">PacketCable, &ldquo;<a href="http://www.packetcable.com/downloads/specs/PKT-SP-CODEC-MEDIA-I02-061013.pdf">Codec and Media Specification</a>,&rdquo; PacketCable&nbsp;PKT-SP-CODEC-MEDIA-I02-061013, October&nbsp;2006.</td></tr>
<tr><td class="author-text" valign="top"><a name="I-D.ietf-mmusic-sdp-capability-negotiation">[I-D.ietf-mmusic-sdp-capability-negotiation]</a></td>
<td class="author-text">Andreasen, F., &ldquo;<a href="http://www.ietf.org/internet-drafts/draft-ietf-mmusic-sdp-capability-negotiation-13.txt">SDP Capability Negotiation</a>,&rdquo; draft-ietf-mmusic-sdp-capability-negotiation-13 (work in progress), March&nbsp;2010 (<a href="http://www.ietf.org/internet-drafts/draft-ietf-mmusic-sdp-capability-negotiation-13.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC3890">[RFC3890]</a></td>
<td class="author-text">Westerlund, M., &ldquo;<a href="http://tools.ietf.org/html/rfc3890">A Transport Independent Bandwidth Modifier for the Session Description Protocol (SDP)</a>,&rdquo; RFC&nbsp;3890, September&nbsp;2004 (<a href="http://www.rfc-editor.org/rfc/rfc3890.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC3108">[RFC3108]</a></td>
<td class="author-text">Kumar, R. and M. Mostafa, &ldquo;<a href="http://tools.ietf.org/html/rfc3108">Conventions for the use of the Session Description Protocol (SDP) for ATM Bearer Connections</a>,&rdquo; RFC&nbsp;3108, May&nbsp;2001 (<a href="http://www.rfc-editor.org/rfc/rfc3108.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC4504">[RFC4504]</a></td>
<td class="author-text">Sinnreich, H., Lass, S., and C. Stredicke, &ldquo;<a href="http://tools.ietf.org/html/rfc4504">SIP Telephony Device Requirements and Configuration</a>,&rdquo; RFC&nbsp;4504, May&nbsp;2006 (<a href="http://www.rfc-editor.org/rfc/rfc4504.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC3441">[RFC3441]</a></td>
<td class="author-text">Kumar, R., &ldquo;<a href="http://tools.ietf.org/html/rfc3441">Asynchronous Transfer Mode (ATM) Package for the Media Gateway Control Protocol (MGCP)</a>,&rdquo; RFC&nbsp;3441, January&nbsp;2003 (<a href="http://www.rfc-editor.org/rfc/rfc3441.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC3952">[RFC3952]</a></td>
<td class="author-text">Duric, A. and S. Andersen, &ldquo;<a href="http://tools.ietf.org/html/rfc3952">Real-time Transport Protocol (RTP) Payload Format for internet Low Bit Rate Codec (iLBC) Speech</a>,&rdquo; RFC&nbsp;3952, December&nbsp;2004 (<a href="http://www.rfc-editor.org/rfc/rfc3952.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC4060">[RFC4060]</a></td>
<td class="author-text">Xie, Q. and D. Pearce, &ldquo;<a href="http://tools.ietf.org/html/rfc4060">RTP Payload Formats for European Telecommunications Standards Institute (ETSI) European Standard ES 202 050, ES 202 211, and ES 202 212 Distributed Speech Recognition Encoding</a>,&rdquo; RFC&nbsp;4060, May&nbsp;2005 (<a href="http://www.rfc-editor.org/rfc/rfc4060.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC1958">[RFC1958]</a></td>
<td class="author-text"><a href="mailto:brian@dxcoms.cern.ch">Carpenter, B.</a>, &ldquo;<a href="http://tools.ietf.org/html/rfc1958">Architectural Principles of the Internet</a>,&rdquo; RFC&nbsp;1958, June&nbsp;1996 (<a href="http://www.rfc-editor.org/rfc/rfc1958.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC2327">[RFC2327]</a></td>
<td class="author-text"><a href="mailto:mjh@isi.edu">Handley, M.</a> and <a href="mailto:van@ee.lbl.gov">V. Jacobson</a>, &ldquo;<a href="http://tools.ietf.org/html/rfc2327">SDP: Session Description Protocol</a>,&rdquo; RFC&nbsp;2327, April&nbsp;1998 (<a href="http://www.rfc-editor.org/rfc/rfc2327.txt">TXT</a>, <a href="http://xml.resource.org/public/rfc/html/rfc2327.html">HTML</a>, <a href="http://xml.resource.org/public/rfc/xml/rfc2327.xml">XML</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC3267">[RFC3267]</a></td>
<td class="author-text">Sjoberg, J., Westerlund, M., Lakaniemi, A., and Q. Xie, &ldquo;<a href="http://tools.ietf.org/html/rfc3267">Real-Time Transport Protocol (RTP) Payload Format and File Storage Format for the Adaptive Multi-Rate (AMR) and Adaptive Multi-Rate Wideband (AMR-WB) Audio Codecs</a>,&rdquo; RFC&nbsp;3267, June&nbsp;2002 (<a href="http://www.rfc-editor.org/rfc/rfc3267.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC3016">[RFC3016]</a></td>
<td class="author-text">Kikuchi, Y., Nomura, T., Fukunaga, S., Matsui, Y., and H. Kimata, &ldquo;<a href="http://tools.ietf.org/html/rfc3016">RTP Payload Format for MPEG-4 Audio/Visual Streams</a>,&rdquo; RFC&nbsp;3016, November&nbsp;2000 (<a href="http://www.rfc-editor.org/rfc/rfc3016.txt">TXT</a>).</td></tr>
<tr><td class="author-text" valign="top"><a name="RFC3551">[RFC3551]</a></td>
<td class="author-text">Schulzrinne, H. and S. Casner, &ldquo;<a href="http://tools.ietf.org/html/rfc3551">RTP Profile for Audio and Video Conferences with Minimal Control</a>,&rdquo; STD&nbsp;65, RFC&nbsp;3551, July&nbsp;2003 (<a href="http://www.rfc-editor.org/rfc/rfc3551.txt">TXT</a>, <a href="http://www.rfc-editor.org/rfc/rfc3551.ps">PS</a>, <a href="http://www.rfc-editor.org/rfc/rfc3551.pdf">PDF</a>).</td></tr>
</table>

<a name="rfc.authors"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<h3>Authors' Addresses</h3>
<table width="99%" border="0" cellpadding="0" cellspacing="0">
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Marc Willekens</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Nokia Siemens Networks</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Atealaan 34</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Herentals, BE  2200</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Belgium</td></tr>
<tr><td class="author" align="right">Email:&nbsp;</td>
<td class="author-text"><a href="mailto:marc.willekens.ext@nsn.com">marc.willekens.ext@nsn.com</a></td></tr>
<tr cellpadding="3"><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Miguel A. Garcia-Martin</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Nokia Siemens Networks</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">P.O.Box 6</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Nokia Siemens Networks, FIN  02022</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Finland</td></tr>
<tr><td class="author" align="right">Email:&nbsp;</td>
<td class="author-text"><a href="mailto:miguel.garcia@nsn.com">miguel.garcia@nsn.com</a></td></tr>
<tr cellpadding="3"><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Peili Xu</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Huawei Technologies</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Bantian</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">Longgang, Shenzhen  518129</td></tr>
<tr><td class="author-text">&nbsp;</td>
<td class="author-text">China</td></tr>
<tr><td class="author" align="right">Email:&nbsp;</td>
<td class="author-text"><a href="mailto:xupeili@huawei.com">xupeili@huawei.com</a></td></tr>
</table>
<a name="rfc.copyright"></a><br /><hr />
<table summary="layout" cellpadding="0" cellspacing="2" class="TOCbug" align="right"><tr><td class="TOCbug"><a href="#toc">&nbsp;TOC&nbsp;</a></td></tr></table>
<h3>Full Copyright Statement</h3>
<p class='copyright'>
Copyright &copy; The IETF Trust (2008).</p>
<p class='copyright'>
This document is subject to the rights,
licenses and restrictions contained in BCP&nbsp;78,
and except as set forth therein,
the authors retain all their rights.</p>
<p class='copyright'>
This document and the information contained herein are provided
on an &ldquo;AS IS&rdquo; basis and THE CONTRIBUTOR,
THE ORGANIZATION HE/SHE REPRESENTS
OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY, THE IETF TRUST
AND THE INTERNET ENGINEERING TASK FORCE DISCLAIM ALL WARRANTIES,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTY THAT
THE USE OF THE INFORMATION HEREIN WILL NOT INFRINGE ANY RIGHTS OR ANY
IMPLIED WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR
PURPOSE.</p>
<h3>Intellectual Property</h3>
<p class='copyright'>
The IETF takes no position regarding the validity or scope of any
Intellectual Property Rights or other rights that might be claimed
to pertain to the implementation or use of the technology
described in this document or the extent to which any license
under such rights might or might not be available; nor does it
represent that it has made any independent effort to identify any
such rights.
Information on the procedures with respect to
rights in RFC documents can be found in BCP&nbsp;78 and BCP&nbsp;79.</p>
<p class='copyright'>
Copies of IPR disclosures made to the IETF Secretariat and any
assurances of licenses to be made available,
or the result of an attempt made to obtain a general license or
permission for the use of such proprietary rights by implementers or
users of this specification can be obtained from the IETF on-line IPR
repository at <a href='http://www.ietf.org/ipr'>http://www.ietf.org/ipr</a>.</p>
<p class='copyright'>
The IETF invites any interested party to bring to its attention
any copyrights,
patents or patent applications,
or other
proprietary rights that may cover technology that may be required
to implement this standard.
Please address the information to the IETF at <a href='mailto:ietf-ipr@ietf.org'>ietf-ipr@ietf.org</a>.</p>
</body></html>
